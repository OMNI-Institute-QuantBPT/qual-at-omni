---
title: Data Cleaning
toc-depth: 2
---

```{r packages, echo=FALSE, eval=FALSE}
library(tidyverse)
library(omni)
library(flextable)
library(janeaustenr) # jane austen books

text <- austen_books()
```

## What This Page Covers 

Youâ€™ll find guidance on:

-   **[Principles and purpose of qualitative data cleaning]{.teal-600}**
-   **[Defining "clean" and "analysis-ready" data at Omni]{.teal-600}**
-   **[Step-by-step cleaning procedures in R]{.teal-600}**
-   **[Reporting and documentation standards]{.teal-600}**

These data cleaning methods can be applied to text from: Word documents (.docx), PDFs
(.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses
(.xlsx or .csv), and more.

## Introduction

Data cleaning is often one of the first things you will do when you
start working with qualitative data at Omni. Whether weâ€™re working with
interview transcripts, focus group discussions, or open-ended survey
responses, the raw data we receive is rarely ready for immediate
analysis. Cleaning is not just about tidying up; itâ€™s about making
informed decisions that clarify the meaning and integrity of the data
while preparing it for systematic analysis.

The decisions we make during the cleaning process are every bit as
complex and impactful as those made during coding and analysis.
Thoughtful data cleaning can preserve the richness of qualitative data,
while careless decisions can distort or diminish participants' voices.
Therefore, it is especially important to have a strong set of working
principles to guide your decisions when cleaning qualitative data.

This guide covers a general approach to qualitative data cleaning, with
an emphasis on useful R packages and functions designed to conquer some
common challenges. While this guide includes tools and code to make your
life easier, it also offers guidelines for making judgment calls about
what to remove, retain, or clarify in the data.

The steps in a qualitative data cleaning process will always be informed
by two key factors:

1)  **[The state of the data when we (Omni) receive it]{.teal-600}**

-   For example, some transcripts may come from automated services (like
    Zoom or Otter.ai) and contain timestamps, speaker labels, or filler
    words that require removal. Others may be professionally transcribed
    and need minimal cleaning.

2)  **[The specific needs of the project]{.teal-600}** 
-   Because of this variability,
    we encourage a flexible, judgment-driven approach to data cleaning.
    The steps described in this guide are common to many projects, but
    their order and application should be tailored to the needs of the
    dataset and the analytic goals of the project. Importantly,
    depending on the type of analysis, different cleaning steps may be
    required. Consult the analysis plan and research questions in your
    project materials to verify the needs of the project.

## Rationale

When we clean qualitative data, we apply a series of thoughtful transformations that make the data clearer, more consistent, and usable
for analysis. Qualitative data cleaning requires attention to detail and
sensitivity to the context in which the data were collected. The
procedures we use need to be flexible because the downstream purposes of
the data can vary from project to project, whether for thematic coding,
content analysis, or mixed-methods integration.

The qualitative data cleaner often has to make many judgment calls
during this process. These decisions are guided by the projectâ€™s goals,
the nature of the source data, team experience, and guidance documents
(like this one). Every decision and its rationale should be clearly
documented in the data cleaning script or data log (more on that below).
Transparency in this process ensures that the cleaned dataset remains
trustworthy and aligned with our ethical standards for qualitative
research.

Qualitative data cleaning requires a lot of careful thought and
attention. The R code that cleans text data needs to be clearly written
and well-commented, not only for reproducibility but to ensure that
meaning is preserved, and participant voices are not inadvertently
altered or diminished. In qualitative work, the cleaning process can
directly impact the integrity of the analysis.

Just as with quantitative analysis, qualitative data-cleaning decisions
are made with greater ease and clarity when there is a clear work plan,
guided by the projectâ€™s research questions or evaluation goals. Having a
shared understanding of what the team hopes to explore in the data helps
inform:

- What should be cleaned
- What should be preserved (even if messy)
- What should be flagged for discussion 

Finally, whether youâ€™re writing code for qualitative data cleaning or
any other purpose, always write your R scripts as if they will later be:

-   Heavily scrutinized
-   Held up as example code
-   Modified by someone brand new to both R and the project

Make it easy on future Omni-itesâ€”and on your future self!

## When are my data clean?

For there to be project tasks that direct Omni-ites to â€˜clean qualitative data,â€™ and a
guide to help in doing so, there should also be a shared understanding
of what it means for qualitative data to be clean.

**[At Omni, qualitative data are considered clean when they are organized, de-identified, and ready for analysis or coding.]{.teal-600}**

That means the data:

- Accurately reflect the original source material (e.g., interviews, focus groups, or open-text survey responses) 
- Have been transformed into a structure that makes them easy to navigate and analyze 
- Protect the privacy and confidentiality of participants 
- Are consistent, clear, and free of irrelevant clutter (like transcription artifacts) 

### What Makes a Qualitative Dataset "Analysis-Ready"?

For qualitative text data to be ready for analysis, they should meet the following criteria:

1) Speaker Information Is Clear and Consistent

- Participant speakers and interviewers are clearly labeled in the data.
- Each speakerâ€™s text is grouped logically into segments, preserving
conversational flow. 

2) Participant Identifiers Are Specified and Protected

- Real names, locations, and other direct identifiers have been removed or
replaced with participant IDs or pseudonyms. 
- Confidential information (e.g., agency names, job titles, organizations) is anonymized where necessary, following Omniâ€™s confidentiality guidelines. 

3) Questions Are Clearly Distinguished From Responses

- Interviewer questions (or prompts) are labeled or separated from
participant responses, as appropriate. This can be done by adding
question text as its own field in the dataset or by adding markers in
the transcript. 

4) Text Segments Are Ordered and Organized

- The transcript text is ordered according to the flow of conversation.
Segments are correctly time-sequenced (even if timestamps themselves are
removed). 

5) Text Is Structured Into a Tidy, Rectangular Format

- Each row represents a single speaker turn or unit of analysis (e.g., a
complete response to a question). 
- Data are stored in a rectangular table (data frame), with columns for: 
  - Session name or group (e.g., "Educators" or "Public Health")
  - Participant ID or role (e.g., "Participant 1", "Facilitator")
  - Text segment (the response or comment)
  - Any relevant metadata (e.g., discussion section, date) 
  - Transcription
  
6) Artifacts Are Removed

- All timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless
specifically required for analysis. 
- Automated transcription quirks
(e.g., repeated words, filler words, auto-captions like â€œ[inaudible]â€)
are reviewed, cleaned, or flagged. 

7) Text Is Consistent in Style and Format

- All text is converted to lowercase, unless case is important for
analysis. 
- Spelling errors are corrected when they obscure meaning (but
regional spellings or participant quirks may be preserved if relevant).
- Punctuation and spacing are standardized (no excessive whitespace,
missing periods, etc.).

8) Relevant Identifiers Are Added to the Dataset

- If there are multiple sessions or groups, these are labeled (e.g.,
"Educators," "Public Health"). 
- If there are themes or discussion
sections (e.g., "Challenges," "Recommendations"), these are identified.
- If codes are pre-assigned for analytic purposes (e.g.,
â€œPre-implementation,â€ â€œPost-implementationâ€), they are included in the
data structure. 

### How Do We Know When Qualitative Data Are Clean

Here are some guiding questions to help determine when qualitative data are
ready for analysis (i.e., clean):

- What is the plan for coding or analyzing this data?

- The analysis plan (or coding framework) should inform cleaning
decisions. For example, if the team plans to do thematic coding, theyâ€™ll
need text organized into meaningful speaker turns or responses. What
needs to be anonymized?

- Identify any sensitive information that must be redacted or replaced to
maintain confidentiality and ensure participant privacy. Are speaker
turns properly attributed and easy to follow?

- Each speakerâ€™s contributions should be clearly labeled, consistently
formatted, and grouped logically. Are responses to specific questions
clearly identifiable?

- If interviews or focus groups follow a semi-structured guide, itâ€™s
important to separate questions from responses for clarity in analysis.
Is the structure of the data appropriate for the analytic tool?

- If the data are being uploaded to Dedoose, NVivo, or another platform,
they should follow the required format (e.g., tidy data frame with
speaker IDs and group names). Have all unnecessary artifacts been
removed?

- Time stamps, filler words, and transcription errors that donâ€™t add value
to the analysis should be removed. Has the cleaned data been reviewed by
someone else (QA check)?

- Whenever possible, have another Omni-ite review the cleaned data for
accuracy and completeness. 

### Common Issues to Discuss Early in the Cleaning Process

Just like in quantitative data cleaning, clarifying
expectations at the start of a project will save time later. For
qualitative projects, consider these:

- Will we analyze both facilitator questions and participant responses, or
just participant responses? 
- How will we handle overlapping speech, interruptions, or incomplete thoughts? 
- Do we need to standardize participant roles (e.g., "Public Health Official" vs. "PH Staff") for consistency? 
- Are we preparing data for manual coding or automated text
analysis? 
- Do we need to translate or transcribe non-English responses?
- Do we need to connect text segments with broader context, such as the
discussion theme or section of the focus group? 

**[Quick summary of "clean qualitative data" at Omni:]{.teal-600}**

- Anonymized 
- Clearly structured and labeled 
- Organized for easy analysis
- Free of unnecessary artifacts 
- Ready for use in coding and interpretation

## How do I report the results of data cleaning?

Cleaning qualitative data is an interpretive and decision-heavy process,
and those decisions need to be transparent. Reporting your cleaning
process helps:

Project leads understand whatâ€™s been done and why. Provide documentation
in case changes need to be made later. Build trust in the integrity of
the cleaned dataset. Support future qualitative coding, interpretation,
and reporting. Qualitative data cleaning produces resultsâ€”changes to the
text or data structureâ€”that should be documented in a clear, shareable
data cleaning report.

**[What to include in a report about qualitative data cleaning]{.teal-600}**

1. Summary of the Dataset You Cleaned Start with an overview:

How many transcripts or files were cleaned? How many sessions (e.g.,
focus groups, interviews) are included? What types of participants are
represented (e.g., educators, public health professionals)? 

Example: This dataset includes transcripts from 8 focus groups, with 42
participants. Participants represent two stakeholder groups: Educators
(n = 20) and Public Health Professionals (n = 22).

2.  Anonymization and De-Identification Steps Document what you removed
    or replaced to protect confidentiality.

Were participant names replaced with IDs (e.g., Participant 01)? Were
organizations, locations, or personal identifiers removed or redacted?
Were job titles generalized (e.g., â€œCEOâ€ changed to â€œsenior leaderâ€)?

Example: Replaced all participant names with Participant IDs (e.g.,
P01). Removed specific references to organizations and locations (e.g.,
â€œat Boulder Community Hospitalâ€ becomes â€œat [hospital]â€). Redacted job
titles for anonymity when mentioned alongside unique organizations.

3.  Speaker Labeling and Text Structuring Describe how speakers were
    labeled and how the transcript was organized.

Were speakers consistently labeled as "Participant" and "Facilitator"?
Was each speaker turn separated into its own row or segment? Were
questions separated from responses? 

Example: Speaker turns were labeled
consistently as either Facilitator or Participant. Each speaker turn is
stored as one row in the cleaned dataset, with associated metadata
(Session name, Speaker role, Discussion section).

4.  Artifacts Removed (Timestamps, Filler Words, etc.) Note what
    transcription artifacts were removed or edited:

Were timestamps deleted? Were filler words (e.g., â€œum,â€ â€œuhâ€) removed?
If so, specify whether this was systematic or case-by-case. Were
transcription errors corrected? 

Example: Removed all timestamps in the
format [hh:mm:ss]. Deleted common filler words (â€œum,â€ â€œuhâ€) unless they
contributed to participant meaning or tone. Reviewed and corrected
auto-transcription errors (e.g., â€œDodooseâ€ corrected to â€œDedooseâ€).

5.  Text Standardization and Formatting Summarize standardization steps
    for readability and consistency:

Was text converted to lowercase? Was spelling corrected? If so, did you
preserve participant colloquialisms? Were consistent punctuation and
spacing applied? 

Example: Converted all text to lowercase for
consistency. Standardized punctuation (e.g., added periods to sentence
ends where missing). Corrected spelling errors that obscured meaning but
preserved participant vernacular and tone where appropriate.

6.  Metadata or Contextual Information Added Note any metadata added to
    support analysis:

Session name (e.g., â€œEducatorsâ€ vs. â€œPublic Health Professionalsâ€)
Discussion section (e.g., â€œChallenges,â€ â€œRecommendationsâ€) Participant
role or group designation 

Example: Added metadata fields to identify
Session Name, Participant Group (Educator/Public Health), and Discussion
Section (Barriers, Facilitators, Recommendations).

7.  Key Decisions Made During Cleaning Flag any important decisions that
    could impact analysis:

If you excluded any portions of text (e.g., off-topic discussions),
document what was excluded and why. If you made choices about retaining
or removing interruptions, overlapping speech, or non-verbal cues,
describe the rationale. If you generalized identifying details in ways
that may impact interpretation, note this. 

Example: Excluded
introductory small talk (greetings, logistics discussions) from the
analysis dataset. Retained overlapping speech where relevant to the
discussion. Generalized certain job titles to preserve anonymity (e.g.,
â€œHead Nurseâ€ changed to â€œMedical Staffâ€).

8.  Counts and Summaries Where Relevant When helpful, include counts
    that summarize:

How many identifiers were removed? How many sessions, speakers, or
responses are in the final dataset? If you organized by themes, how many
segments are in each theme? 

Example: Final cleaned dataset includes 8
focus groups, 42 participants, and 620 participant responses across
three discussion sections: Challenges (n = 220), Facilitators (n = 200),
and Recommendations (n = 200).

**[Tips for reporting qualitative data cleaning be transparent]{.teal-600}** 

- Even small decisions (e.g., standardizing speaker labels) can have big implications during analysis. If youâ€™re unsure whether to document something, document it!
- Take the perspective of your project lead or analyst. What decisions
might they need to revisit later? What context would help them
understand how the data were shaped?
- Support replicability and quality control. Your cleaning report should
make it easy for another team member to:
  - Understand what was done
  - Re-run the cleaning script 
  - Suggest or request changes with full knowledge of the process 
  
**[Example summary table to describe data cleaning for reporting]{.teal-600}**

| **Cleaning Step**       | **Action Taken**                                           | **Notes**                                     |
|--------------------------|------------------------------------------------------------|------------------------------------------------|
| **Anonymization**        | Removed names; replaced with Participant IDs (P01â€“P42).   | Locations and job titles generalized.          |
| **Speaker Labeling**     | Labeled as *Facilitator* or *Participant*.                | Consistent across all sessions.                |
| **Timestamps Removed**   | Deleted all timestamps (hh:mm:ss).                        |                                                |
| **Filler Words Removed** | Removed â€œum,â€ â€œuhâ€ except when indicating hesitation.     | Case-by-case review.                           |
| **Text Standardization** | Converted to lowercase; corrected major spelling errors.  | Preserved participant language and tone.       |
| **Metadata Added**       | Added session name, participant group, and discussion section. | Useful for subgroup analysis.              |
| **Exclusions**           | Removed introductions and off-topic discussions.          | Documented in the data log.                    |


## Terminology

ðŸ“ Relevant Terminology for Qualitative Data Cleaning in R 

ðŸ”§ Data Structure & Format Terms 

- Transcript: A written or typed record of spoken language from interviews, focus groups, or meetings. Transcripts may include speaker labels, timestamps, and other artifacts that need cleaning.
- Turn-Taking: Each time a participant or facilitator speaks is called a
"turn." Clean data often organize these turns into individual rows in a
dataset.
- Segment (or Excerpt): A portion of text, such as a paragraph, sentence,
or speaker turn, treated as a unit for coding or analysis. Segments are
often defined by the speaker's response or by topic.
- Tidy Data: Data where:
  - Each row represents a single observation (e.g., a speaker turn or
segment) 
  - Each column contains one type of information (e.g., speaker ID,
text, session group) 
  - Tidy data make it easier to manipulate, clean, and
analyze qualitative datasets in R. 
- Rectangular Data: Another term for a table or data frame, where rows and columns are used to organize data in R.

ðŸ—‚ï¸ Qualitative Metadata & Labeling Term

- Speaker Label: An identifier showing who is speaking (e.g., "Facilitator," "Participant 1"). Clean data should use consistent speaker labels.
- Participant ID: A unique identifier assigned to participants to protect
anonymity (e.g., "P01"). These are often used in place of names.
- Session ID/Group: The label identifying the specific interview or focus
group a participant was part of (e.g., "Session 1 â€“ Educators").
- Discussion Section/Topic Area: A label identifying a portion of the
conversation (e.g., "Barriers," "Recommendations") to help organize
qualitative data.

âœ‚ï¸ Data Cleaning & Transformation Terms 

- Anonymization/De-Identification: The process of removing or replacing personal
identifiers (e.g., names, locations, job titles) to protect participant
privacy.
- Standardization: Making text consistent in format (e.g., converting to
lowercase, consistent punctuation, spacing).
- Tokenization: (Optional depending on your analysis!) Breaking down text
into smaller partsâ€”words, sentences, or phrasesâ€”typically for text
mining. Not always part of standard qualitative coding workflows.
- Filtering: Removing unnecessary rows or segments (e.g., small talk,
off-topic responses) from the data.
- Recoding: Transforming data from one format to another (e.g.,
generalizing job titles or grouping participant roles).
- Join/Merge: Combining two datasets based on a shared key (e.g., merging
participant demographic info with transcripts).
- Pivoting: Restructuring data from wide format (many columns) to long
format (many rows), or vice versa, to make it easier to analyze or
display.

ðŸ·ï¸ Text Cleaning Terms

- Timestamps: Time markers in transcripts (e.g., [00:12:34]) that need to be removed unless necessary for the analysis.
- Filler Words: Common speech disfluencies (e.g., "um," "uh," "like") that
can be removed for clarity, depending on analysis goals.
- Inaudibles/Transcription Errors: Markers like â€œ[inaudible]â€ or machine
transcription errors that need to be corrected or flagged.
- Spelling and Grammar Standardization: Correcting spelling errors that
make text difficult to read, while preserving participant voice and tone
where relevant.

# Data cleaning procedures

The first step we'll need to take is to figure out what kind of document
you want to read into R.

## Reading your data into R

First, we'll need to read our data into R. Depending on how your raw
text is stored, you'll need to take various steps to read in your data
for analysis. The goal is to turn any of your text into a dataframe with
rows and columns of your text responses. In some cases, you may need to
keep participant ID columns or other columns if you're doing a
mixed-method analysis. In other cases, you may be analyzing different
focus groups and comparing them to eachother. Whatever you are doing,
make sure your dataframe is set up or your analysis. If you are unsure
about this, ask a member of Qual BPT for some help!

Here is an example of what your data may look like when you first read
it into R.

![](images/dirty_data.png)

and here's what we want it to look like (eventually) for most of our
analysis needs.

![](images/clean_data.png)

With clean data, we can:

-   Compare participants' responses across sessions and discussion
    sections. We could answer questions like:
    -   What did Educators say about Community Impact vs. Public
        Health?"
    -   What did participants across all interviews think about
        abatement funds?
-   Filter by participant role (e.g., facilitators vs. participants) for
    targeted analysis. We could answer questions like:
    -    How many participants mentioned that the county should invest
        in wraparound services across all interviews?
    -   What is the most common barrier in accessing services in the
        county?
-   Preserve anonymity by removing names and identifiers.

## Cleaning transcripts

One of the main forms of qualitative data we receive includes online transcripts. Below is a function you can use to clean your Zoom/Otter.ai transcripts and get them to a tidy format by entering the interviewer name(s), and key phrases used by the interviewer to mark the section of the discussion. For example, an interview might begin with an introduction, then include a discussion of barriers, and a discussion of strengths. We'll likely want to separate these out into sections so our analyses can speak to each section independent of each other, rather than be clumped altogether. 

This function works for Zoom transcripts that are saved as Word documents or .txt files. There are few things you need to specify in the function, including updating the file path, the interviewers, setting your list of questions, adding section labels, and the session name. 

```{r, echo = TRUE, eval=FALSE}

# youll need these libraries for this function:
library(tidyverse)
library(officer)
library(stringr)

# function to clean transcripts
clean_transcripts <- function(file_path,
                              file_type = c(".docx", ".txt"),
                              interviewers,
                              session_name) {

  file_type <- match.arg(file_type)

  # ================================
  # âœ… 1. Load transcript
  # ================================
  if (file_type == ".docx") {
    doc <- read_docx(file_path)
    text_data <- docx_summary(doc)
    df <- text_data %>%
      dplyr::select(line = doc_index, text)
  } else if (file_type == ".txt") {
    text_lines <- readLines(file_path, encoding = "UTF-8")
    df <- tibble(line = seq_along(text_lines), text = text_lines)
  } else {
    stop("Unsupported file type. Use '.docx' or '.txt'")
  }

  # ================================
  # âœ… 2. Classify speakers
  # ================================
  df <- df %>%
    mutate(
      speaker = case_when(
        str_detect(text, str_c(interviewers, collapse = "|")) ~ "interviewer",
        TRUE ~ "participant"
      )
    ) %>%
    filter(
      text != "",
      !str_detect(text, "^\\d+$"),
      !str_detect(text, "-->")
    )

  # ================================
  # âœ… 3. Extract and assign participant IDs
  # ================================
  unique_participants <- df %>%
    filter(speaker == "participant" & str_detect(text, ":")) %>%
    mutate(participant_name = str_extract(text, "^[^:]+")) %>%
    distinct(participant_name) %>%
    drop_na() %>%
    mutate(participant_id = paste0("P", row_number()))

  df <- df %>%
    mutate(
      participant_name = if_else(
        speaker == "participant" & str_detect(text, ":"),
        str_extract(text, "^[^:]+"),
        NA_character_
      )
    ) %>%
    left_join(unique_participants, by = "participant_name") %>%
    select(-participant_name)

  # ================================
  # âœ… 4. Detect section markers and extract section labels
  # ================================
  df <- df %>%
    mutate(
      question = if_else(str_detect(text, "\\[.*\\]"), 1L, 0L),
      section_label_raw = if_else(
        question == 1L,
        str_extract(text, "\\[(.*?)\\]"),
        NA_character_
      )
    ) %>%
    mutate(
      section_label_clean = str_remove_all(section_label_raw, "\\[|\\]")
    )

  # ================================
  # âœ… 5. Remove text before the first question
  # ================================
  first_question_line <- min(df$line[df$question == 1], na.rm = TRUE)

  if (!is.finite(first_question_line)) {
    stop("âŒ No questions (section markers) detected in brackets!")
  }

  df <- df %>%
    filter(line >= first_question_line)

  # ================================
  # âœ… 6. Fill forward the section labels
  # ================================
  df <- df %>%
    arrange(line) %>%
    tidyr::fill(section_label_clean, .direction = "down") %>%
    mutate(
      section = as.numeric(factor(section_label_clean))
    )

  # ================================
  # âœ… 7. Create original_text (remove speaker name only)
  # ================================
  df <- df %>%
    mutate(
      original_text = str_remove(text, ".*?:\\s*")  # Remove everything before the colon
    )

  # ================================
  # âœ… 8. Clean the `text` column for analysis
  # ================================
  df <- df %>%
    mutate(
      text = iconv(original_text, from = "UTF-8", to = "ASCII//TRANSLIT"),
      text = tolower(text),
      text = str_replace_all(text, "[^a-zA-Z0-9\\s]", "")  # Remove special characters
    )

  # ================================
  # âœ… 9. Filter out section label rows (optional)
  # ================================
  df <- df %>%
    filter(question != 1L)

  # ================================
  # âœ… 10. Filter out interviewer lines (optional)
  # ================================
  df <- df %>%
    filter(speaker != "interviewer") %>%
    mutate(session = session_name)

  # ================================
  # âœ… 11. Return final dataframe
  # ================================
  final_df <- df %>%
    select(
      line,
      speaker,
      participant_id,
      section,
      section_label = section_label_clean,
      text,           # cleaned lowercase version
      original_text,  # original casing/punctuation minus speaker name
      session
    )

  return(final_df)
}

```

The example below comes from the Loudoun County Opioid Abatement project where Shon, Lindsay, Hannah, Luke, Eden, and Arden are staffed, so any of them could have been an interviewer. 

### Instructions

1. Open the listening session slides/guide/questions that correspond to the session to make sure we know the order of the discussion.
2. Open the listening session transcript. If it is a .vtt file, save it as a .txt or .docx and open the new .txt/.docx file. 
3. Identify which sections are present from the session out of the following list of section labels. If there is a slide that is unique to a single session then it will not be included in the list below. For example, the public safety session had a slide about "public safety in the community" that other sessions did not have. In this case, I added a unique section label to mark this section.  

-   [Data check]
-   [Community impact]
-   [Abatement funds]
-   [Prevention and harm reduction]
-   [Treatment and recovery]
-   [Other strategies]
-   [Vision for the future]
-   [Next steps]

4. Add the section labels where relevant in the transcript. For example, when you see in the transcript something that marks the beginning of the data checks slide, you would add above that line "[Data check]". Importantly, note that:
-   You do not need to add any section labels before the [Data check] label. This will be our first one.
-   Section labels should be on their own line and spelled exactly as the labels above, including the brackets []. This is important because our cleaning function searches for brackets!
-   Please do not edit the raw text- you are adding new lines with the section labels, not changing anything in the text.
-   Not all sections are in the same order across the sessions (e.g., sometimes treatment and recovery were discussed before prevention and harm reduction) so carefully skim through the transcript to identify the order (this should also align with the order of the deck which is helpful to have open at the same time)

5. Save the file (.docx or .txt) with the section labels included.

6. Copy and paste the example chunk below and edit the code to fit your session parameters. 

7. Run the chunk and check that all sections of the session are shown.

8. If everything looks ok, add your dataframe to the R chunk labeled ```{r bind all data together}.

9. Run the whole script below and check the "cleaned_text" dataframe. 

```{r, echo=TRUE, eval=FALSE}
# %%%%%%%%%%%%%%%%%%% List interviewer names %%%%%%%%%%%%%%%%%%%
interviewers <- c("Shon Reed", 
                  "Lindsay Houston",
                  "Hannah Lunkenheimer",
                  "Luke Saunders",
                  "Eden Griffin",
                  "Sam Barron",
                  "Arden Trewartha")
```

```{r, echo=TRUE, eval=FALSE}
# %%%%%%%%%%%%%%%%%%%%%%% EXAMPLE %%%%%%%%%%%%%%%%%%%%%%%

# public safety session
ps_df <- clean_transcripts( # relabel the dataframe something meaningful - like ps_df stands for public safety dataframe
  file_path = "../../../data_collection/Listening Sessions/Transcripts/Public Safety Transcript.txt", # add your transcript file here- you should only need to change out the last part!
  file_type = ".txt", # specify whether you have a .txt or .docx file
  interviewers = interviewers,
  session_name = "public safety" # add a session name
)

ps_df %>% 
  select(section_label) %>%
  unique()
```

```{r, echo=TRUE, eval=FALSE}
#education 2
edu2_df <- clean_transcripts( # relabel the dataframe something meaningful - like ps_df stands for public safety dataframe
  file_path = "../../../data_collection/Listening Sessions/Transcripts/Education 2 Listening Session file.txt", # add your transcript file here- you should only need to change out the last part!
  file_type = ".txt", # specify whether you have a .txt or .docx file
  interviewers = interviewers,
  session_name = "education" # add a session name
)

edu2_df %>% 
  select(section_label) %>%
  unique()
```

```{r, echo=TRUE, eval=FALSE}

# education
ed_df <- clean_transcripts(
  file_path      = "../../../data_collection/Listening Sessions/Transcripts/Education Listening Session Transcript.docx",
  file_type      = ".docx",
  interviewers   = interviewers,
  session_name   = "education"
)

ed_df %>% 
  select(section_label) %>%
  unique()
```

```{r bind all data together, echo=TRUE, eval=FALSE}
#####################
# 3) Combine all data
#####################
cleaned_text <- dplyr::bind_rows(
  # add your new dataframe here to this list
  ed_df,
  edu2_df,
  ps_df)

cleaned_text <- cleaned_text %>%
  select(-section, -speaker)
```

```{r, echo=TRUE, eval=FALSE}
write_rds(cleaned_text, file = "data_clean/text_data_clean.rds")
```

<!-- And when you want to clean the transcripts and mark the interviewer, you can add the names of the interviewers here.  -->

<!-- In the case where an interviewer asks a question an exact way, we can enter the question as it is listed on the interview guide. However, this is not always the best way to run an interview when you're following a more relaxed vibe. So, it may be helpful to have the interview guide (or deck, whatever the interviewer used to facilitate the discussion) and the transcript opened to identify the order of discussion and section labels, and to identify where those key markers of the text are going to identify your questions.  -->

<!-- What is a good example of a question list if the interviewer did not read the question verbatim? Let's imagine the first question listed on the interview guide is "What kinds of barriers do you think prevent community members from accessing services in the county?".  -->

<!-- Bad example: "accessing services" this is a bad example because this phrase has been marked as an identifier for a question, so any instance of "accessing services" comes up will count the phrase as a question. -->

<!-- Good example: "barriers do you think prevent community members from accessing services" it is less likely for someone to have used this exact string of words in the conversation, so we're safe to mark this as a question identifier.  -->

## Other text file types

### PDFs

```{r, echo=TRUE, eval=FALSE}
library(pdftools)
library(tibble)
library(dplyr)

# Define the folder where PDFs are saved
folder_path <- "path/to/your/pdf/folder"

# List all PDF files in the folder
pdf_files <- list.files(folder_path, pattern = "\\.pdf$", full.names = TRUE)

pdf_data <- pdf_files %>%
  map_df(~ tibble(
    file = basename(.x),           # Extract file name only
    text = paste(pdf_text(.x), collapse = " ")  # Merge all pages into one text block
  ))

# View the cleaned data
print(pdf_data)

pdf_data <- pdf_data %>%
  mutate(text = str_replace_all(text, "\\s+", " "))  # Remove extra spaces/newlines

print(pdf_data)


```

### Excel sheets

Of course, we also tend to ask qualitative questions in some of our surveys at Omni, and these types of data should be read in like quantitative data and should already be in a clean format if you follow the data cleaning guide (insert link to data cleaning guide).

## QA Checklist for Qual Cleaning

[ ] Are participant and interviewer roles correctly labeled?\
[ ] Have names, locations, and job titles been de-identified?\
[ ] Are timestamps removed (unless needed for analysis)?\
[ ] Are discussion sections correctly labeled?\
[ ] Has text been standardized (case, punctuation, spacing)?\
[ ] Is the cleaned dataset in a tidy format (one speaker turn per row)?\
[ ] Has the cleaned dataset been reviewed by another team member?\

## Terminology {.unnumbered}

Before starting your pre-processing and analysis, itâ€™s important to
understand a few core terms. These concepts are essential for working
with text data and deciding on the appropriate pre-processing and
analysis steps.

| **Term** | **Definition** |
|-----------------------|-------------------------------------------------|
| Tokenization | Breaking text into units (words, phrases, sentences) |
| Stemming | Reducing words to their root (e.g., "running" â†’ "run") |
| Lemmatization | Reducing to dictionary form (e.g., "better" â†’ "good") |
| Stop Words | Common words often removed (e.g., "the", "and") |
| Document-Term Matrix | Table of word frequencies across documents |
| TF-IDF | Term importance based on frequency and inverse document frequency |
| Dataset | Collection of text documents as one dataset |
| Dictionary | List of keywords/phrases used to code or categorize text |

```{r, echo=TRUE}
# Load all packages 
library(tidyverse)
library(tidytext)
library(quanteda)
library(textstem)
library(sentimentr)
library(topicmodels)
library(flextable)
library(knitr)
library(omni)

```

```{r, include=TRUE}
# Create a fake, tidy qualitative dataset
text_data <- tibble(
  line = 1:10,
  speaker = c("interviewer", "participant", "participant", "interviewer", "participant",
              "participant", "interviewer", "participant", "participant", "participant"),
  participant_id = c("I1", "P1", "P2", "I1", "P1", "P2", "I1", "P1", "P2", "P1"),
  question = c(1, 0, 0, 1, 0, 0, 1, 0, 0, 0),
  section = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 3),
  section_label = c("Introduction", "Introduction", "Introduction", "Barriers", 
                    "Barriers", "Barriers", "Recommendations", "Recommendations", 
                    "Recommendations", "Recommendations"),
  text = c(
    "Can you tell me about your experience accessing services in the county?",
    "Sure, I think one of the biggest challenges is transportation in Travis County. There are many people here who do not own their own cars which makes it difficult to access any type of treatment services. On top of that, the buses are never on time so people have to do a lot of planning ahead of time to get to their appointment.",
    "I agree, especially for people in rural areas. It's hard to get to services.",
    "What kinds of barriers do you see in your community?",
    "Travis county definitely has a lack of awareness about available programs.",
    "Also, the application process is confusing and time-consuming. The health administrative offices used to post the applications at midnight and they would take new clients on a rolling basis, so by the time it was morning all applications would be filled.",
    "What are your recommendations for improving access?",
    "More outreach and education campaigns would help Travis county residents, rather than wasting time on trying to get policy changes.",
    "Simplifying the application process would make a big difference.",
    "Providing transportation vouchers could also improve access."
  ),
  session = c(rep("Education", 5), rep("Public Health", 5))
) %>% 
  mutate(text = tolower(text),
         text = str_replace_all(text, "[^a-zA-Z0-9\\s]", ""))

text_data <- text_data %>% 
  filter(speaker != "interviewer")
```

Pre-processing prepares your qualitative data for analysis by
**cleaning**, **organizing**, and **standardizing** text. This step
ensures the data is usable for word frequency, sentiment analysis, topic
modeling, and other text mining techniques.

You should always assess the **scope and quality** of your data first:

-   Are the data cleaned (lowercase, removed participant names,
    punctuation, symbols)? 

-   How much text do you have? (Word counts per document/response.)

-   How many participants contributed?

-   How detailed or shallow are the responses?

-   Whose voices are you analyzing?

Once you understand your data, you can decide which pre-processing steps
are appropriate.

## Tokenization {.unnumbered}

Tokenization breaks text into individual piecesâ€”usually words, but
sometimes phrases or sentences.

-   Most text mining techniques require tokenized text.

-   This is common for word frequency analysis, sentiment analysis, and
    topic modeling.

-   After tokenization, we lose the flow of sentences which is generally
    okay for some analyses, but not for narrative analysis or content
    analysis.

```{r, include=TRUE}
# %%%%%%%%%%%%%%% Tokenize text %%%%%%%%%%%%%%%

# Tokenize text
tokenized_text <- text_data %>% 
  unnest_tokens(word, text)

```

**What are Stop Words?**

Stop words are common words like "the", "and", "but" that donâ€™t add much
meaning on their own. Because we want to focus on broader themes from
our participants' voices, we usually want to remove stop words after
text is tokenized. This process allows us to focus on content-rich
words, like nouns and verbs. We should remove stop words when running a
word frequency analysis, topic modeling, or sentiment analysis.

We can also create custom stop words that we want to remove from our
analyses, for example, location names or project-specific words that
appear frequently but arenâ€™t relevant to the analysis.

**Example:**

-   In the example below, my custom stop words are "travis" and
    "county", and they're added to the stop_words bank which includes
    other words like "but", "is", "the", etc. If you'd like to see all
    of the stop words, see View(stop_words).

```{r, echo=TRUE}
# %%%%%%%%%%%%%%% Stop words %%%%%%%%%%%%%%%

# Use standard stop words + custom ones (e.g., counties, names)
my_stop_words <- bind_rows(stop_words, 
                           data.frame(word = c("travis", 
                                               "county"), lexicon = "custom"))

cleaned_text <- tokenized_text %>% 
  anti_join(my_stop_words, by = "word")

```

## Stemming {.unnumbered}

Stemming words cuts them down to their root forms (e.g., "running"
becomes "run"). This pre-processing step should primarily be used for
topic modeling or for other analyses that you decide that exact word
form isnâ€™t critical. This step is recommended to use with larger
datasets, with typically hundreds of documents or more, but for our
purposes we recommend stemming any time you have enough data for topic
modeling (around 5,000 total words).

```{r, echo=TRUE}
# %%%%%%%%%%%%%%% Stemming %%%%%%%%%%%%%%%

library(textstem)

stemmed_text <- cleaned_text %>%
  mutate(stem_word = stem_words(word))
```

## Lemmatization {.unnumbered}

Lemmatization converts words to their dictionary root and keeps the
words readable to the user (e.g., "better" becomes "good"). This
pre-processing step should be used for word frequency analysis,
sentiment analysis, or thematic/content analysis as it works will with
small and large datasets.

```{r, echo=TRUE}

# %%%%%%%%%%%%%%% Lemmatization %%%%%%%%%%%%%%%

lemmatized_text <- cleaned_text %>% 
  mutate(lem_word = lemmatize_words(word))

```

Let's compare the stem words, vs lemmatized words against the original
tokenized words:

```{r, echo=TRUE}
compare_words <- cleaned_text %>% 
  left_join(stemmed_text, 
            by = join_by(line, 
                         speaker, 
                         participant_id, question, section, section_label,
                         session, word)) %>% 
  left_join(lemmatized_text,
            by = join_by(line, 
                         speaker, 
                         participant_id, question, section, section_label,
                         session, word)) %>%
  slice(1:10) %>%
  kable()
```

```{r, echo=TRUE}
compare_words
```

```{r, echo=TRUE}
# create a data frame for the table
comparison_table <- data.frame(
  "Stemming" = c(
    "You need speed over accuracy",
    "Working with large datasets",
    "Basic information retrieval tasks",
    "Search engines or topic modeling where fine detail isn't critical",
    "Not concerned about human readability"
  ),
  "Lemmatization" = c(
    "Slower but more accurate",
    "Better for small datasets",
    "Better for nuanced analysis",
    "Better for in-depth analysis",
    "Maintains readable words)"
  )
)

kable(comparison_table,
      caption = "When to Use Stemming vs. Lemmatization",
      align = 'll')

```

