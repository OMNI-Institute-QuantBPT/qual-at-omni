---
title: Data Cleaning
toc-depth: 2
---

```{r packages, echo=FALSE}
library(tidyverse)
library(omni)
library(flextable)
library(janeaustenr) # jane austen books

text <- austen_books()
```

Manager's Summary

Data Cleaner's Summary

## Introduction

**Do not share this guide outside of Omni**

Data cleaning is often one of the first things you will do when you
start working with qualitative data at Omni. Whether weâ€™re working with
interview transcripts, focus group discussions, or open-ended survey
responses, the raw data we receive is rarely ready for immediate
analysis. Cleaning is not just about tidying up; itâ€™s about making
informed decisions that clarify the meaning and integrity of the data
while preparing it for systematic analysis.

The decisions we make during the cleaning process are every bit as
complex and impactful as those made during coding and analysis.
Thoughtful data cleaning can preserve the richness of qualitative data,
while careless decisions can distort or diminish participants' voices.
Therefore, it is especially important to have a strong set of working
principles to guide your decisions when cleaning qualitative data.

This guide covers a general approach to qualitative data cleaning, with
an emphasis on useful R packages and functions designed to conquer some
common challenges. While this guide includes tools and code to make your
life easier, it also offers guidelines for making judgment calls about
what to remove, retain, or clarify in the data.

The steps in a qualitative data cleaning process will always be informed
by two key factors:

1)  **The state of the data when we (Omni) receive it**

-   For example, some transcripts may come from automated services (like
    Zoom or Otter.ai) and contain timestamps, speaker labels, or filler
    words that require removal. Others may be professionally transcribed
    and need minimal cleaning.

2)  **The specific needs of the project** 
-   Because of this variability,
    we encourage a flexible, judgment-driven approach to data cleaning.
    The steps described in this guide are common to many projects, but
    their order and application should be tailored to the needs of the
    dataset and the analytic goals of the project. Importantly,
    depending on the type of analysis, different cleaning steps may be
    required. Consult the analysis plan and research questions in your
    project materials to verify the needs of the project.

## Rationale

When we clean qualitative data, we apply a series of thoughtful transformations that make the data clearer, more consistent, and usable
for analysis. Qualitative data cleaning requires attention to detail and
sensitivity to the context in which the data were collected. The
procedures we use need to be flexible because the downstream purposes of
the data can vary from project to project, whether for thematic coding,
content analysis, or mixed-methods integration.

The qualitative data cleaner often has to make many judgment calls
during this process. These decisions are guided by the projectâ€™s goals,
the nature of the source data, team experience, and guidance documents
(like this one). Every decision and its rationale should be clearly
documented in the data cleaning script or data log (more on that below).
Transparency in this process ensures that the cleaned dataset remains
trustworthy and aligned with our ethical standards for qualitative
research.

Qualitative data cleaning requires a lot of careful thought and
attention. The R code that cleans text data needs to be clearly written
and well-commented, not only for reproducibility but to ensure that
meaning is preserved, and participant voices are not inadvertently
altered or diminished. In qualitative work, the cleaning process can
directly impact the integrity of the analysis.

Just as with quantitative analysis, qualitative data-cleaning decisions
are made with greater ease and clarity when there is a clear work plan,
guided by the projectâ€™s research questions or evaluation goals. Having a
shared understanding of what the team hopes to explore in the data helps
inform:

- What should be cleaned
- What should be preserved (even if messy)
- What should be flagged for discussion 

Two especially helpful documents to have before qualitative data cleaning begins are:

- A **[codebook](codebook.qmd)** (or at least a data dictionary). This helps ensure consistency in how we treat things like speaker names, special terminology, or
sensitive content. 
- A **[data analysis plan](https://omniinstitute.atlassian.net/wiki/spaces/Quant/pages/375226966/Guide+for+data+analysis+plans)**. This outlines the teamâ€™s
approach to coding and analysis and helps identify if additional
cleaning steps are necessary. For example: anonymizing sensitive details
or removing artifacts from automated transcription tools (timestamps,
filler words, etc.). 

Whenever possible, we expect teams to develop a data analysis plan and request any available data dictionaries or
codebooks from the client or partner organizations who collected the
data. However, you may need to create a codebook if one doesnâ€™t
existâ€”feel free to reach out to the QualBPT (or whichever team you want
to point folks to) if you need support.

In many cases, the people drafting the analysis plan are different from
those cleaning the qualitative data, so strong cross-team communication
is essential. We recommend including the qualitative data cleaner (or
cleaning team) in project discussions as early as possible. When
drafting the analysis plan, think through what text cleaning steps will
be necessary to make the data usable for coding, protect participant
confidentiality, and meet the projectâ€™s goals.

Finally, whether youâ€™re writing code for qualitative data cleaning or
any other purpose, always write your R scripts as if they will later be:

-   Heavily scrutinized
-   Held up as example code
-   Modified by someone brand new to both R and the project

Make it easy on future Omni-itesâ€”and on your future self!

## When are data clean?

**What Does It Mean to Have "Clean" Qualitative Data?**
- For there to be project tasks that direct Omni-ites to â€˜clean qualitative data,â€™ and a
guide to help in doing so, there should also be a shared understanding
of what it means for qualitative data to be clean.

**Definition of Clean Qualitative Data**
- At Omni, qualitative data are
considered clean when they are organized, de-identified, and ready for
analysis or coding.

That means the data:
- Accurately reflect the original source material (e.g., interviews, focus
groups, or open-text survey responses) Have been transformed into a
structure that makes them easy to navigate and analyze Protect the
privacy and confidentiality of participants Are consistent, clear, and
free of irrelevant clutter (like transcription artifacts) 

**What Makes a Qualitative Dataset "Analysis-Ready"?**

- For qualitative text data to be ready for analysis, they should meet the following criteria:

1) Speaker Information Is Clear and Consistent

- Participant speakers and interviewers are clearly labeled in the data.
- Each speakerâ€™s text is grouped logically into segments, preserving
conversational flow. 

2) Participant Identifiers Are Specified and Protected

- Real names, locations, and other direct identifiers have been removed or
replaced with participant IDs or pseudonyms. 
- Confidential information (e.g., agency names, job titles, organizations) is anonymized where necessary, following Omniâ€™s confidentiality guidelines. 

3) Questions Are Clearly Distinguished From Responses

- Interviewer questions (or prompts) are labeled or separated from
participant responses, as appropriate. This can be done by adding
question text as its own field in the dataset or by adding markers in
the transcript. 

4) Text Segments Are Ordered and Organized

- The transcript text is ordered according to the flow of conversation.
Segments are correctly time-sequenced (even if timestamps themselves are
removed). 

5) Text Is Structured Into a Tidy, Rectangular Format

- Each row represents a single speaker turn or unit of analysis (e.g., a
complete response to a question). 
- Data are stored in a rectangular table (data frame), with columns for: 
  - Session name or group (e.g., "Educators" or "Public Health")
  - Participant ID or role (e.g., "Participant 1", "Facilitator")
  - Text segment (the response or comment)
  - Any relevant metadata (e.g., discussion section, date) 
  - Transcription
  
6) Artifacts Are Removed

- All timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless
specifically required for analysis. 
- Automated transcription quirks
(e.g., repeated words, filler words, auto-captions like â€œ[inaudible]â€)
are reviewed, cleaned, or flagged. 

7) Text Is Consistent in Style and Format

- All text is converted to lowercase, unless case is important for
analysis. 
- Spelling errors are corrected when they obscure meaning (but
regional spellings or participant quirks may be preserved if relevant).
- Punctuation and spacing are standardized (no excessive whitespace,
missing periods, etc.). 

8) Relevant Identifiers Are Added to the Dataset

- If there are multiple sessions or groups, these are labeled (e.g.,
"Educators," "Public Health"). 
- If there are themes or discussion
sections (e.g., "Challenges," "Recommendations"), these are identified.
- If codes are pre-assigned for analytic purposes (e.g.,
â€œPre-implementation,â€ â€œPost-implementationâ€), they are included in the
data structure. 

**How Do We Know When Qualitative Data Are Clean?**

Here are some guiding questions to help determine when qualitative data are
ready for analysis (i.e., clean):

- What is the plan for coding or analyzing this data?

- The analysis plan (or coding framework) should inform cleaning
decisions. For example, if the team plans to do thematic coding, theyâ€™ll
need text organized into meaningful speaker turns or responses. What
needs to be anonymized?

- Identify any sensitive information that must be redacted or replaced to
maintain confidentiality and ensure participant privacy. Are speaker
turns properly attributed and easy to follow?

- Each speakerâ€™s contributions should be clearly labeled, consistently
formatted, and grouped logically. Are responses to specific questions
clearly identifiable?

- If interviews or focus groups follow a semi-structured guide, itâ€™s
important to separate questions from responses for clarity in analysis.
Is the structure of the data appropriate for the analytic tool?

- If the data are being uploaded to Dedoose, NVivo, or another platform,
they should follow the required format (e.g., tidy data frame with
speaker IDs and group names). Have all unnecessary artifacts been
removed?

- Time stamps, filler words, and transcription errors that donâ€™t add value
to the analysis should be removed. Has the cleaned data been reviewed by
someone else (QA check)?

- Whenever possible, have another Omni-ite review the cleaned data for
accuracy and completeness. 

**Common Issues to Discuss Early in the Cleaning Process**

Just like in quantitative data cleaning, clarifying
expectations at the start of a project will save time later. For
qualitative projects, consider these:

- Will we analyze both facilitator questions and participant responses, or
just participant responses? 
- How will we handle overlapping speech, interruptions, or incomplete thoughts? 
- Do we need to standardize participant roles (e.g., "Public Health Official" vs. "PH Staff") for consistency? 
- Are we preparing data for manual coding or automated text
analysis? 
- Do we need to translate or transcribe non-English responses?
- Do we need to connect text segments with broader context, such as the
discussion theme or section of the focus group? 

**Quick Summary of "Clean Qualitative Data" at Omni: Clean qualitative data are:**

- Anonymized 
- Clearly structured and labeled 
- Organized for easy analysis
- Free of unnecessary artifacts 
- Ready for use in coding and interpretation

## How do I report the results of data cleaning?

ðŸ“ How to Report the Results of Qualitative Data Cleaning at Omni
Cleaning qualitative data is an interpretive and decision-heavy process,
and those decisions need to be transparent. Reporting your cleaning
process helps:

Project leads understand whatâ€™s been done and why. Provide documentation
in case changes need to be made later. Build trust in the integrity of
the cleaned dataset. Support future qualitative coding, interpretation,
and reporting. Qualitative data cleaning produces resultsâ€”changes to the
text or data structureâ€”that should be documented in a clear, shareable
data cleaning report.

ðŸ“‹ What to Include in a Qualitative Data Cleaning Report 1. Summary of
the Dataset You Cleaned Start with an overview:

How many transcripts or files were cleaned? How many sessions (e.g.,
focus groups, interviews) are included? What types of participants are
represented (e.g., educators, public health professionals)? Example:
This dataset includes transcripts from 8 focus groups, with 42
participants. Participants represent two stakeholder groups: Educators
(n = 20) and Public Health Professionals (n = 22).

2.  Anonymization and De-Identification Steps Document what you removed
    or replaced to protect confidentiality.

Were participant names replaced with IDs (e.g., Participant 01)? Were
organizations, locations, or personal identifiers removed or redacted?
Were job titles generalized (e.g., â€œCEOâ€ changed to â€œsenior leaderâ€)?
Example: Replaced all participant names with Participant IDs (e.g.,
P01). Removed specific references to organizations and locations (e.g.,
â€œat Boulder Community Hospitalâ€ becomes â€œat [hospital]â€). Redacted job
titles for anonymity when mentioned alongside unique organizations.

3.  Speaker Labeling and Text Structuring Describe how speakers were
    labeled and how the transcript was organized.

Were speakers consistently labeled as "Participant" and "Facilitator"?
Was each speaker turn separated into its own row or segment? Were
questions separated from responses? Example: Speaker turns were labeled
consistently as either Facilitator or Participant. Each speaker turn is
stored as one row in the cleaned dataset, with associated metadata
(Session name, Speaker role, Discussion section).

4.  Artifacts Removed (Timestamps, Filler Words, etc.) Note what
    transcription artifacts were removed or edited:

Were timestamps deleted? Were filler words (e.g., â€œum,â€ â€œuhâ€) removed?
If so, specify whether this was systematic or case-by-case. Were
transcription errors corrected? Example: Removed all timestamps in the
format [hh:mm:ss]. Deleted common filler words (â€œum,â€ â€œuhâ€) unless they
contributed to participant meaning or tone. Reviewed and corrected
auto-transcription errors (e.g., â€œDodooseâ€ corrected to â€œDedooseâ€).

5.  Text Standardization and Formatting Summarize standardization steps
    for readability and consistency:

Was text converted to lowercase? Was spelling corrected? If so, did you
preserve participant colloquialisms? Were consistent punctuation and
spacing applied? Example: Converted all text to lowercase for
consistency. Standardized punctuation (e.g., added periods to sentence
ends where missing). Corrected spelling errors that obscured meaning but
preserved participant vernacular and tone where appropriate.

6.  Metadata or Contextual Information Added Note any metadata added to
    support analysis:

Session name (e.g., â€œEducatorsâ€ vs. â€œPublic Health Professionalsâ€)
Discussion section (e.g., â€œChallenges,â€ â€œRecommendationsâ€) Participant
role or group designation Example: Added metadata fields to identify
Session Name, Participant Group (Educator/Public Health), and Discussion
Section (Barriers, Facilitators, Recommendations).

7.  Key Decisions Made During Cleaning Flag any important decisions that
    could impact analysis:

If you excluded any portions of text (e.g., off-topic discussions),
document what was excluded and why. If you made choices about retaining
or removing interruptions, overlapping speech, or non-verbal cues,
describe the rationale. If you generalized identifying details in ways
that may impact interpretation, note this. Example: Excluded
introductory small talk (greetings, logistics discussions) from the
analysis dataset. Retained overlapping speech where relevant to the
discussion. Generalized certain job titles to preserve anonymity (e.g.,
â€œHead Nurseâ€ changed to â€œMedical Staffâ€).

8.  Counts and Summaries Where Relevant When helpful, include counts
    that summarize:

How many identifiers were removed? How many sessions, speakers, or
responses are in the final dataset? If you organized by themes, how many
segments are in each theme? Example: Final cleaned dataset includes 8
focus groups, 42 participants, and 620 participant responses across
three discussion sections: Challenges (n = 220), Facilitators (n = 200),
and Recommendations (n = 200).

ðŸ’¡ Tips for Reporting Qualitative Data Cleaning Be Transparent Even
small decisions (e.g., standardizing speaker labels) can have big
implications during analysis. If youâ€™re unsure whether to document
something, document it!

Take the Perspective of Your Project Lead or Analyst What decisions
might they need to revisit later? What context would help them
understand how the data were shaped?

Support Replicability and Quality Control Your cleaning report should
make it easy for another team member to:

Understand what was done Re-run the cleaning script Suggest or request
changes with full knowledge of the process ðŸ–¼ï¸ Example Summary Table in a
Qualitative Cleaning Report Cleaning Step Action Taken Notes
Anonymization Removed names, replaced with Participant IDs (P01-P42)
Locations and job titles generalized Speaker Labeling Labeled as
Facilitator or Participant Consistent across all sessions Timestamps
Removed Deleted all timestamps (hh:mm:ss)\
Filler Words Removed "um," "uh" except when indicating hesitation
Case-by-case review Text Standardization Converted to lowercase,
corrected major spelling errors Preserved participant language/tone
Metadata Added Session name, participant group, discussion section
Useful for subgroup analysis Exclusions Removed introductions, off-topic
discussions Documented in the data log

## Terminology

ðŸ“ Relevant Terminology for Qualitative Data Cleaning in R ðŸ”§ Data
Structure & Format Terms Transcript A written or typed record of spoken
language from interviews, focus groups, or meetings. Transcripts may
include speaker labels, timestamps, and other artifacts that need
cleaning.

Turn-Taking Each time a participant or facilitator speaks is called a
"turn." Clean data often organize these turns into individual rows in a
dataset.

Segment (or Excerpt) A portion of text, such as a paragraph, sentence,
or speaker turn, treated as a unit for coding or analysis. Segments are
often defined by the speaker's response or by topic.

Tidy Data Data where:

Each row represents a single observation (e.g., a speaker turn or
segment) Each column contains one type of information (e.g., speaker ID,
text, session group) Tidy data make it easier to manipulate, clean, and
analyze qualitative datasets in R. Rectangular Data Another term for a
table or data frame, where rows and columns are used to organize data in
R.

ðŸ—‚ï¸ Qualitative Metadata & Labeling Terms Speaker Label An identifier
showing who is speaking (e.g., "Facilitator," "Participant 1"). Clean
data should use consistent speaker labels.

Participant ID A unique identifier assigned to participants to protect
anonymity (e.g., "P01"). These are often used in place of names.

Session ID / Group The label identifying the specific interview or focus
group a participant was part of (e.g., "Session 1 â€“ Educators").

Discussion Section / Topic Area A label identifying a portion of the
conversation (e.g., "Barriers," "Recommendations") to help organize
qualitative data.

âœ‚ï¸ Data Cleaning & Transformation Terms Anonymization /
De-Identification The process of removing or replacing personal
identifiers (e.g., names, locations, job titles) to protect participant
privacy.

Standardization Making text consistent in format (e.g., converting to
lowercase, consistent punctuation, spacing).

Tokenization (Optional depending on your analysis!) Breaking down text
into smaller partsâ€”words, sentences, or phrasesâ€”typically for text
mining. Not always part of standard qualitative coding workflows.

Filtering Removing unnecessary rows or segments (e.g., small talk,
off-topic responses) from the data.

Recoding Transforming data from one format to another (e.g.,
generalizing job titles or grouping participant roles).

Join / Merge Combining two datasets based on a shared key (e.g., merging
participant demographic info with transcripts).

Pivoting Restructuring data from wide format (many columns) to long
format (many rows), or vice versa, to make it easier to analyze or
display.

ðŸ·ï¸ Text Cleaning Terms Timestamps Time markers in transcripts (e.g.,
[00:12:34]) that need to be removed unless necessary for the analysis.

Filler Words Common speech disfluencies (e.g., "um," "uh," "like") that
can be removed for clarity, depending on analysis goals.

Inaudibles / Transcription Errors Markers like â€œ[inaudible]â€ or machine
transcription errors that need to be corrected or flagged.

Spelling and Grammar Standardization Correcting spelling errors that
make text difficult to read, while preserving participant voice and tone
where relevant.

# Data cleaning procedures

The first step we'll need to take is to figure out what kind of document
you want to read into R.

## Reading your data into R

First, we'll need to read our data into R. Depending on how your raw
text is stored, you'll need to take various steps to read in your data
for analysis. The goal is to turn any of your text into a dataframe with
rows and columns of your text responses. In some cases, you may need to
keep participant ID columns or other columns if you're doing a
mixed-method analysis. In other cases, you may be analyzing different
focus groups and comparing them to eachother. Whatever you are doing,
make sure your dataframe is set up or your analysis. If you are unsure
about this, ask Hannah or a member of Qual BPT for some help!

Here is an example of what your data may look like when you first read
it into R.

![](images/dirty_data.png)

and here's what we want it to look like (eventually) for most of our
analysis needs.

![](images/clean_data.png)

With clean data, we can:

-   Compare participants' responses across sessions and discussion
    sections. We could answer questions like:

    -   What did Educators say about Community Impact vs. Public
        Health?"

    -   What did participants across all interviews think about
        abatement funds?

-   Filter by participant role (e.g., facilitators vs. participants) for
    targeted analysis. We could answer questions like:

    -    How many participants mentioned that the county should invest
        in wraparound services across all interviews?

    -   What is the most common barrier in accessing services in the
        county?

-   Preserve anonymity by removing names and identifiers.

### Zoom transcripts

One of the main forms of qualitative data we receive includes Zoom transcripts. Below is a function you can use to clean your Zoom transcripts and get them to a tidy format by entering the interviewer name(s), and key phrases used by the interviewer to mark the section of the discussion. For example, an interview might begin with an introduction, then include a discussion of barriers, and a discussion of strengths. We'll likely want to separate these out into sections so our analyses can speak to each section independent of each other, rather than be clumped altogether. 

```{r, echo = TRUE}

# youll need these libraries for this function:
library(tidyverse)
library(officer)
library(stringr)

clean_transcript <- function(file_path,
                             file_type = c(".docx", ".txt"),
                             interviewers,
                             question_list,
                             section_labels,
                             session_name) {
  
  # Match file_type argument
  file_type <- match.arg(file_type)
  
  # ================================
  # âœ… 1. Load transcript based on file_type
  # ================================
  if (file_type == ".docx") {
    doc <- read_docx(file_path)
    text_data <- docx_summary(doc)
    df <- text_data %>%
      dplyr::select(line = doc_index, text)
  } else if (file_type == ".txt") {
    text_lines <- readLines(file_path, encoding = "UTF-8")
    df <- tibble(line = seq_along(text_lines), text = text_lines)
  } else {
    stop("Unsupported file type. Use '.docx' or '.txt'")
  }

  # ================================
  # âœ… 2. Classify speaker: interviewer vs participant
  # ================================
  df <- df %>%
    mutate(
      speaker = case_when(
        str_detect(text, str_c(interviewers, collapse = "|")) ~ "interviewer",
        TRUE ~ "participant"
      )
    ) %>%
    filter(
      text != "",                      # Remove blank rows
      !str_detect(text, "^\\d+$"),     # Remove number-only rows
      !str_detect(text, "-->")         # Remove timestamp markers
    )

  # ================================
  # âœ… 3. Extract participant & interviewer names
  # ================================
  
  # Participants
  unique_participants <- df %>%
    filter(speaker == "participant" & str_detect(text, ":")) %>%
    mutate(participant_name = str_extract(text, "^[^:]+")) %>%
    distinct(participant_name) %>%
    drop_na() %>%
    mutate(participant_id = paste0("P", row_number()))

  # Assign participant IDs back
  df <- df %>%
    mutate(
      participant_name = if_else(
        speaker == "participant" & str_detect(text, ":"),
        str_extract(text, "^[^:]+"),
        NA_character_
      )
    ) %>%
    left_join(unique_participants, by = "participant_name") %>%
    select(-participant_name)

  # Interviewers
  unique_interviewers <- df %>%
    filter(speaker == "interviewer" & str_detect(text, ":")) %>%
    mutate(interviewer_name = str_extract(text, "^[^:]+")) %>%
    distinct(interviewer_name) %>%
    drop_na() %>%
    mutate(interviewer_id = paste0("I", row_number()))

  # Assign interviewer IDs back
  df <- df %>%
    mutate(
      interviewer_name = if_else(
        speaker == "interviewer" & str_detect(text, ":"),
        str_extract(text, "^[^:]+"),
        NA_character_
      )
    ) %>%
    left_join(unique_interviewers, by = "interviewer_name") %>%
    mutate(
      participant_id = coalesce(participant_id, interviewer_id)
    ) %>%
    select(-interviewer_name, -interviewer_id)

  # ================================
  # âœ… 4. Clean and Preprocess Text
  # ================================
  df <- df %>%
    mutate(
      text = str_remove(text, ".*?:\\s*"),   # Remove speaker names (before colon)
      text = tolower(text),                  # Convert to lowercase
      text = str_replace_all(text, "[^a-zA-Z0-9\\s]", ""),  # Remove special characters (except spaces)
      text = iconv(text, from = "UTF-8", to = "ASCII//TRANSLIT")  # Convert non-ASCII characters
    )

  # ================================
  # âœ… 5. Create speaker segments BEFORE detecting questions
  # ================================
  df <- df %>%
    arrange(line) %>%
    filter(!is.na(participant_id)) %>%
    mutate(
      group_id = cumsum(
        participant_id != lag(participant_id, default = first(participant_id))
      )
    ) %>%
    group_by(group_id) %>%
    summarize(
      across(-text, first),                # Keep first of all other columns
      text = str_c(text, collapse = " "),  # Collapse text
      .groups = "drop"
    ) %>%
    arrange(line)

  # ================================
  # âœ… 6. Detect interviewer questions
  # ================================
  df <- df %>%
    mutate(
      question = if_else(
        speaker == "interviewer" &
          str_detect(
            text,
            regex(str_c(question_list, collapse = "|"), ignore_case = TRUE)
          ),
        1L,
        0L
      )
    )

  # ================================
  # âœ… 7. Remove text before first question
  # ================================
  first_question_line <- min(df$line[df$question == 1], na.rm = TRUE)
  
  df <- df %>%
    filter(line >= first_question_line)

  # ================================
  # âœ… 8. Assign section numbers
  # ================================
  df <- df %>%
    mutate(section = cumsum(question == 1))

  # Map section numbers to section labels
  section_map <- tibble(
    section = seq_along(section_labels),
    section_label = section_labels
  )

  # Join section labels
  df <- df %>%
    left_join(section_map, by = "section")

  # ================================
  # âœ… 9. Remove interviewer lines AFTER section labels assigned
  # ================================
  df <- df %>%
    filter(speaker != "interviewer") %>%
    mutate(session = session_name)

  # ================================
  # âœ… 10. Return final dataframe
  # ================================
  final_df <- df %>%
    select(
      line,
      speaker,
      participant_id,
      question,
      section,
      section_label,
      text,
      session
    )

  return(final_df)
}

```

And when you want to clean the transcripts and mark the interviewer, you can add the names of the interviewers here. 

This function works for Zoom transcripts that are saved as Word documents or .txt files. There are few things you need to specify in the function, including updating the file path, the interviewers, setting your list of questions, adding section labels, and the session name. 

This example comes from the Loudoun County Opioid Abatement project where Shon, Lindsay, Hannah, Luke, Eden, and Arden are staffed, so any of them could have been an interviewer. 

@QUALBPT is there anything listed here that may be helpful to add that we might want to analyze or examine?
@QUALBPT is there ever a case where we would need to analyze the interviewer's language?

In the case where an interviewer asks a question an exact way, we can enter the question as it is listed on the interview guide. However, this is not always the best way to run an interview when you're following a more relaxed vibe. So, it may be helpful to have the interview guide (or deck, whatever the interviewer used to facilitate the discussion) and the transcript opened to identify the order of discussion and section labels, and to identify where those key markers of the text are going to identify your questions. 

What is a good example of a question list if the interviewer did not read the question verbatim? Let's imagine the first question listed on the interview guide is "What kinds of barriers do you think prevent community members from accessing services in the county?". 

Bad example: "accessing services" this is a bad example because this phrase has been marked as an identifier for a question, so any instance of "accessing services" comes up will count the phrase as a question.

Good example: "barriers do you think prevent community members from accessing services" it is less likely for someone to have used this exact string of words in the conversation, so we're safe to mark this as a question identifier. 

```{r}
# %%%%%%%%%%%%%%%%%%% List interviewer names %%%%%%%%%%%%%%%%%%%
# ed_df <- clean_transcript(
#   file_path      = "../../../data_collection/Listening Sessions/Transcripts/Education Listening Session Transcript.docx",
#   file_type      = ".docx",
#   interviewers   = c("Shon Reed", "Lindsay Houston", 
#                      "Hannah Lunkenheimer", "Luke Saunders", 
#                      "Eden Griffin", "Sam Barron",
#                      "Arden Trewartha"),
#   question_list  = c("1st question", 
#                      "how has the opioid crisis impacted schools and universities within Loudoun County", 
#                      "opioid abatement fund",
#                      "what are what are other specific examples that are working well",
#                      "current efforts on the treatment and recovery",
#                      "are there any other strategies",
#                      "vision for the future",
#                      "survey that you can complete if you would like"),
#   section_labels = c("Data check", "Community impact", "Abatement funds",
#                      "Prevention and harm reduction", "Treatment and recovery",
#                      "Other strategies", "Vision for the future", "Next steps"),
#   session_name   = "education"
# )

```

### PDFs

```{r}
library(pdftools)
library(tibble)
library(dplyr)

# # Define the folder where PDFs are saved
# folder_path <- "path/to/your/pdf/folder"
# 
# # List all PDF files in the folder
# pdf_files <- list.files(folder_path, pattern = "\\.pdf$", full.names = TRUE)
# 
# pdf_data <- pdf_files %>%
#   map_df(~ tibble(
#     file = basename(.x),           # Extract file name only
#     text = paste(pdf_text(.x), collapse = " ")  # Merge all pages into one text block
#   ))
# 
# # View the cleaned data
# print(pdf_data)
# 
# pdf_data <- pdf_data %>%
#   mutate(text = str_replace_all(text, "\\s+", " "))  # Remove extra spaces/newlines
# 
# print(pdf_data)


```

### Excel sheets

Of course, we also tend to ask qualitative questions in some of our surveys at Omni, and these types of data should be read in like quantitative data and should already be in a clean format if you follow the data cleaning guide (insert link to data cleaning guide).

### @QUALBPT Any other forms of text we use?

```{r}
# %%%%%%%%%%%%%%% Fix misspelled words %%%%%%%%%%%%%%%

# library(hunspell)
# 
# # Flag misspelled words
# misspelled <- cleaned_text %>%
#   mutate(
#     misspelled = !hunspell_check(word),
#     suggestions = map(word, hunspell_suggest)
#   ) %>%
#   filter(misspelled)
# 
# head(misspelled)
# 
# corrected_text <- cleaned_text %>%
#   mutate(word = case_match(
#     word, 
#     "leraning" ~ "learning",
#     .default = word
#   ))
# 
# head(corrected_text)

```


# QA Checklist for Qual Cleaning

[ ] Are participant and interviewer roles correctly labeled?
[ ] Have names, locations, and job titles been de-identified?
[ ] Are timestamps removed (unless needed for analysis)?
[ ] Are discussion sections correctly labeled?
[ ] Has text been standardized (case, punctuation, spacing)?
[ ] Is the cleaned dataset in a tidy format (one speaker turn per row)?
[ ] Has the cleaned dataset been reviewed by another team member?

```{=html}
<div class="outer">
  <div class="green-box"
       style="--bar-bg: #5776b2;
              --bar-text-color: #FFFFFF;
              --box-h: 90px;">
    <div class="green-col">Cleaning and Pre-Processing Your Data</div>
    <div class="green-col pattern">
      <img src="images/Pattern-05-Periwinkle.png" alt="Pattern">
    </div>
  </div>
</div>
```

<br>

## Terminology {.unnumbered}

Before starting your pre-processing and analysis, itâ€™s important to
understand a few core terms. These concepts are essential for working
with text data and deciding on the appropriate pre-processing and
analysis steps.

| **Term** | **Definition** |
|-----------------------|-------------------------------------------------|
| Tokenization | Breaking text into units (words, phrases, sentences) |
| Stemming | Reducing words to their root (e.g., "running" â†’ "run") |
| Lemmatization | Reducing to dictionary form (e.g., "better" â†’ "good") |
| Stop Words | Common words often removed (e.g., "the", "and") |
| Document-Term Matrix | Table of word frequencies across documents |
| TF-IDF | Term importance based on frequency and inverse document frequency |
| Corpus | Collection of text documents as one dataset |
| Dictionary | List of keywords/phrases used to code or categorize text |

::::: columns
::: {.column width="60%"}
```{r, echo=TRUE}
# Load all packages 
library(tidyverse)
library(tidytext)
library(quanteda)
library(textstem)
library(sentimentr)
library(topicmodels)
library(flextable)
library(knitr)
library(omni)

```
:::

::: {.column width="40%"}
![](images/preprocessing.png)
:::
:::::

```{r, include=FALSE}
# Create a fake, tidy qualitative dataset
text_data <- tibble(
  line = 1:10,
  speaker = c("interviewer", "participant", "participant", "interviewer", "participant",
              "participant", "interviewer", "participant", "participant", "participant"),
  participant_id = c("I1", "P1", "P2", "I1", "P1", "P2", "I1", "P1", "P2", "P1"),
  question = c(1, 0, 0, 1, 0, 0, 1, 0, 0, 0),
  section = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 3),
  section_label = c("Introduction", "Introduction", "Introduction", "Barriers", 
                    "Barriers", "Barriers", "Recommendations", "Recommendations", 
                    "Recommendations", "Recommendations"),
  text = c(
    "Can you tell me about your experience accessing services in the county?",
    "Sure, I think one of the biggest challenges is transportation in Travis County. There are many people here who do not own their own cars which makes it difficult to access any type of treatment services. On top of that, the buses are never on time so people have to do a lot of planning ahead of time to get to their appointment.",
    "I agree, especially for people in rural areas. It's hard to get to services.",
    "What kinds of barriers do you see in your community?",
    "Travis county definitely has a lack of awareness about available programs.",
    "Also, the application process is confusing and time-consuming. The health administrative offices used to post the applications at midnight and they would take new clients on a rolling basis, so by the time it was morning all applications would be filled.",
    "What are your recommendations for improving access?",
    "More outreach and education campaigns would help Travis county residents, rather than wasting time on trying to get policy changes.",
    "Simplifying the application process would make a big difference.",
    "Providing transportation vouchers could also improve access."
  ),
  session = c(rep("Education", 5), rep("Public Health", 5))
) %>% 
  mutate(text = tolower(text),
         text = str_replace_all(text, "[^a-zA-Z0-9\\s]", ""))

text_data <- text_data %>% 
  filter(speaker != "interviewer")
```

Pre-processing prepares your qualitative data for analysis by
**cleaning**, **organizing**, and **standardizing** text. This step
ensures the data is usable for word frequency, sentiment analysis, topic
modeling, and other text mining techniques.

You should always assess the **scope and quality** of your data first:

-   Are the data cleaned (lowercase, removed participant names,
    punctuation, symbols)? 

```{r, echo=FALSE}
omni::callout_box(
    text = "Check out our function that does all of these data cleaning tasks for you in R! You can also segment your text by question, combine multiple interviews and focus groups into one dataset, and more.",
    color = "periwinkle-600",
    fixed_width_px = 800
)
```
<center> 
  <a href="https://www.example.com" target="_blank" rel="noopener" class="yellow-btn">
    Cleaning transcripts function
  </a>
</center>
-   How much text do you have? (Word counts per document/response.)

-   How many participants contributed?

-   How detailed or shallow are the responses?

-   Whose voices are you analyzing?

Once you understand your data, you can decide which pre-processing steps
are appropriate.

## Tokenization {.unnumbered}

Tokenization breaks text into individual piecesâ€”usually words, but
sometimes phrases or sentences.

-   Most text mining techniques require tokenized text.

-   This is common for word frequency analysis, sentiment analysis, and
    topic modeling.

-   After tokenization, we lose the flow of sentences which is generally
    okay for some analyses, but not for narrative analysis or content
    analysis.

```{r}
# %%%%%%%%%%%%%%% Tokenize text %%%%%%%%%%%%%%%

# Tokenize text
tokenized_text <- text_data %>% 
  unnest_tokens(word, text)

```

**What are Stop Words?**

Stop words are common words like "the", "and", "but" that donâ€™t add much
meaning on their own. Because we want to focus on broader themes from
our participants' voices, we usually want to remove stop words after
text is tokenized. This process allows us to focus on content-rich
words, like nouns and verbs. We should remove stop words when running a
word frequency analysis, topic modeling, or sentiment analysis.

We can also create custom stop words that we want to remove from our
analyses, for example, location names or project-specific words that
appear frequently but arenâ€™t relevant to the analysis.

**Example:**

-   In the example below, my custom stop words are "travis" and
    "county", and they're added to the stop_words bank which includes
    other words like "but", "is", "the", etc. If you'd like to see all
    of the stop words, see View(stop_words).

```{r}
# %%%%%%%%%%%%%%% Stop words %%%%%%%%%%%%%%%

# Use standard stop words + custom ones (e.g., counties, names)
my_stop_words <- bind_rows(stop_words, 
                           data.frame(word = c("travis", 
                                               "county"), lexicon = "custom"))

cleaned_text <- tokenized_text %>% 
  anti_join(my_stop_words, by = "word")

```

## Stemming {.unnumbered}

Stemming words cuts them down to their root forms (e.g., "running"
becomes "run"). This pre-processing step should primarily be used for
topic modeling or for other analyses that you decide that exact word
form isnâ€™t critical. This step is recommended to use with larger
datasets, with typically hundreds of documents or more, but for our
purposes we recommend stemming any time you have enough data for topic
modeling (around 5,000 total words).

```{r}
# %%%%%%%%%%%%%%% Stemming %%%%%%%%%%%%%%%

library(textstem)

stemmed_text <- cleaned_text %>%
  mutate(stem_word = stem_words(word))
```

## Lemmatization {.unnumbered}

Lemmatization converts words to their dictionary root and keeps the
words readable to the user (e.g., "better" becomes "good"). This
pre-processing step should be used for word frequency analysis,
sentiment analysis, or thematic/content analysis as it works will with
small and large corpuses.

```{r}

# %%%%%%%%%%%%%%% Lemmatization %%%%%%%%%%%%%%%

lemmatized_text <- cleaned_text %>% 
  mutate(lem_word = lemmatize_words(word))

```

Let's compare the stem words, vs lemmatized words against the original
tokenized words:

```{r}
compare_words <- cleaned_text %>% 
  left_join(stemmed_text, 
            by = join_by(line, 
                         speaker, 
                         participant_id, question, section, section_label,
                         session, word)) %>% 
  left_join(lemmatized_text,
            by = join_by(line, 
                         speaker, 
                         participant_id, question, section, section_label,
                         session, word)) %>%
  slice(1:10) %>%
  kable()
```

```{r, include=TRUE}
compare_words
```

```{r, echo=FALSE}
# Create a data frame for the table
comparison_table <- data.frame(
  "Stemming" = c(
    "You need speed over accuracy",
    "Working with large datasets",
    "Basic information retrieval tasks",
    "Search engines or topic modeling where fine detail isn't critical",
    "Not concerned about human readability"
  ),
  "Lemmatization" = c(
    "Slower but more accurate",
    "Better for small datasets",
    "Better for nuanced analysis",
    "Better for in-depth analysis",
    "Maintains readable words)"
  )
)

# Print the table
kable(comparison_table,
      caption = "When to Use Stemming vs. Lemmatization",
      align = 'll')

```

