{
  "hash": "7fd47ffe655040f6c5f70099d937e25b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Subtab1 test\ntoc-depth: 2\n---\n\n\n\n\n## Quarto\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nManager's Summary\n\nData Cleaner's Summary\n\n## Introduction\n\n**Do not share this guide outside of OMNI**\n\nData cleaning is often one of the first things you will do when you\nstart working with qualitative data at OMNI. Whether we‚Äôre working with\ninterview transcripts, focus group discussions, or open-ended survey\nresponses, the raw data we receive is rarely ready for immediate\nanalysis. Cleaning is not just about tidying up; it‚Äôs about making\ninformed decisions that clarify the meaning and integrity of the data\nwhile preparing it for systematic analysis.\n\nThe decisions we make during the cleaning process are every bit as\ncomplex and impactful as those made during coding and analysis.\nThoughtful data cleaning can preserve the richness of qualitative data,\nwhile careless decisions can distort or diminish participants' voices.\nTherefore, it is especially important to have a strong set of working\nprinciples to guide your decisions when cleaning qualitative data.\n\nThis guide covers a general approach to qualitative data cleaning, with\nan emphasis on useful R packages and functions designed to conquer some\ncommon challenges. While this guide includes tools and code to make your\nlife easier, it also offers guidelines for making judgment calls about\nwhat to remove, retain, or clarify in the data.\n\nThe steps in a qualitative data cleaning process will always be informed\nby two key factors:\n\n1)  **The state of the data when we (OMNI) receive it**\n\n-   For example, some transcripts may come from automated services (like\n    Zoom or Otter.ai) and contain timestamps, speaker labels, or filler\n    words that require removal. Others may be professionally transcribed\n    and need minimal cleaning.\n\n2)  **The specific needs of the project** Because of this variability,\n    we encourage a flexible, judgment-driven approach to data cleaning.\n    The steps described in this guide are common to many projects, but\n    their order and application should be tailored to the needs of the\n    dataset and the analytic goals of the project. Importantly,\n    depending on the type of analysis, different cleaning steps may be\n    required. Consult the analysis plan and research questions in your\n    project materials to verify the needs of the project.\n\n### Supporting resources\n\n## Rationale\n\nWhen we clean qualitative data, we apply a series of thoughtful\ntransformations that make the data clearer, more consistent, and usable\nfor analysis. Qualitative data cleaning requires attention to detail and\nsensitivity to the context in which the data were collected. The\nprocedures we use need to be flexible because the downstream purposes of\nthe data can vary from project to project‚Äîwhether for thematic coding,\ncontent analysis, or mixed-methods integration.\n\nThe qualitative data cleaner often has to make many judgment calls\nduring this process. These decisions are guided by the project‚Äôs goals,\nthe nature of the source data, team experience, and guidance documents\n(like this one). Every decision and its rationale should be clearly\ndocumented in the data cleaning script or data log (more on that below).\nTransparency in this process ensures that the cleaned dataset remains\ntrustworthy and aligned with our ethical standards for qualitative\nresearch.\n\nQualitative data cleaning requires a lot of careful thought and\nattention. The R code that cleans text data needs to be clearly written\nand well-commented, not only for reproducibility but to ensure that\nmeaning is preserved, and participant voices are not inadvertently\naltered or diminished. In qualitative work, the cleaning process can\ndirectly impact the integrity of the analysis.\n\nJust as with quantitative analysis, qualitative data-cleaning decisions\nare made with greater ease and clarity when there is a clear work plan,\nguided by the project‚Äôs research questions or evaluation goals. Having a\nshared understanding of what the team hopes to explore in the data helps\ninform:\n\nWhat should be cleaned What should be preserved (even if messy) What\nshould be flagged for discussion Two especially helpful documents to\nhave before qualitative data cleaning begins are:\n\nA codebook (or at least a data dictionary) This helps ensure consistency\nin how we treat things like speaker names, special terminology, or\nsensitive content. A data analysis plan This outlines the team‚Äôs\napproach to coding and analysis and helps identify if additional\ncleaning steps are necessary. For example: anonymizing sensitive details\nor removing artifacts from automated transcription tools (timestamps,\nfiller words, etc.). Whenever possible, we expect teams to develop a\ndata analysis plan and request any available data dictionaries or\ncodebooks from the client or partner organizations who collected the\ndata. However, you may need to create a codebook if one doesn‚Äôt\nexist‚Äîfeel free to reach out to the QualBPT (or whichever team you want\nto point folks to) if you need support.\n\nIn many cases, the people drafting the analysis plan are different from\nthose cleaning the qualitative data, so strong cross-team communication\nis essential. We recommend including the qualitative data cleaner (or\ncleaning team) in project discussions as early as possible. When\ndrafting the analysis plan, think through what text cleaning steps will\nbe necessary to make the data usable for coding, protect participant\nconfidentiality, and meet the project‚Äôs goals.\n\nFinally, whether you‚Äôre writing code for qualitative data cleaning or\nany other purpose, always write your R scripts as if they will later be:\n\n-   Heavily scrutinized\n-   Held up as example code\n-   Modified by someone brand new to both R and the project\n\nMake it easy on future OMNI-ites‚Äîand on your future self!\n\n## When are data clean?\n\n‚úÖ What Does It Mean to Have \"Clean\" Qualitative Data? For there to be\nproject tasks that direct OMNI-ites to ‚Äòclean qualitative data,‚Äô and a\nguide to help in doing so, there should also be a shared understanding\nof what it means for qualitative data to be clean.\n\nüìù Definition of Clean Qualitative Data: At OMNI, qualitative data are\nconsidered clean when they are organized, de-identified, and ready for\nanalysis or coding.\n\nThat means the data:\n\nAccurately reflect the original source material (e.g., interviews, focus\ngroups, or open-text survey responses) Have been transformed into a\nstructure that makes them easy to navigate and analyze Protect the\nprivacy and confidentiality of participants Are consistent, clear, and\nfree of irrelevant clutter (like transcription artifacts) üéØ What Makes\na Qualitative Dataset \"Analysis-Ready\"? For qualitative text data to be\nready for analysis, they should meet the following criteria:\n\nSpeaker Information Is Clear and Consistent\n\nParticipant speakers and interviewers are clearly labeled in the data.\nEach speaker‚Äôs text is grouped logically into segments, preserving\nconversational flow. Participant Identifiers Are Specified and Protected\n\nReal names, locations, and other direct identifiers have been removed or\nreplaced with participant IDs or pseudonyms. Confidential information\n(e.g., agency names, job titles, organizations) is anonymized where\nnecessary, following OMNI‚Äôs confidentiality guidelines. Questions Are\nClearly Distinguished From Responses\n\nInterviewer questions (or prompts) are labeled or separated from\nparticipant responses, as appropriate. This can be done by adding\nquestion text as its own field in the dataset or by adding markers in\nthe transcript. Text Segments Are Ordered and Organized\n\nThe transcript text is ordered according to the flow of conversation.\nSegments are correctly time-sequenced (even if timestamps themselves are\nremoved). Text Is Structured Into a Tidy, Rectangular Format\n\nEach row represents a single speaker turn or unit of analysis (e.g., a\ncomplete response to a question). Data are stored in a rectangular table\n(data frame), with columns for: Session name or group (e.g., \"Educators\"\nor \"Public Health\") Participant ID or role (e.g., \"Participant 1,\"\n\"Facilitator\") Text segment (the response or comment) Any relevant\nmetadata (e.g., discussion section, date) Timestamps and Transcription\nArtifacts Are Removed\n\nAll timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless\nspecifically required for analysis. Automated transcription quirks\n(e.g., repeated words, filler words, auto-captions like ‚Äú[inaudible]‚Äù)\nare reviewed, cleaned, or flagged. Text Is Consistent in Style and\nFormat\n\nAll text is converted to lowercase, unless case is important for\nanalysis. Spelling errors are corrected when they obscure meaning (but\nregional spellings or participant quirks may be preserved if relevant).\nPunctuation and spacing are standardized (no excessive whitespace,\nmissing periods, etc.). Relevant Identifiers Are Added to the Dataset\n\nIf there are multiple sessions or groups, these are labeled (e.g.,\n\"Educators,\" \"Public Health\"). If there are themes or discussion\nsections (e.g., \"Challenges,\" \"Recommendations\"), these are identified.\nIf codes are pre-assigned for analytic purposes (e.g.,\n‚ÄúPre-implementation,‚Äù ‚ÄúPost-implementation‚Äù), they are included in the\ndata structure. üí° How Do We Know When Qualitative Data Are Clean? Here\nare some guiding questions to help determine when qualitative data are\nready for analysis (i.e., clean):\n\nWhat is the plan for coding or analyzing this data?\n\nThe analysis plan (or coding framework) should inform cleaning\ndecisions. For example, if the team plans to do thematic coding, they‚Äôll\nneed text organized into meaningful speaker turns or responses. What\nneeds to be anonymized?\n\nIdentify any sensitive information that must be redacted or replaced to\nmaintain confidentiality and ensure participant privacy. Are speaker\nturns properly attributed and easy to follow?\n\nEach speaker‚Äôs contributions should be clearly labeled, consistently\nformatted, and grouped logically. Are responses to specific questions\nclearly identifiable?\n\nIf interviews or focus groups follow a semi-structured guide, it‚Äôs\nimportant to separate questions from responses for clarity in analysis.\nIs the structure of the data appropriate for the analytic tool?\n\nIf the data are being uploaded to Dedoose, NVivo, or another platform,\nthey should follow the required format (e.g., tidy data frame with\nspeaker IDs and group names). Have all unnecessary artifacts been\nremoved?\n\nTime stamps, filler words, and transcription errors that don‚Äôt add value\nto the analysis should be removed. Has the cleaned data been reviewed by\nsomeone else (QA check)?\n\nWhenever possible, have another OMNI-ite review the cleaned data for\naccuracy and completeness. ‚ú® Common Issues to Discuss Early in the\nCleaning Process Just like in quantitative data cleaning, clarifying\nexpectations at the start of a project will save time later. For\nqualitative projects, consider these:\n\nWill we analyze both facilitator questions and participant responses, or\njust participant responses? How will we handle overlapping speech,\ninterruptions, or incomplete thoughts? Do we need to standardize\nparticipant roles (e.g., \"Public Health Official\" vs. \"PH Staff\") for\nconsistency? Are we preparing data for manual coding or automated text\nanalysis? Do we need to translate or transcribe non-English responses?\nDo we need to connect text segments with broader context, such as the\ndiscussion theme or section of the focus group? üöÄ In the Following\nSections... We‚Äôll see how these fundamentals‚Äîlike tidy qualitative data,\npipes, and regular expressions‚Äîplay out in real-world cleaning tasks,\nsuch as:\n\nRemoving timestamps and filler words Labeling speakers and organizing\nsegments Anonymizing sensitive information Structuring text for analysis\nsoftware (Dedoose, NVivo, etc.) ‚úÖ Quick Summary of \"Clean Qualitative\nData\" at OMNI: Clean qualitative data are:\n\nAnonymized Clearly structured and labeled Organized for easy analysis\nFree of unnecessary artifacts Ready for use in coding and interpretation\n\n## How do I report the results of data cleaning?\n\nüìù How to Report the Results of Qualitative Data Cleaning at OMNI\nCleaning qualitative data is an interpretive and decision-heavy process,\nand those decisions need to be transparent. Reporting your cleaning\nprocess helps:\n\nProject leads understand what‚Äôs been done and why. Provide documentation\nin case changes need to be made later. Build trust in the integrity of\nthe cleaned dataset. Support future qualitative coding, interpretation,\nand reporting. Qualitative data cleaning produces results‚Äîchanges to the\ntext or data structure‚Äîthat should be documented in a clear, shareable\ndata cleaning report.\n\nüìã What to Include in a Qualitative Data Cleaning Report 1. Summary of\nthe Dataset You Cleaned Start with an overview:\n\nHow many transcripts or files were cleaned? How many sessions (e.g.,\nfocus groups, interviews) are included? What types of participants are\nrepresented (e.g., educators, public health professionals)? Example:\nThis dataset includes transcripts from 8 focus groups, with 42\nparticipants. Participants represent two stakeholder groups: Educators\n(n = 20) and Public Health Professionals (n = 22).\n\n2.  Anonymization and De-Identification Steps Document what you removed\n    or replaced to protect confidentiality.\n\nWere participant names replaced with IDs (e.g., Participant 01)? Were\norganizations, locations, or personal identifiers removed or redacted?\nWere job titles generalized (e.g., ‚ÄúCEO‚Äù changed to ‚Äúsenior leader‚Äù)?\nExample: Replaced all participant names with Participant IDs (e.g.,\nP01). Removed specific references to organizations and locations (e.g.,\n‚Äúat Boulder Community Hospital‚Äù becomes ‚Äúat [hospital]‚Äù). Redacted job\ntitles for anonymity when mentioned alongside unique organizations.\n\n3.  Speaker Labeling and Text Structuring Describe how speakers were\n    labeled and how the transcript was organized.\n\nWere speakers consistently labeled as \"Participant\" and \"Facilitator\"?\nWas each speaker turn separated into its own row or segment? Were\nquestions separated from responses? Example: Speaker turns were labeled\nconsistently as either Facilitator or Participant. Each speaker turn is\nstored as one row in the cleaned dataset, with associated metadata\n(Session name, Speaker role, Discussion section).\n\n4.  Artifacts Removed (Timestamps, Filler Words, etc.) Note what\n    transcription artifacts were removed or edited:\n\nWere timestamps deleted? Were filler words (e.g., ‚Äúum,‚Äù ‚Äúuh‚Äù) removed?\nIf so, specify whether this was systematic or case-by-case. Were\ntranscription errors corrected? Example: Removed all timestamps in the\nformat [hh:mm:ss]. Deleted common filler words (‚Äúum,‚Äù ‚Äúuh‚Äù) unless they\ncontributed to participant meaning or tone. Reviewed and corrected\nauto-transcription errors (e.g., ‚ÄúDodoose‚Äù corrected to ‚ÄúDedoose‚Äù).\n\n5.  Text Standardization and Formatting Summarize standardization steps\n    for readability and consistency:\n\nWas text converted to lowercase? Was spelling corrected? If so, did you\npreserve participant colloquialisms? Were consistent punctuation and\nspacing applied? Example: Converted all text to lowercase for\nconsistency. Standardized punctuation (e.g., added periods to sentence\nends where missing). Corrected spelling errors that obscured meaning but\npreserved participant vernacular and tone where appropriate.\n\n6.  Metadata or Contextual Information Added Note any metadata added to\n    support analysis:\n\nSession name (e.g., ‚ÄúEducators‚Äù vs. ‚ÄúPublic Health Professionals‚Äù)\nDiscussion section (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù) Participant\nrole or group designation Example: Added metadata fields to identify\nSession Name, Participant Group (Educator/Public Health), and Discussion\nSection (Barriers, Facilitators, Recommendations).\n\n7.  Key Decisions Made During Cleaning Flag any important decisions that\n    could impact analysis:\n\nIf you excluded any portions of text (e.g., off-topic discussions),\ndocument what was excluded and why. If you made choices about retaining\nor removing interruptions, overlapping speech, or non-verbal cues,\ndescribe the rationale. If you generalized identifying details in ways\nthat may impact interpretation, note this. Example: Excluded\nintroductory small talk (greetings, logistics discussions) from the\nanalysis dataset. Retained overlapping speech where relevant to the\ndiscussion. Generalized certain job titles to preserve anonymity (e.g.,\n‚ÄúHead Nurse‚Äù changed to ‚ÄúMedical Staff‚Äù).\n\n8.  Counts and Summaries Where Relevant When helpful, include counts\n    that summarize:\n\nHow many identifiers were removed? How many sessions, speakers, or\nresponses are in the final dataset? If you organized by themes, how many\nsegments are in each theme? Example: Final cleaned dataset includes 8\nfocus groups, 42 participants, and 620 participant responses across\nthree discussion sections: Challenges (n = 220), Facilitators (n = 200),\nand Recommendations (n = 200).\n\nüí° Tips for Reporting Qualitative Data Cleaning Be Transparent Even\nsmall decisions (e.g., standardizing speaker labels) can have big\nimplications during analysis. If you‚Äôre unsure whether to document\nsomething, document it!\n\nTake the Perspective of Your Project Lead or Analyst What decisions\nmight they need to revisit later? What context would help them\nunderstand how the data were shaped?\n\nSupport Replicability and Quality Control Your cleaning report should\nmake it easy for another team member to:\n\nUnderstand what was done Re-run the cleaning script Suggest or request\nchanges with full knowledge of the process üñºÔ∏è Example Summary Table in a\nQualitative Cleaning Report Cleaning Step Action Taken Notes\nAnonymization Removed names, replaced with Participant IDs (P01-P42)\nLocations and job titles generalized Speaker Labeling Labeled as\nFacilitator or Participant Consistent across all sessions Timestamps\nRemoved Deleted all timestamps (hh:mm:ss)\\\nFiller Words Removed \"um,\" \"uh\" except when indicating hesitation\nCase-by-case review Text Standardization Converted to lowercase,\ncorrected major spelling errors Preserved participant language/tone\nMetadata Added Session name, participant group, discussion section\nUseful for subgroup analysis Exclusions Removed introductions, off-topic\ndiscussions Documented in the data log\n\n## Terminology\n\nüìù Relevant Terminology for Qualitative Data Cleaning in R üîß Data\nStructure & Format Terms Transcript A written or typed record of spoken\nlanguage from interviews, focus groups, or meetings. Transcripts may\ninclude speaker labels, timestamps, and other artifacts that need\ncleaning.\n\nTurn-Taking Each time a participant or facilitator speaks is called a\n\"turn.\" Clean data often organize these turns into individual rows in a\ndataset.\n\nSegment (or Excerpt) A portion of text, such as a paragraph, sentence,\nor speaker turn, treated as a unit for coding or analysis. Segments are\noften defined by the speaker's response or by topic.\n\nTidy Data Data where:\n\nEach row represents a single observation (e.g., a speaker turn or\nsegment) Each column contains one type of information (e.g., speaker ID,\ntext, session group) Tidy data make it easier to manipulate, clean, and\nanalyze qualitative datasets in R. Rectangular Data Another term for a\ntable or data frame, where rows and columns are used to organize data in\nR.\n\nüóÇÔ∏è Qualitative Metadata & Labeling Terms Speaker Label An identifier\nshowing who is speaking (e.g., \"Facilitator,\" \"Participant 1\"). Clean\ndata should use consistent speaker labels.\n\nParticipant ID A unique identifier assigned to participants to protect\nanonymity (e.g., \"P01\"). These are often used in place of names.\n\nSession ID / Group The label identifying the specific interview or focus\ngroup a participant was part of (e.g., \"Session 1 ‚Äì Educators\").\n\nDiscussion Section / Topic Area A label identifying a portion of the\nconversation (e.g., \"Barriers,\" \"Recommendations\") to help organize\nqualitative data.\n\n‚úÇÔ∏è Data Cleaning & Transformation Terms Anonymization /\nDe-Identification The process of removing or replacing personal\nidentifiers (e.g., names, locations, job titles) to protect participant\nprivacy.\n\nStandardization Making text consistent in format (e.g., converting to\nlowercase, consistent punctuation, spacing).\n\nTokenization (Optional depending on your analysis!) Breaking down text\ninto smaller parts‚Äîwords, sentences, or phrases‚Äîtypically for text\nmining. Not always part of standard qualitative coding workflows.\n\nFiltering Removing unnecessary rows or segments (e.g., small talk,\noff-topic responses) from the data.\n\nRecoding Transforming data from one format to another (e.g.,\ngeneralizing job titles or grouping participant roles).\n\nJoin / Merge Combining two datasets based on a shared key (e.g., merging\nparticipant demographic info with transcripts).\n\nPivoting Restructuring data from wide format (many columns) to long\nformat (many rows), or vice versa, to make it easier to analyze or\ndisplay.\n\nüè∑Ô∏è Text Cleaning Terms Timestamps Time markers in transcripts (e.g.,\n[00:12:34]) that need to be removed unless necessary for the analysis.\n\nFiller Words Common speech disfluencies (e.g., \"um,\" \"uh,\" \"like\") that\ncan be removed for clarity, depending on analysis goals.\n\nInaudibles / Transcription Errors Markers like ‚Äú[inaudible]‚Äù or machine\ntranscription errors that need to be corrected or flagged.\n\nSpelling and Grammar Standardization Correcting spelling errors that\nmake text difficult to read, while preserving participant voice and tone\nwhere relevant.\n\n# Data cleaning procedures\n\nThe first step we'll need to take is to figure out what kind of document\nyou want to read into R.\n\n## Reading your data into R\n\nFirst, we'll need to read our data into R. Depending on how your raw\ntext is stored, you'll need to take various steps to read in your data\nfor analysis. The goal is to turn any of your text into a dataframe with\nrows and columns of your text responses. In some cases, you may need to\nkeep participant ID columns or other columns if you're doing a\nmixed-method analysis. In other cases, you may be analyzing different\nfocus groups and comparing them to eachother. Whatever you are doing,\nmake sure your dataframe is set up or your analysis. If you are unsure\nabout this, ask Hannah or a member of Qual BPT for some help!\n\nHere is an example of what your data may look like when you first read\nit into R.\n\n![](dirty_data.png)\n\nand here's what we want it to look like (eventually) for most of our\nanalysis needs.\n\n![](clean_data.png)\n\nWith clean data, we can:\n\n-   Compare participants' responses across sessions and discussion\n    sections. We could answer questions like:\n\n    -   What did Educators say about Community Impact vs. Public\n        Health?\"\n\n    -   What did participants across all interviews think about\n        abatement funds?\n\n-   Filter by participant role (e.g., facilitators vs. participants) for\n    targeted analysis. We could answer questions like:\n\n    -    How many participants mentioned that the county should invest\n        in wraparound services across all interviews?\n\n    -   What is the most common barrier in accessing services in the\n        county?\n\n-   Preserve anonymity by removing names and identifiers.\n\n### Zoom transcripts\n\nOne of the main forms of qualitative data we receive includes Zoom transcripts. Below is a function you can use to clean your Zoom transcripts and get them to a tidy format by entering the interviewer name(s), and key phrases used by the interviewer to mark the section of the discussion. For example, an interview might begin with an introduction, then include a discussion of barriers, and a discussion of strengths. We'll likely want to separate these out into sections so our analyses can speak to each section independent of each other, rather than be clumped altogether. \n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nAnd when you want to clean the transcripts and mark the interviewer, you can add the names of the interviewers here. \n\nThis function works for Zoom transcripts that are saved as Word documents or .txt files. There are few things you need to specify in the function, including updating the file path, the interviewers, setting your list of questions, adding section labels, and the session name. \n\nThis example comes from the Loudoun County Opioid Abatement project where Shon, Lindsay, Hannah, Luke, Eden, and Arden are staffed, so any of them could have been an interviewer. \n\n@QUALBPT is there anything listed here that may be helpful to add that we might want to analyze or examine?\n@QUALBPT is there ever a case where we would need to analyze the interviewer's language?\n\nIn the case where an interviewer asks a question an exact way, we can enter the question as it is listed on the interview guide. However, this is not always the best way to run an interview when you're following a more relaxed vibe. So, it may be helpful to have the interview guide (or deck, whatever the interviewer used to facilitate the discussion) and the transcript opened to identify the order of discussion and section labels, and to identify where those key markers of the text are going to identify your questions. \n\nWhat is a good example of a question list if the interviewer did not read the question verbatim? Let's imagine the first question listed on the interview guide is \"What kinds of barriers do you think prevent community members from accessing services in the county?\". \n\nBad example: \"accessing services\" this is a bad example because this phrase has been marked as an identifier for a question, so any instance of \"accessing services\" comes up will count the phrase as a question.\n\nGood example: \"barriers do you think prevent community members from accessing services\" it is less likely for someone to have used this exact string of words in the conversation, so we're safe to mark this as a question identifier. \n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### PDFs\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n### Excel sheets\n\nOf course, we also tend to ask qualitative questions in some of our surveys at OMNI, and these types of data should be read in like quantitative data and should already be in a clean format if you follow the data cleaning guide (insert link to data cleaning guide).\n\n### @QUALBPT Any other forms of text we use?\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# QA Checklist for Qual Cleaning\n\n[ ] Are participant and interviewer roles correctly labeled?\n[ ] Have names, locations, and job titles been de-identified?\n[ ] Are timestamps removed (unless needed for analysis)?\n[ ] Are discussion sections correctly labeled?\n[ ] Has text been standardized (case, punctuation, spacing)?\n[ ] Is the cleaned dataset in a tidy format (one speaker turn per row)?\n[ ] Has the cleaned dataset been reviewed by another team member?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}