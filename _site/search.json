[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Qualitative Best Practices at Omni",
    "section": "",
    "text": "Our BPT specializes in qualitative research methods; providing expertise, guidance, and support to OMNI teams; and building internal company capacity for qualitative approaches.\nBy centering participant voices, documenting our methods clearly, and maintaining a reflexive stance, this guide strengthens the credibility and usefulness of Omni‚Äôs qualitative work. It equips staff with tools and strategies that not only meet evaluation standards but also foster accountability, responsiveness, and connection to the communities we serve.\nDo not share this website outside of Omni\n\nKey Features of this Website:\n\n\n\n\n\n\n  \n  \n\n\n\nTool Flexibility: While R is our preferred tool for reproducibility and integration with quantitative methods, the guide also includes best-practice workflows for using Dedoose (for team-based coding) and AI tools like NotebookLM (for early exploratory work).\n\n\n\n\n  \n\n\n\nMethod Selection Guidance: We offer practical decision points based on dataset size, analytic goals, and project context, ensuring methods match the scope and purpose of each evaluation.\n\n\n\n\n  \n  \n  \n\n\n\nStructured Workflows: Omni workflows help analysts navigate all stages of qualitative analysis‚Äîfrom clarifying analytic frameworks and coding approaches to integrating qualitative and quantitative data in mixed-methods designs.\n\n\n\n\n  \n  \n  \n\n\n\nAdaptability: Whether you're working with rich interview transcripts or brief open-ended survey responses, the guide provides adaptable tools that emphasize rigor, transparency, and context.\n\n\n\n\nOmni‚Äôs approach to qualitative data collection, analysis, and reporting, is grounded in building deep understanding of evaluation questions through a community-centered approach. We emphasize participant protections, trust building, a neutral facilitation approach, and culturally responsive design to create a rich and contextualized understanding of the data. We recognize participants as the experts of their own experience, holders of important and valuable knowledge, and elucidators of rich and varied stories, experiences, and perspectives around key issues.\nWe use a strengths-based and trauma-informed approach, attuned to the culture and context of the participants, and focused on surfacing the root causes behind inequities. We are committed to using our qualitative methods to provide valuable insights that can inform decision-making processes and positively impact communities.\nOur team has extensive experience with the use of focus groups, key informant interviews, document review, and facilitated discussions. We also employ more innovative practices including photovoice and community open house events that foster community engagement and dialogue around data and key issues. We utilize a variety of analytic approaches, and include both deductive and inductive strategies. One of our most commonly utilized approaches is thematic analysis. This process involves identifying and interpreting patterns and themes within the data, allowing for a deeper understanding of core research questions. Omni primarily utilizes qualitative software for analysis, which is a qualitative analysis software program that supports the systematic analysis of textual data. As an online platform, a team of analysts can collaboratively code data and assess inter-rater reliability. We follow best practices in the field to ensure that our approaches are rigorous, transparent, and appropriate for the research questions at hand.\n\n\n\n\n\nVersion Control\n\n\n\n\nVersion\nDescription\nDate released\n\n\n\n\n-3.0\nAdd guides and resources to website\n2025-11-11\n\n\n-4.0\nAdding interactive features\n2025-08-14\n\n\n-5.0\nSecond draft for review and rebrand\n2025-08-14\n\n\n-6.0\nInitial draft for review\n2025-03-26"
  },
  {
    "objectID": "customization.html",
    "href": "customization.html",
    "title": "Customization",
    "section": "",
    "text": "Executive Summary"
  },
  {
    "objectID": "customization.html#purpose",
    "href": "customization.html#purpose",
    "title": "Customization",
    "section": "Purpose",
    "text": "Purpose\nThis guide was developed to support Omni staff in conducting methodologically sound, transparent, and reproducible qualitative analyses. It offers practical, step-by-step instructions and highlights best practices for text pre-processing, analysis, and reporting. Whether working with interview transcripts, focus groups, open-ended survey responses, or other text-based data, Omni teams can use this guide to produce findings that are both grounded in participants‚Äô voices and useful for program improvement and decision-making.\n\nHow does this guide align with Omni‚Äôs core values?\n\n\n\n  \n    \n      Inquiry\n      \n        Provides clear, rigorous methods that encourage thoughtful exploration of participants‚Äô experiences.\n      \n    \n  \n\n  \n    \n      Agility\n      \n        Equips staff with adaptable tools to meet diverse project needs and respond efficiently to change.\n      \n    \n  \n\n  \n    \n      Connection\n      \n        Centers participants‚Äô voices and strengthens relationships with the communities and partners we serve.\n      \n    \n  \n\n  \n    \n      Accountability\n      \n        Uses transparent, reproducible analysis practices to keep our work credible, ethical, and trustworthy."
  },
  {
    "objectID": "customization.html#what-this-guide-covers",
    "href": "customization.html#what-this-guide-covers",
    "title": "Customization",
    "section": "What This Guide Covers",
    "text": "What This Guide Covers\nYou‚Äôll find guidance on:\n\nText mining / Natural Language Processing (NLP)\n(e.g., word frequency, sentiment analysis, topic modeling)\nThematic and content analysis\n(e.g., dictionary-based coding, thematic coding frameworks)\nNarrative analysis @qualBPT do we need?\n(Optional: e.g., structural analysis, language style matching)\nVisualizing and reporting qualitative data\n(e.g., word clouds, bar charts, heatmaps, joint displays for mixed-methods)\n\nThese methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more.\nIn many applied settings, qualitative methods (and especially mixed-methods) are described in vague terms. Reports may mention ‚Äúthemes emerging‚Äù or ‚Äútriangulating findings,‚Äù but rarely explain the actual process used to get there. This vagueness makes it hard to replicate or assess qualitative findings and limits their credibility.\n\n\n\n\n\n\nAt Omni, we aim to avoid vague or ad hoc practices. We document\nclear, systematic workflows that integrate qualitative insights with\nquantitative data when appropriate.\n\n\n\n\nWhy Are Existing Descriptions of Methods So Vague?\nSeveral factors explain the common lack of clarity in methodology:\n\nDifferent disciplines (e.g., public health vs.¬†education research) use different frameworks, leading to inconsistent approaches.\nQuantitative research has standard tools (R, SPSS, Stata), but qualitative tools (NVivo, MAXQDA, Dedoose) often rely on manual processes and don‚Äôt always integrate cleanly with quantitative workflows.\nQualitative analysis requires human interpretation and reflexivity. Documenting every step is time-consuming, and under tight timelines, many organizations skip this critical process.\nQualitative and quantitative teams often work separately, without shared standards or mixed-methods integration.\n\n[Hannah is just messing around here to see how an .mp4 reads into R and plays]\n\n  \n  Your browser does not support the video tag.\n\n\n\n\n  \n    Omni's Approach to Analysis\n    \n      \n    \n  \n\n\nOmni‚Äôs qualitative practice is grounded in pragmatism and critical realism.\n\nPragmatism means we focus on providing useful, actionable insights for real-world decision-making. Our goal is to help clients understand participants‚Äô experiences in ways that inform policy, programs, and practice. This reflects a pragmatic stance rooted in the work of scholars like  Morgan (2007)  and  Danermark et al.¬†(2015) , emphasizing inquiry that is guided by consequences and utility.\nCritical realism acknowledges that while participants‚Äô experiences reflect real phenomena (barriers, challenges, successes), they are shaped by context and perspective. Influenced by  Fletcher‚Äôs (2017)  work and work by others, this perspective guides us to acknowledge our limitations, reflect on researcher influence, and avoid overstating claims.\nOmni‚Äôs qualitative practice draws on reflexive thematic analysis  (Clarke & Braun, 2006)  and content analysis  (Hseih & Shannon, 2005) , emphasizing the researcher‚Äôs active role in interpreting data and constructing themes, in alignment with our commitment to critical realism and methodological transparency.\n\n\n\nTransparent and Systematic Workflows\nAt Omni, we use structured qualitative and mixed-methods workflows. These processes are transparent, systematic, and designed to integrate qualitative and quantitative findings when appropriate.\n\nExample Omni Workflow for Qualitative analysis:\n\nClarify Purpose and Analytic Framework\n\n\nDefine the evaluation questions and purpose of the qualitative analysis\nSelect an analytic method\n\n\nPrepare and Familiarize with the Data\n\n\nClean transcripts/text\nRead through interviews, discussions, or sessions at least once (text like reports you may not need context for, use your discretion)\n\n\nSystematic Coding of the Data\n\n\nDeductive, Inductive, or hybrid\nDeductive coding uses predefined codes (like our dictionaries) to apply to our data\nInductive coding uses text mining or topic modeling to identify emergent themes\n\n\nTheme Development and Refinement\n\n\nAnalyze and refine codes/themes\n\n\nInterpretation and Synthesis\n\n\nCompare themes to evaluation questions and contextual frameworks\n\n\nExplore themes visually\nGet ready for reporting"
  },
  {
    "objectID": "customization.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "href": "customization.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "title": "Customization",
    "section": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI",
    "text": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI\n\n\n\n  \n\n    \n    \n      R\n      \n        \n          Best when\n          \n            Datasets are large or mixed (qual + quant), need audit trails.\n            You want reproducibility, automation, version control.\n            Time crunch with existing scripts/templates; IRR optional or phased.\n          \n        \n        \n          Pros\n          \n            Transparent, reproducible code; scalable pipelines.\n            Flexible: word freq, sentiment, dictionaries, topic models.\n            Precise visuals; integrates surveys/demographics easily.\n          \n          Cons\n          \n            Setup/learning curve.\n            Requires clear documentation to ensure shared understanding.\n          \n        \n      \n    \n\n    \n    \n      Dedoose\n      \n        \n          Best when\n          \n            Collaborative coding with a team; training new coders.\n            Small‚Äìmoderate corpora.\n            Quick turnarounds with IRR workflows built in the tool.\n          \n        \n        \n          Pros\n          \n            Multi‚Äëuser collaboration, role permissions, IRR features.\n            Low barrier for non‚Äëprogrammers.\n          \n          Cons\n          \n            License cost.\n            Automation/custom analyses limited vs. code.\n            Reproducibility/export trails less granular than scripted pipelines.\n          \n        \n      \n    \n\n    \n    \n      AI\n      \n        \n          Best when\n          \n            Early exploration: surfacing possible themes/codes quickly.\n            Short corpora; scoping questions; drafting a codebook.\n            Stakeholder previews before deeper human analysis.\n          \n        \n        \n          Pros\n          \n            Very fast; low barrier; helps brainstorm structures.\n            Can summarize, cluster, and compare at a glance.\n            Useful for iteration before moving to R or Dedoose.\n          \n          Cons\n          \n            Not a substitute for human interpretation; can hallucinate.\n            Inconsistent across runs; shallow context if prompts are weak.\n            Data governance/privacy limits‚Äîavoid sensitive uploads without approvals.\n          \n        \n      \n    \n\n  \n\n  \n  ‚Äπ\n  ‚Ä∫\n\n  \n  \n    \n    \n    \n  \n\n\n\n\n\n\n  \n    Method Selection\n    \n      \n    \n  \n\n\n\n\nOnce pre-processed, your data is ready for analysis. Selecting the right method depends on:\n\nHow much data you have\nYour research question(s)\nWhether you need exploratory insights or answers to specific questions\nYour integrative framework (if conducting mixed-methods)\n\n\n\n\n\n\nUnderstanding Your Data Before Analysis\nBefore starting pre-processing or analysis, it‚Äôs important to assess the scope and quality of your data. Take time to understand:\n\nHow many participants are included?\nHow much text do you have (word count, number of responses)?\nHow detailed are the responses (in-depth vs.¬†brief)?\nHow are participants grouped (by stakeholder type, session, etc.)?\nWhose voices are most important to elevate in this analysis?\n\nThis step ensures you choose methods that fit your dataset and align with your project goals. For example:\n\nSmaller datasets (under ~2,000 words) are well-suited to word frequency, sentiment analysis, or basic content analysis.\nLarger datasets (5,000+ words) can support topic modeling or advanced thematic analysis.\n\nAssessing your data upfront helps set realistic expectations for analysis and ensures your findings are grounded, transparent, and defensible.\n\n\nWorking with a Small Corpus\nAt Omni, qualitative research often happens in real-world settings, with tight timelines and limited participant availability. We may aim for 10 interviews and complete 5. We may expect long, detailed conversations and instead get brief answers. Even with these constraints, small datasets can still provide meaningful insights, especially when there is consistency across participant experiences.\nWhen working with limited data:\n\nFocus on what participants actually shared, rather than attempting to generalize.\nDocument patterns and recurring concerns, while linking them clearly to the project‚Äôs research questions.\nBe transparent about the number of participants, the methods used, and any limitations in interpretation.\n\nSmaller samples can still highlight critical issues‚Äîsuch as barriers to access or common recommendations for program improvement‚Äîbut the scope and representativeness of these findings should be clearly communicated.\n\n\nSuggested Methods by Dataset Size and Purpose\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: If you are working with open-ended\nresponses from a survey and have data from 30 or fewer\nparticipants, carefully consider whether the data are\nsufficient for meaningful analysis. In many cases, it is appropriate to\nreport that there were too few responses to analyze\nsystematically. However, if you need to report findings, be\ntransparent about limitations. Focus on describing frequently\nmentioned key words, rather than inferring broader themes.\nAvoid suggesting consensus when data are limited, and clearly state that\nfindings reflect input from a small number of\nparticipants. Transparent reporting maintains the credibility\nof your analysis.\n\n\n\n\n\nGrouping Voices to Guide Analysis\nBefore you start coding or analyzing, decide:\n\nWhose voices are we centering in this analysis?\nHow will we group participant responses?\n\nYour grouping choices influence:\n\nWhich perspectives are highlighted\nHow themes emerge\nWhat questions you can answer\n\nAt Omni, we might group data by:\n\nParticipant (individual experiences)\nStakeholder Group (e.g., educators vs.¬†public health professionals)\nDiscussion Section (e.g., barriers vs.¬†recommendations)\n\nThese decisions should align with the project‚Äôs goals and be clearly documented in reports and presentations.\n\n\nReady for Pre-processing?\nOnce you understand your data, you‚Äôre ready to start pre-processing!\n\n\n  \n    Cleaning and Pre-Processing Your Data"
  },
  {
    "objectID": "customization.html#terminology",
    "href": "customization.html#terminology",
    "title": "Customization",
    "section": "Terminology",
    "text": "Terminology\nBefore starting your pre-processing and analysis, it‚Äôs important to understand a few core terms. These concepts are essential for working with text data and deciding on the appropriate pre-processing and analysis steps.\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nTokenization\nBreaking text into units (words, phrases, sentences)\n\n\nStemming\nReducing words to their root (e.g., ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù)\n\n\nLemmatization\nReducing to dictionary form (e.g., ‚Äúbetter‚Äù ‚Üí ‚Äúgood‚Äù)\n\n\nStop Words\nCommon words often removed (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù)\n\n\nDocument-Term Matrix\nTable of word frequencies across documents\n\n\nTF-IDF\nTerm importance based on frequency and inverse document frequency\n\n\nCorpus\nCollection of text documents as one dataset\n\n\nDictionary\nList of keywords/phrases used to code or categorize text\n\n\n\n\n\n\n# Load all packages \nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(quanteda)\nlibrary(textstem)\nlibrary(sentimentr)\nlibrary(topicmodels)\nlibrary(flextable)\nlibrary(knitr)\nlibrary(omni)\n\n\n\n\n\nPre-processing prepares your qualitative data for analysis by cleaning, organizing, and standardizing text. This step ensures the data is usable for word frequency, sentiment analysis, topic modeling, and other text mining techniques.\nYou should always assess the scope and quality of your data first:\n\nAre the data cleaned (lowercase, removed participant names, punctuation, symbols)?\n\n\n\n\n\n\n\nCheck out our function that does all of these data cleaning tasks for\nyou in R! You can also segment your text by question, combine multiple\ninterviews and focus groups into one dataset, and more.\n\n\n\n\n Cleaning transcripts function \n\n\nHow much text do you have? (Word counts per document/response.)\nHow many participants contributed?\nHow detailed or shallow are the responses?\nWhose voices are you analyzing?\n\nOnce you understand your data, you can decide which pre-processing steps are appropriate."
  },
  {
    "objectID": "customization.html#tokenization",
    "href": "customization.html#tokenization",
    "title": "Customization",
    "section": "Tokenization",
    "text": "Tokenization\nTokenization breaks text into individual pieces‚Äîusually words, but sometimes phrases or sentences.\n\nMost text mining techniques require tokenized text.\nThis is common for word frequency analysis, sentiment analysis, and topic modeling.\nAfter tokenization, we lose the flow of sentences which is generally okay for some analyses, but not for narrative analysis or content analysis.\n\nWhat are Stop Words?\nStop words are common words like ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúbut‚Äù that don‚Äôt add much meaning on their own. Because we want to focus on broader themes from our participants‚Äô voices, we usually want to remove stop words after text is tokenized. This process allows us to focus on content-rich words, like nouns and verbs. We should remove stop words when running a word frequency analysis, topic modeling, or sentiment analysis.\nWe can also create custom stop words that we want to remove from our analyses, for example, location names or project-specific words that appear frequently but aren‚Äôt relevant to the analysis.\nExample:\n\nIn the example below, my custom stop words are ‚Äútravis‚Äù and ‚Äúcounty‚Äù, and they‚Äôre added to the stop_words bank which includes other words like ‚Äúbut‚Äù, ‚Äúis‚Äù, ‚Äúthe‚Äù, etc. If you‚Äôd like to see all of the stop words, see View(stop_words)."
  },
  {
    "objectID": "customization.html#stemming",
    "href": "customization.html#stemming",
    "title": "Customization",
    "section": "Stemming",
    "text": "Stemming\nStemming words cuts them down to their root forms (e.g., ‚Äúrunning‚Äù becomes ‚Äúrun‚Äù). This pre-processing step should primarily be used for topic modeling or for other analyses that you decide that exact word form isn‚Äôt critical. This step is recommended to use with larger datasets, with typically hundreds of documents or more, but for our purposes we recommend stemming any time you have enough data for topic modeling (around 5,000 total words)."
  },
  {
    "objectID": "customization.html#lemmatization",
    "href": "customization.html#lemmatization",
    "title": "Customization",
    "section": "Lemmatization",
    "text": "Lemmatization\nLemmatization converts words to their dictionary root and keeps the words readable to the user (e.g., ‚Äúbetter‚Äù becomes ‚Äúgood‚Äù). This pre-processing step should be used for word frequency analysis, sentiment analysis, or thematic/content analysis as it works will with small and large corpuses.\nLet‚Äôs compare the stem words, vs lemmatized words against the original tokenized words:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nline\nspeaker\nparticipant_id\nquestion\nsection\nsection_label\nsession\nword\nstem_word\nlem_word\n\n\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nbiggest\nbiggest\nbig\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nchallenges\nchalleng\nchallenge\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ntransportation\ntransport\ntransportation\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ncars\ncar\ncar\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nmakes\nmake\nmake\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ndifficult\ndifficult\ndifficult\n\n\n\n\n\n\n\n\nWhen to Use Stemming vs.¬†Lemmatization\n\n\n\n\n\n\nStemming\nLemmatization\n\n\n\n\nYou need speed over accuracy\nSlower but more accurate\n\n\nWorking with large datasets\nBetter for small datasets\n\n\nBasic information retrieval tasks\nBetter for nuanced analysis\n\n\nSearch engines or topic modeling where fine detail isn‚Äôt critical\nBetter for in-depth analysis\n\n\nNot concerned about human readability\nMaintains readable words)\n\n\n\n\n\n\n\n  \n    Analyses"
  },
  {
    "objectID": "customization.html#word-frequency-analysis",
    "href": "customization.html#word-frequency-analysis",
    "title": "Customization",
    "section": "Word frequency analysis",
    "text": "Word frequency analysis\n\n\n\n\nWord frequency analysis is a simple and effective method that counts how often specific words appear in your dataset. It‚Äôs often used early in qualitative analysis to get a general sense of prominent topics, but it can also be applied as a stand-alone method to identify frequently mentioned issues in participant responses. Word frequency works best when you have a reasonable amount of text to analyze. As a general best practice, having at least 100‚Äì200 content words (excluding stop words) allows for more reliable interpretation of patterns, though smaller datasets can still offer preliminary insights.\nTo ensure accuracy, it‚Äôs important to pre-process your text. Using lemmatized words helps avoid counting variations like ‚Äúrun‚Äù and ‚Äúrunning‚Äù separately, and removing stop words‚Äîcommon words such as ‚Äúthe‚Äù or ‚Äúand‚Äù‚Äîallows you to focus on terms that carry more meaning. In cases where participants mention names of places or projects repeatedly, custom stop word lists can also help refine the results.\n\n\nWhile word frequency counts themselves do not explain context or meaning, they can help point to emerging themes by highlighting concepts that recur across participants or within particular sections of discussion. For example, if words like ‚Äútransportation,‚Äù ‚Äúaccess,‚Äù and ‚Äúbarrier‚Äù frequently appear in responses about service challenges, they signal a potential theme that warrants deeper exploration. Word frequency analysis can also help guide more interpretive methods such as thematic or content analysis, and is most useful when findings are contextualized within the broader dataset and research goals.\n\n\n# A tibble: 6 √ó 2\n  word             n\n  &lt;chr&gt;        &lt;int&gt;\n1 time             4\n2 people           3\n3 access           2\n4 application      2\n5 applications     2\n6 process          2"
  },
  {
    "objectID": "customization.html#sentiment-analysis",
    "href": "customization.html#sentiment-analysis",
    "title": "Customization",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\nSentiment analysis is a method that measures the emotional tone of text by categorizing words or phrases as positive, negative, or neutral. It can be used to quickly gauge participants‚Äô attitudes toward a topic or to assess the overall tone of responses across interviews, focus groups, or surveys. Sentiment analysis works best when you have larger amounts of text‚Äîideally, datasets with several hundred words or more‚Äîbecause emotional tone can vary within short responses, making sentiment harder to interpret in very small datasets. However, it can still offer insights in smaller datasets when applied carefully and when results are presented as exploratory.\nBest practices for sentiment analysis include pre-processing your text by removing stop words and standardizing language through lemmatization. This ensures consistent scoring and avoids misclassifications due to word variations. Sentiment analysis typically relies on pre-built lexicons, such as Bing, AFINN, or the NRC Emotion Lexicon, which assign emotional values to words. It‚Äôs important to note that these lexicons were often designed for general use (such as social media text) and may require customization to fit specific public health or social science contexts. For example, in health-related interviews, a word like ‚Äútreatment‚Äù might appear frequently and carry different sentiment depending on the discussion‚Äôs focus.\nWhile sentiment analysis doesn‚Äôt capture nuance or context in the way manual coding can, it can highlight patterns of emotional tone across datasets or within specific discussion topics. For example, sentiment analysis might reveal that participants express more negative sentiment when discussing barriers to accessing services, and more positive sentiment when discussing recommendations for future improvements. These insights can help guide deeper qualitative coding or serve as an additional layer of analysis to support findings. As with any automated method, it‚Äôs important to review and interpret results in context and to document any limitations or adaptations made to the analysis.\n\n\n# A tibble: 2 √ó 2\n  sentiment     n\n  &lt;chr&gt;     &lt;int&gt;\n1 negative      5\n2 positive      3\n\n\n\n\n\n\n\n\n\nTip for finding quotes by tone\nLet‚Äôs say you want to pull a quote to include in a report and you know that you want it to be a positively toned quote in a ‚Äúrecommendations‚Äù section of your discussion. You can use the sentimentr package to gather sentiments of each sentence (or segment) and sort by sentiment score to find the quote with the most positive tone in your criteria.\nSee an example below:\n\n\n# A tibble: 7 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n7    10 participant P1                    0       3 Recommendatio‚Ä¶ prov‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: element_id &lt;int&gt;, avg_sentiment &lt;dbl&gt;,\n#   sd_sentiment &lt;dbl&gt;, n_sentences &lt;int&gt;\n\n\nMixed-methods with sentiment analysis\nBecause sentiment analysis gives you a numeric output as a sentiment score, you can imagine instances where you may want to compare sentiment scores between groups, correlate sentiment scores with other variables in a quantitative survey, or conduct pre-post comparisons."
  },
  {
    "objectID": "customization.html#topic-modeling",
    "href": "customization.html#topic-modeling",
    "title": "Customization",
    "section": "Topic modeling",
    "text": "Topic modeling\nTopic modeling is an automated method used to identify themes or topics across large collections of text. It uses algorithms to group together words that frequently appear in similar contexts, helping reveal hidden patterns or structures in qualitative data. Topic modeling is especially useful when you have large datasets‚Äîtypically a minimum of 5,000 words or more spread across multiple documents or participant responses. The method works best when documents are of relatively similar length, which helps the model assign topics more evenly.\nThis method is not recommended for use on smaller corpuses and would be considered poor practice to rely on it to generate meaningful insights. If you don‚Äôt have enough data for this analysis, consider using the content analysis strategy to identify themes in the data.\nBefore running a topic model, it‚Äôs important to pre-process your text. Best practices include stemming words to reduce variation (so that ‚Äúrun‚Äù and ‚Äúrunning‚Äù are treated as the same word) and removing stop words to focus on meaningful content. Topic modeling doesn‚Äôt require predefined codes or themes, making it a good exploratory tool for surfacing unexpected topics in your data. However, it‚Äôs important to remember that these topics are generated algorithmically‚Äîthey group terms based on statistical patterns, not human interpretation. As a result, human review is always needed to interpret and label the topics in a way that makes sense for your project and participants.\nTopic modeling can complement manual coding by offering a high-level view of common themes, pointing analysts toward areas that may warrant deeper exploration. For example, a topic model might surface clusters of words related to barriers (‚Äútransportation,‚Äù ‚Äúaccess,‚Äù ‚Äúcost‚Äù) and another cluster about solutions (‚Äúeducation,‚Äù ‚Äúoutreach,‚Äù ‚Äúsupport‚Äù), giving you a starting point for thematic analysis. Commonly used R packages for topic modeling include topicmodels, which provides algorithms like Latent Dirichlet Allocation (LDA), and tm for pre-processing and managing textual data.\n\n\n[1] 46.1033\n\n\n[1] 46.13593\n\n\n# A tibble: 20 √ó 3\n# Groups:   topic [2]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0617\n 2     1 transportation 0.0544\n 3     1 services       0.0467\n 4     1 residents      0.0313\n 5     1 challenges     0.0297\n 6     1 agree          0.0281\n 7     1 lot            0.0278\n 8     1 access         0.0276\n 9     1 applications   0.0275\n10     1 application    0.0274\n11     2 people         0.0800\n12     2 time           0.0695\n13     2 process        0.0485\n14     2 application    0.0381\n15     2 applications   0.0381\n16     2 access         0.0380\n17     2 timeconsuming  0.0264\n18     2 campaigns      0.0260\n19     2 buses          0.0254\n20     2 simplifying    0.0253\n\n\n# A tibble: 30 √ó 3\n# Groups:   topic [3]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0778\n 2     1 transportation 0.0543\n 3     1 services       0.0542\n 4     1 lot            0.0390\n 5     1 residents      0.0353\n 6     1 applications   0.0347\n 7     1 access         0.0312\n 8     1 vouchers       0.0261\n 9     1 makes          0.0256\n10     1 planning       0.0249\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "customization.html#content-analysis",
    "href": "customization.html#content-analysis",
    "title": "Customization",
    "section": "Content analysis",
    "text": "Content analysis\nContent analysis is a method used to count how often predefined concepts, themes, or categories appear in qualitative data. It relies on a dictionary‚Äîa list of key terms or phrases‚Äîdesigned to reflect your evaluation questions or coding framework. Content analysis works well for both small and large datasets, making it a flexible tool when you want to systematically measure the presence of specific themes across interviews, focus groups, or open-ended survey responses.\nA key requirement for effective content analysis is a carefully designed dictionary that accurately captures the concepts you‚Äôre interested in. This might include terms related to barriers, facilitators, or recommendations, depending on the project‚Äôs goals. Best practice is to validate the dictionary by reviewing examples of matched text to make sure the terms are identifying the intended content. You may need to refine the dictionary over time, adding synonyms or removing words that generate false positives.\nContent analysis can help answer questions like ‚ÄúHow frequently do participants mention prevention strategies?‚Äù or ‚ÄúWhat percentage of responses reference funding challenges?‚Äù It is particularly useful when you need to quantify qualitative data for reporting purposes, or when you want to compare how frequently themes appear across different stakeholder groups. In R, the quanteda package offers efficient tools for dictionary-based content analysis, allowing you to apply a dictionary and quickly summarize how often key terms or concepts appear in the dataset.\n\n\nDocument-feature matrix of: 7 documents, 109 features (81.26% sparse) and 0 docvars.\n       features\ndocs    sure i think one of the biggest challenges is transportation\n  text1    1 1     1   1  5   2       1          1  1              1\n  text2    0 1     0   0  0   0       0          0  0              0\n  text3    0 0     0   0  1   0       0          0  0              0\n  text4    0 0     0   0  0   4       0          0  1              0\n  text5    0 0     0   0  0   0       0          0  0              0\n  text6    0 0     0   0  0   1       0          0  0              0\n[ reached max_ndoc ... 1 more document, reached max_nfeat ... 99 more features ]\n\n\nDocument-feature matrix of: 7 documents, 3 features (85.71% sparse) and 0 docvars.\n       features\ndocs    prevention treatment harm_reduction\n  text1          0         1              0\n  text2          0         0              0\n  text3          1         0              0\n  text4          0         0              0\n  text5          2         0              0\n  text6          0         0              0\n[ reached max_ndoc ... 1 more document ]\n\n\n[1] \"text1\" \"text2\" \"text3\" \"text4\" \"text5\" \"text6\"\n\n\n# A tibble: 6 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: doc_id &lt;chr&gt;, prevention &lt;dbl&gt;, treatment &lt;dbl&gt;,\n#   harm_reduction &lt;dbl&gt;"
  },
  {
    "objectID": "customization.html#thematic-analysis-in-dedoose",
    "href": "customization.html#thematic-analysis-in-dedoose",
    "title": "Customization",
    "section": "Thematic Analysis in Dedoose",
    "text": "Thematic Analysis in Dedoose\n@qualBPT help here!! Can we add anything re coding to this guide in this section, maybe Ivonne‚Äôs work? What other programs should we add?\nIf using Dedoose to conduct thematic analysis, we recommend a structured, reflective approach grounded in reflexive thematic analysis (Clarke & Braun, 2006) and informed by critical realism.\nHere‚Äôs how to approach it:\n\nStart with Familiarization Read through transcripts or responses in full before coding.\n\nUse memos to reflect on initial impressions, patterns, and researcher assumptions.\n\nDevelop Codes Iteratively Begin with inductive coding (bottom-up), focusing on what participants actually say.\n\nAvoid pre-loading the codebook unless doing deductive analysis is needed for evaluation purposes.\nUse Dedoose‚Äôs ‚ÄúDescriptor‚Äù fields to track context (e.g., stakeholder group, session type) for later analysis.\n\nApply Codes Reflexively Apply codes carefully, updating definitions and merging/splitting codes as needed.\n\nEncourage coders to discuss disagreements and maintain an audit trail of key coding decisions.\n\nConstruct Themes Thoughtfully After coding, review excerpts by code and group them into broader themes that reflect patterns across participants.\n\nUse Dedoose‚Äôs ‚ÄúCode Co-Occurrence‚Äù and ‚ÄúCode Application‚Äù tools to explore theme structure.\n\nAcknowledge Researcher Role Reflect on how your perspective, language, and interpretation influence theme development.\n\nBe cautious not to overstate findings; describe patterns and nuance rather than asserting consensus.\n\nDocument Everything Keep a record of how codes and themes evolved.\n\nClearly state the number of participants or excerpts that informed each theme.\nMake your interpretive lens and limitations explicit‚Äîespecially when datasets are small or uneven across groups.\n\nThematic analysis in Dedoose should still reflect Omni‚Äôs commitment to critical realism: treat participant input as reflecting real issues shaped by context and perspective, and be transparent about what the data can‚Äîand cannot‚Äîsupport."
  },
  {
    "objectID": "customization.html#combining-analyses",
    "href": "customization.html#combining-analyses",
    "title": "Customization",
    "section": "Combining analyses",
    "text": "Combining analyses\nNo single method can fully capture the richness and complexity of qualitative data. At Omni, we often combine different qualitative analysis approaches to explore various angles of our data and answer nuanced evaluation questions. Pairing methods like word frequency, sentiment analysis, content analysis, and thematic analysis can help reveal both patterns and meaning, ensuring our findings are grounded in evidence and provide actionable insights."
  },
  {
    "objectID": "subtab1.html",
    "href": "subtab1.html",
    "title": "Subtab1 test",
    "section": "",
    "text": "Manager‚Äôs Summary\nData Cleaner‚Äôs Summary"
  },
  {
    "objectID": "subtab1.html#quarto",
    "href": "subtab1.html#quarto",
    "title": "Subtab1 test",
    "section": "",
    "text": "Manager‚Äôs Summary\nData Cleaner‚Äôs Summary"
  },
  {
    "objectID": "subtab1.html#running-code",
    "href": "subtab1.html#running-code",
    "title": "Subtab1 test",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "subtab1.html#introduction",
    "href": "subtab1.html#introduction",
    "title": "Subtab1 test",
    "section": "Introduction",
    "text": "Introduction\nDo not share this guide outside of OMNI\nData cleaning is often one of the first things you will do when you start working with qualitative data at OMNI. Whether we‚Äôre working with interview transcripts, focus group discussions, or open-ended survey responses, the raw data we receive is rarely ready for immediate analysis. Cleaning is not just about tidying up; it‚Äôs about making informed decisions that clarify the meaning and integrity of the data while preparing it for systematic analysis.\nThe decisions we make during the cleaning process are every bit as complex and impactful as those made during coding and analysis. Thoughtful data cleaning can preserve the richness of qualitative data, while careless decisions can distort or diminish participants‚Äô voices. Therefore, it is especially important to have a strong set of working principles to guide your decisions when cleaning qualitative data.\nThis guide covers a general approach to qualitative data cleaning, with an emphasis on useful R packages and functions designed to conquer some common challenges. While this guide includes tools and code to make your life easier, it also offers guidelines for making judgment calls about what to remove, retain, or clarify in the data.\nThe steps in a qualitative data cleaning process will always be informed by two key factors:\n\nThe state of the data when we (OMNI) receive it\n\n\nFor example, some transcripts may come from automated services (like Zoom or Otter.ai) and contain timestamps, speaker labels, or filler words that require removal. Others may be professionally transcribed and need minimal cleaning.\n\n\nThe specific needs of the project Because of this variability, we encourage a flexible, judgment-driven approach to data cleaning. The steps described in this guide are common to many projects, but their order and application should be tailored to the needs of the dataset and the analytic goals of the project. Importantly, depending on the type of analysis, different cleaning steps may be required. Consult the analysis plan and research questions in your project materials to verify the needs of the project.\n\n\nSupporting resources"
  },
  {
    "objectID": "subtab1.html#rationale",
    "href": "subtab1.html#rationale",
    "title": "Subtab1 test",
    "section": "Rationale",
    "text": "Rationale\nWhen we clean qualitative data, we apply a series of thoughtful transformations that make the data clearer, more consistent, and usable for analysis. Qualitative data cleaning requires attention to detail and sensitivity to the context in which the data were collected. The procedures we use need to be flexible because the downstream purposes of the data can vary from project to project‚Äîwhether for thematic coding, content analysis, or mixed-methods integration.\nThe qualitative data cleaner often has to make many judgment calls during this process. These decisions are guided by the project‚Äôs goals, the nature of the source data, team experience, and guidance documents (like this one). Every decision and its rationale should be clearly documented in the data cleaning script or data log (more on that below). Transparency in this process ensures that the cleaned dataset remains trustworthy and aligned with our ethical standards for qualitative research.\nQualitative data cleaning requires a lot of careful thought and attention. The R code that cleans text data needs to be clearly written and well-commented, not only for reproducibility but to ensure that meaning is preserved, and participant voices are not inadvertently altered or diminished. In qualitative work, the cleaning process can directly impact the integrity of the analysis.\nJust as with quantitative analysis, qualitative data-cleaning decisions are made with greater ease and clarity when there is a clear work plan, guided by the project‚Äôs research questions or evaluation goals. Having a shared understanding of what the team hopes to explore in the data helps inform:\nWhat should be cleaned What should be preserved (even if messy) What should be flagged for discussion Two especially helpful documents to have before qualitative data cleaning begins are:\nA codebook (or at least a data dictionary) This helps ensure consistency in how we treat things like speaker names, special terminology, or sensitive content. A data analysis plan This outlines the team‚Äôs approach to coding and analysis and helps identify if additional cleaning steps are necessary. For example: anonymizing sensitive details or removing artifacts from automated transcription tools (timestamps, filler words, etc.). Whenever possible, we expect teams to develop a data analysis plan and request any available data dictionaries or codebooks from the client or partner organizations who collected the data. However, you may need to create a codebook if one doesn‚Äôt exist‚Äîfeel free to reach out to the QualBPT (or whichever team you want to point folks to) if you need support.\nIn many cases, the people drafting the analysis plan are different from those cleaning the qualitative data, so strong cross-team communication is essential. We recommend including the qualitative data cleaner (or cleaning team) in project discussions as early as possible. When drafting the analysis plan, think through what text cleaning steps will be necessary to make the data usable for coding, protect participant confidentiality, and meet the project‚Äôs goals.\nFinally, whether you‚Äôre writing code for qualitative data cleaning or any other purpose, always write your R scripts as if they will later be:\n\nHeavily scrutinized\nHeld up as example code\nModified by someone brand new to both R and the project\n\nMake it easy on future OMNI-ites‚Äîand on your future self!"
  },
  {
    "objectID": "subtab1.html#when-are-data-clean",
    "href": "subtab1.html#when-are-data-clean",
    "title": "Subtab1 test",
    "section": "When are data clean?",
    "text": "When are data clean?\n‚úÖ What Does It Mean to Have ‚ÄúClean‚Äù Qualitative Data? For there to be project tasks that direct OMNI-ites to ‚Äòclean qualitative data,‚Äô and a guide to help in doing so, there should also be a shared understanding of what it means for qualitative data to be clean.\nüìù Definition of Clean Qualitative Data: At OMNI, qualitative data are considered clean when they are organized, de-identified, and ready for analysis or coding.\nThat means the data:\nAccurately reflect the original source material (e.g., interviews, focus groups, or open-text survey responses) Have been transformed into a structure that makes them easy to navigate and analyze Protect the privacy and confidentiality of participants Are consistent, clear, and free of irrelevant clutter (like transcription artifacts) üéØ What Makes a Qualitative Dataset ‚ÄúAnalysis-Ready‚Äù? For qualitative text data to be ready for analysis, they should meet the following criteria:\nSpeaker Information Is Clear and Consistent\nParticipant speakers and interviewers are clearly labeled in the data. Each speaker‚Äôs text is grouped logically into segments, preserving conversational flow. Participant Identifiers Are Specified and Protected\nReal names, locations, and other direct identifiers have been removed or replaced with participant IDs or pseudonyms. Confidential information (e.g., agency names, job titles, organizations) is anonymized where necessary, following OMNI‚Äôs confidentiality guidelines. Questions Are Clearly Distinguished From Responses\nInterviewer questions (or prompts) are labeled or separated from participant responses, as appropriate. This can be done by adding question text as its own field in the dataset or by adding markers in the transcript. Text Segments Are Ordered and Organized\nThe transcript text is ordered according to the flow of conversation. Segments are correctly time-sequenced (even if timestamps themselves are removed). Text Is Structured Into a Tidy, Rectangular Format\nEach row represents a single speaker turn or unit of analysis (e.g., a complete response to a question). Data are stored in a rectangular table (data frame), with columns for: Session name or group (e.g., ‚ÄúEducators‚Äù or ‚ÄúPublic Health‚Äù) Participant ID or role (e.g., ‚ÄúParticipant 1,‚Äù ‚ÄúFacilitator‚Äù) Text segment (the response or comment) Any relevant metadata (e.g., discussion section, date) Timestamps and Transcription Artifacts Are Removed\nAll timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless specifically required for analysis. Automated transcription quirks (e.g., repeated words, filler words, auto-captions like ‚Äú[inaudible]‚Äù) are reviewed, cleaned, or flagged. Text Is Consistent in Style and Format\nAll text is converted to lowercase, unless case is important for analysis. Spelling errors are corrected when they obscure meaning (but regional spellings or participant quirks may be preserved if relevant). Punctuation and spacing are standardized (no excessive whitespace, missing periods, etc.). Relevant Identifiers Are Added to the Dataset\nIf there are multiple sessions or groups, these are labeled (e.g., ‚ÄúEducators,‚Äù ‚ÄúPublic Health‚Äù). If there are themes or discussion sections (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù), these are identified. If codes are pre-assigned for analytic purposes (e.g., ‚ÄúPre-implementation,‚Äù ‚ÄúPost-implementation‚Äù), they are included in the data structure. üí° How Do We Know When Qualitative Data Are Clean? Here are some guiding questions to help determine when qualitative data are ready for analysis (i.e., clean):\nWhat is the plan for coding or analyzing this data?\nThe analysis plan (or coding framework) should inform cleaning decisions. For example, if the team plans to do thematic coding, they‚Äôll need text organized into meaningful speaker turns or responses. What needs to be anonymized?\nIdentify any sensitive information that must be redacted or replaced to maintain confidentiality and ensure participant privacy. Are speaker turns properly attributed and easy to follow?\nEach speaker‚Äôs contributions should be clearly labeled, consistently formatted, and grouped logically. Are responses to specific questions clearly identifiable?\nIf interviews or focus groups follow a semi-structured guide, it‚Äôs important to separate questions from responses for clarity in analysis. Is the structure of the data appropriate for the analytic tool?\nIf the data are being uploaded to Dedoose, NVivo, or another platform, they should follow the required format (e.g., tidy data frame with speaker IDs and group names). Have all unnecessary artifacts been removed?\nTime stamps, filler words, and transcription errors that don‚Äôt add value to the analysis should be removed. Has the cleaned data been reviewed by someone else (QA check)?\nWhenever possible, have another OMNI-ite review the cleaned data for accuracy and completeness. ‚ú® Common Issues to Discuss Early in the Cleaning Process Just like in quantitative data cleaning, clarifying expectations at the start of a project will save time later. For qualitative projects, consider these:\nWill we analyze both facilitator questions and participant responses, or just participant responses? How will we handle overlapping speech, interruptions, or incomplete thoughts? Do we need to standardize participant roles (e.g., ‚ÄúPublic Health Official‚Äù vs.¬†‚ÄúPH Staff‚Äù) for consistency? Are we preparing data for manual coding or automated text analysis? Do we need to translate or transcribe non-English responses? Do we need to connect text segments with broader context, such as the discussion theme or section of the focus group? üöÄ In the Following Sections‚Ä¶ We‚Äôll see how these fundamentals‚Äîlike tidy qualitative data, pipes, and regular expressions‚Äîplay out in real-world cleaning tasks, such as:\nRemoving timestamps and filler words Labeling speakers and organizing segments Anonymizing sensitive information Structuring text for analysis software (Dedoose, NVivo, etc.) ‚úÖ Quick Summary of ‚ÄúClean Qualitative Data‚Äù at OMNI: Clean qualitative data are:\nAnonymized Clearly structured and labeled Organized for easy analysis Free of unnecessary artifacts Ready for use in coding and interpretation"
  },
  {
    "objectID": "subtab1.html#how-do-i-report-the-results-of-data-cleaning",
    "href": "subtab1.html#how-do-i-report-the-results-of-data-cleaning",
    "title": "Subtab1 test",
    "section": "How do I report the results of data cleaning?",
    "text": "How do I report the results of data cleaning?\nüìù How to Report the Results of Qualitative Data Cleaning at OMNI Cleaning qualitative data is an interpretive and decision-heavy process, and those decisions need to be transparent. Reporting your cleaning process helps:\nProject leads understand what‚Äôs been done and why. Provide documentation in case changes need to be made later. Build trust in the integrity of the cleaned dataset. Support future qualitative coding, interpretation, and reporting. Qualitative data cleaning produces results‚Äîchanges to the text or data structure‚Äîthat should be documented in a clear, shareable data cleaning report.\nüìã What to Include in a Qualitative Data Cleaning Report 1. Summary of the Dataset You Cleaned Start with an overview:\nHow many transcripts or files were cleaned? How many sessions (e.g., focus groups, interviews) are included? What types of participants are represented (e.g., educators, public health professionals)? Example: This dataset includes transcripts from 8 focus groups, with 42 participants. Participants represent two stakeholder groups: Educators (n = 20) and Public Health Professionals (n = 22).\n\nAnonymization and De-Identification Steps Document what you removed or replaced to protect confidentiality.\n\nWere participant names replaced with IDs (e.g., Participant 01)? Were organizations, locations, or personal identifiers removed or redacted? Were job titles generalized (e.g., ‚ÄúCEO‚Äù changed to ‚Äúsenior leader‚Äù)? Example: Replaced all participant names with Participant IDs (e.g., P01). Removed specific references to organizations and locations (e.g., ‚Äúat Boulder Community Hospital‚Äù becomes ‚Äúat [hospital]‚Äù). Redacted job titles for anonymity when mentioned alongside unique organizations.\n\nSpeaker Labeling and Text Structuring Describe how speakers were labeled and how the transcript was organized.\n\nWere speakers consistently labeled as ‚ÄúParticipant‚Äù and ‚ÄúFacilitator‚Äù? Was each speaker turn separated into its own row or segment? Were questions separated from responses? Example: Speaker turns were labeled consistently as either Facilitator or Participant. Each speaker turn is stored as one row in the cleaned dataset, with associated metadata (Session name, Speaker role, Discussion section).\n\nArtifacts Removed (Timestamps, Filler Words, etc.) Note what transcription artifacts were removed or edited:\n\nWere timestamps deleted? Were filler words (e.g., ‚Äúum,‚Äù ‚Äúuh‚Äù) removed? If so, specify whether this was systematic or case-by-case. Were transcription errors corrected? Example: Removed all timestamps in the format [hh:mm:ss]. Deleted common filler words (‚Äúum,‚Äù ‚Äúuh‚Äù) unless they contributed to participant meaning or tone. Reviewed and corrected auto-transcription errors (e.g., ‚ÄúDodoose‚Äù corrected to ‚ÄúDedoose‚Äù).\n\nText Standardization and Formatting Summarize standardization steps for readability and consistency:\n\nWas text converted to lowercase? Was spelling corrected? If so, did you preserve participant colloquialisms? Were consistent punctuation and spacing applied? Example: Converted all text to lowercase for consistency. Standardized punctuation (e.g., added periods to sentence ends where missing). Corrected spelling errors that obscured meaning but preserved participant vernacular and tone where appropriate.\n\nMetadata or Contextual Information Added Note any metadata added to support analysis:\n\nSession name (e.g., ‚ÄúEducators‚Äù vs.¬†‚ÄúPublic Health Professionals‚Äù) Discussion section (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù) Participant role or group designation Example: Added metadata fields to identify Session Name, Participant Group (Educator/Public Health), and Discussion Section (Barriers, Facilitators, Recommendations).\n\nKey Decisions Made During Cleaning Flag any important decisions that could impact analysis:\n\nIf you excluded any portions of text (e.g., off-topic discussions), document what was excluded and why. If you made choices about retaining or removing interruptions, overlapping speech, or non-verbal cues, describe the rationale. If you generalized identifying details in ways that may impact interpretation, note this. Example: Excluded introductory small talk (greetings, logistics discussions) from the analysis dataset. Retained overlapping speech where relevant to the discussion. Generalized certain job titles to preserve anonymity (e.g., ‚ÄúHead Nurse‚Äù changed to ‚ÄúMedical Staff‚Äù).\n\nCounts and Summaries Where Relevant When helpful, include counts that summarize:\n\nHow many identifiers were removed? How many sessions, speakers, or responses are in the final dataset? If you organized by themes, how many segments are in each theme? Example: Final cleaned dataset includes 8 focus groups, 42 participants, and 620 participant responses across three discussion sections: Challenges (n = 220), Facilitators (n = 200), and Recommendations (n = 200).\nüí° Tips for Reporting Qualitative Data Cleaning Be Transparent Even small decisions (e.g., standardizing speaker labels) can have big implications during analysis. If you‚Äôre unsure whether to document something, document it!\nTake the Perspective of Your Project Lead or Analyst What decisions might they need to revisit later? What context would help them understand how the data were shaped?\nSupport Replicability and Quality Control Your cleaning report should make it easy for another team member to:\nUnderstand what was done Re-run the cleaning script Suggest or request changes with full knowledge of the process üñºÔ∏è Example Summary Table in a Qualitative Cleaning Report Cleaning Step Action Taken Notes Anonymization Removed names, replaced with Participant IDs (P01-P42) Locations and job titles generalized Speaker Labeling Labeled as Facilitator or Participant Consistent across all sessions Timestamps Removed Deleted all timestamps (hh:mm:ss)\nFiller Words Removed ‚Äúum,‚Äù ‚Äúuh‚Äù except when indicating hesitation Case-by-case review Text Standardization Converted to lowercase, corrected major spelling errors Preserved participant language/tone Metadata Added Session name, participant group, discussion section Useful for subgroup analysis Exclusions Removed introductions, off-topic discussions Documented in the data log"
  },
  {
    "objectID": "subtab1.html#terminology",
    "href": "subtab1.html#terminology",
    "title": "Subtab1 test",
    "section": "Terminology",
    "text": "Terminology\nüìù Relevant Terminology for Qualitative Data Cleaning in R üîß Data Structure & Format Terms Transcript A written or typed record of spoken language from interviews, focus groups, or meetings. Transcripts may include speaker labels, timestamps, and other artifacts that need cleaning.\nTurn-Taking Each time a participant or facilitator speaks is called a ‚Äúturn.‚Äù Clean data often organize these turns into individual rows in a dataset.\nSegment (or Excerpt) A portion of text, such as a paragraph, sentence, or speaker turn, treated as a unit for coding or analysis. Segments are often defined by the speaker‚Äôs response or by topic.\nTidy Data Data where:\nEach row represents a single observation (e.g., a speaker turn or segment) Each column contains one type of information (e.g., speaker ID, text, session group) Tidy data make it easier to manipulate, clean, and analyze qualitative datasets in R. Rectangular Data Another term for a table or data frame, where rows and columns are used to organize data in R.\nüóÇÔ∏è Qualitative Metadata & Labeling Terms Speaker Label An identifier showing who is speaking (e.g., ‚ÄúFacilitator,‚Äù ‚ÄúParticipant 1‚Äù). Clean data should use consistent speaker labels.\nParticipant ID A unique identifier assigned to participants to protect anonymity (e.g., ‚ÄúP01‚Äù). These are often used in place of names.\nSession ID / Group The label identifying the specific interview or focus group a participant was part of (e.g., ‚ÄúSession 1 ‚Äì Educators‚Äù).\nDiscussion Section / Topic Area A label identifying a portion of the conversation (e.g., ‚ÄúBarriers,‚Äù ‚ÄúRecommendations‚Äù) to help organize qualitative data.\n‚úÇÔ∏è Data Cleaning & Transformation Terms Anonymization / De-Identification The process of removing or replacing personal identifiers (e.g., names, locations, job titles) to protect participant privacy.\nStandardization Making text consistent in format (e.g., converting to lowercase, consistent punctuation, spacing).\nTokenization (Optional depending on your analysis!) Breaking down text into smaller parts‚Äîwords, sentences, or phrases‚Äîtypically for text mining. Not always part of standard qualitative coding workflows.\nFiltering Removing unnecessary rows or segments (e.g., small talk, off-topic responses) from the data.\nRecoding Transforming data from one format to another (e.g., generalizing job titles or grouping participant roles).\nJoin / Merge Combining two datasets based on a shared key (e.g., merging participant demographic info with transcripts).\nPivoting Restructuring data from wide format (many columns) to long format (many rows), or vice versa, to make it easier to analyze or display.\nüè∑Ô∏è Text Cleaning Terms Timestamps Time markers in transcripts (e.g., [00:12:34]) that need to be removed unless necessary for the analysis.\nFiller Words Common speech disfluencies (e.g., ‚Äúum,‚Äù ‚Äúuh,‚Äù ‚Äúlike‚Äù) that can be removed for clarity, depending on analysis goals.\nInaudibles / Transcription Errors Markers like ‚Äú[inaudible]‚Äù or machine transcription errors that need to be corrected or flagged.\nSpelling and Grammar Standardization Correcting spelling errors that make text difficult to read, while preserving participant voice and tone where relevant."
  },
  {
    "objectID": "subtab1.html#reading-your-data-into-r",
    "href": "subtab1.html#reading-your-data-into-r",
    "title": "Subtab1 test",
    "section": "Reading your data into R",
    "text": "Reading your data into R\nFirst, we‚Äôll need to read our data into R. Depending on how your raw text is stored, you‚Äôll need to take various steps to read in your data for analysis. The goal is to turn any of your text into a dataframe with rows and columns of your text responses. In some cases, you may need to keep participant ID columns or other columns if you‚Äôre doing a mixed-method analysis. In other cases, you may be analyzing different focus groups and comparing them to eachother. Whatever you are doing, make sure your dataframe is set up or your analysis. If you are unsure about this, ask Hannah or a member of Qual BPT for some help!\nHere is an example of what your data may look like when you first read it into R.\n\nand here‚Äôs what we want it to look like (eventually) for most of our analysis needs.\n\nWith clean data, we can:\n\nCompare participants‚Äô responses across sessions and discussion sections. We could answer questions like:\n\nWhat did Educators say about Community Impact vs.¬†Public Health?‚Äù\nWhat did participants across all interviews think about abatement funds?\n\nFilter by participant role (e.g., facilitators vs.¬†participants) for targeted analysis. We could answer questions like:\n\nHow many participants mentioned that the county should invest in wraparound services across all interviews?\nWhat is the most common barrier in accessing services in the county?\n\nPreserve anonymity by removing names and identifiers.\n\n\nZoom transcripts\nOne of the main forms of qualitative data we receive includes Zoom transcripts. Below is a function you can use to clean your Zoom transcripts and get them to a tidy format by entering the interviewer name(s), and key phrases used by the interviewer to mark the section of the discussion. For example, an interview might begin with an introduction, then include a discussion of barriers, and a discussion of strengths. We‚Äôll likely want to separate these out into sections so our analyses can speak to each section independent of each other, rather than be clumped altogether.\nAnd when you want to clean the transcripts and mark the interviewer, you can add the names of the interviewers here.\nThis function works for Zoom transcripts that are saved as Word documents or .txt files. There are few things you need to specify in the function, including updating the file path, the interviewers, setting your list of questions, adding section labels, and the session name.\nThis example comes from the Loudoun County Opioid Abatement project where Shon, Lindsay, Hannah, Luke, Eden, and Arden are staffed, so any of them could have been an interviewer.\n@QUALBPT is there anything listed here that may be helpful to add that we might want to analyze or examine? @QUALBPT is there ever a case where we would need to analyze the interviewer‚Äôs language?\nIn the case where an interviewer asks a question an exact way, we can enter the question as it is listed on the interview guide. However, this is not always the best way to run an interview when you‚Äôre following a more relaxed vibe. So, it may be helpful to have the interview guide (or deck, whatever the interviewer used to facilitate the discussion) and the transcript opened to identify the order of discussion and section labels, and to identify where those key markers of the text are going to identify your questions.\nWhat is a good example of a question list if the interviewer did not read the question verbatim? Let‚Äôs imagine the first question listed on the interview guide is ‚ÄúWhat kinds of barriers do you think prevent community members from accessing services in the county?‚Äù.\nBad example: ‚Äúaccessing services‚Äù this is a bad example because this phrase has been marked as an identifier for a question, so any instance of ‚Äúaccessing services‚Äù comes up will count the phrase as a question.\nGood example: ‚Äúbarriers do you think prevent community members from accessing services‚Äù it is less likely for someone to have used this exact string of words in the conversation, so we‚Äôre safe to mark this as a question identifier.\n\n\nPDFs\n\n\nExcel sheets\nOf course, we also tend to ask qualitative questions in some of our surveys at OMNI, and these types of data should be read in like quantitative data and should already be in a clean format if you follow the data cleaning guide (insert link to data cleaning guide).\n\n\n@QUALBPT Any other forms of text we use?"
  },
  {
    "objectID": "fun_standards.html",
    "href": "fun_standards.html",
    "title": "Fundamental Standards",
    "section": "",
    "text": "The following fundamental standards and associated practices guide Omni‚Äôs Qualitative methods (including data management and analyses). These apply regardless of the methods or software packages used to support project work and are considered non-negotiables because they are critical to our ability to be #accountable to clients and communities in the accuracy of our work.\nAll staff are expected to review the Fundamental Qualitative Standards and indicate they have done so in Confluence here."
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Methods",
    "section": "",
    "text": "Omni uses various methods for qualitative data collection, including interviews and focus groups, open-ended survey responses, and mixed-methods integration.\nBelow are some guidance and considerations for you as you plan for a qualitative method."
  },
  {
    "objectID": "methods.html#create-a-new-website",
    "href": "methods.html#create-a-new-website",
    "title": "How to use this template",
    "section": "Create a new website",
    "text": "Create a new website\nThe {omni} package contains a create_website() function that will create a new directory (named my_report in the example below) with default files to get you started.\nlibrary(omni)\n\ncreate_website(\"my_report\")\nOnce you created the new directory, it‚Äôll open the main Quarto page, named index.qmd. Hit the Render button and you should be able to preview your website."
  },
  {
    "objectID": "methods.html#add-or-remove-a-page",
    "href": "methods.html#add-or-remove-a-page",
    "title": "How to use this template",
    "section": "Add or remove a page",
    "text": "Add or remove a page\nTo add/remove a page, you must do two things:\n\nCreate (or delete) the page you want to add (or remove). By default, the website has three pages: index.qmd, customization.qmd and about.qmd. Let‚Äôs say we want to add an ‚ÄúAppendix‚Äù page, we create an appendix.qmd file next to other Quarto documents.\nAdd (or remove) the page to _quarto.yml configuration file. Default _quarto.yml looks like this:\n\nwebsite:\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: about.qmd\n        text: Use this template\n      - href: customization.qmd\n        text: Customization\nWe can add our Appendix page by adding:\n- href: appendix.qmd\n  text: Appendix\nThis gives us:\n\n\n\n\n\n\n\nWarning\n\n\n\nThe href attribute above should match exactly the name of the file you created, while the text attribute can be whatever you want since it‚Äôs just what will be in the navigation bar."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "Omni‚Äôs qualitative analysis guide supports staff in conducting transparent, systematic, and actionable qualitative research in complex, real-world settings. Our clients often require timely, credible findings grounded in participants‚Äô lived experiences. To meet these demands, this guide outlines practical workflows rooted in two complementary paradigms: pragmatism and critical realism.\n\n\n\nPragmatism directs us to focus on real-world utility and actionable insights.\n\n\nCritical realism encourages us to understand participant perspectives while acknowledging how those perspectives are shaped by broader structures and contexts.\n\n\n\nTogether, these paradigms support our commitment to meaningful, context-aware findings that are both usable and methodologically sound.\n\n\nThis guide provides step-by-step instructions for conducting qualitative analysis, from data pre-processing to reporting. It includes techniques like word frequency analysis, sentiment analysis, thematic coding, content analysis, and topic modeling, all implemented with transparency and adaptability in mind.\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\nTool Flexibility: While R is our preferred tool for reproducibility and integration with quantitative methods, the guide also includes best-practice workflows for using Dedoose (for team-based coding) and AI tools like NotebookLM (for early exploratory work).\n\n\n\n\n  \n\n\n\nMethod Selection Guidance: We offer practical decision points based on dataset size, analytic goals, and project context, ensuring methods match the scope and purpose of each evaluation.\n\n\n\n\n  \n  \n  \n\n\n\nStructured Workflows: Omni workflows help analysts navigate all stages of qualitative analysis‚Äîfrom clarifying analytic frameworks and coding approaches to integrating qualitative and quantitative data in mixed-methods designs.\n\n\n\n\n  \n  \n  \n\n\n\nAdaptability: Whether you're working with rich interview transcripts or brief open-ended survey responses, the guide provides adaptable tools that emphasize rigor, transparency, and context.\n\n\n\n\n\n\n\n\n\n\n\nBy centering participant voices, documenting our methods clearly, and\nmaintaining a reflexive stance, this guide strengthens the credibility\nand usefulness of Omni‚Äôs qualitative work. It equips staff with tools\nand strategies that not only meet evaluation standards but also foster\naccountability, responsiveness, and connection to the communities we\nserve.\n\n\n\n\n\n\nVersion Control\n\n\n\n\nVersion\nDescription\nDate released\n\n\n\n\n-4.0\nAdding interactive features\n2025-08-14\n\n\n-5.0\nSecond draft for review and rebrand\n2025-08-14\n\n\n-6.0\nInitial draft for review\n2025-03-26"
  },
  {
    "objectID": "analysis.html#purpose",
    "href": "analysis.html#purpose",
    "title": "Analysis",
    "section": "Purpose",
    "text": "Purpose\nThis guide was developed to support Omni staff in conducting methodologically sound, transparent, and reproducible qualitative analyses. It offers practical, step-by-step instructions and highlights best practices for text pre-processing, analysis, and reporting. Whether working with interview transcripts, focus groups, open-ended survey responses, or other text-based data, Omni teams can use this guide to produce findings that are both grounded in participants‚Äô voices and useful for program improvement and decision-making.\n\nHow does this guide align with Omni‚Äôs core values?\nInquiry ‚Äî Provides clear, rigorous methods that encourage thoughtful exploration of participants‚Äô experiences.\nAgility ‚Äî Equips staff with adaptable tools to meet diverse project needs and respond efficiently to change.\nConnection ‚Äî Centers participants‚Äô voices and strengthens relationships with the communities and partners we serve.\nAccountability ‚Äî Uses transparent, reproducible analysis practices to keep our work credible, ethical, and trustworthy."
  },
  {
    "objectID": "analysis.html#what-this-guide-covers",
    "href": "analysis.html#what-this-guide-covers",
    "title": "Analysis",
    "section": "What This Guide Covers",
    "text": "What This Guide Covers\nYou‚Äôll find guidance on:\n\nText mining / Natural Language Processing (NLP)\n(e.g., word frequency, sentiment analysis, topic modeling)\nThematic and content analysis\n(e.g., dictionary-based coding, thematic coding frameworks)\nNarrative analysis @qualBPT do we need?\n(Optional: e.g., structural analysis, language style matching)\nVisualizing and reporting qualitative data\n(e.g., word clouds, bar charts, heatmaps, joint displays for mixed-methods)\n\nThese methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more.\nIn many applied settings, qualitative methods (and especially mixed-methods) are described in vague terms. Reports may mention ‚Äúthemes emerging‚Äù or ‚Äútriangulating findings,‚Äù but rarely explain the actual process used to get there. This vagueness makes it hard to replicate or assess qualitative findings and limits their credibility.\n\n\n\n\n\n\nAt Omni, we aim to avoid vague or ad hoc practices. We document\nclear, systematic workflows that integrate qualitative insights with\nquantitative data when appropriate.\n\n\n\n\nWhy Are Existing Descriptions of Methods So Vague?\nSeveral factors explain the common lack of clarity in methodology:\n\nDifferent disciplines (e.g., public health vs.¬†education research) use different frameworks, leading to inconsistent approaches.\nQuantitative research has standard tools (R, SPSS, Stata), but qualitative tools (NVivo, MAXQDA, Dedoose) often rely on manual processes and don‚Äôt always integrate cleanly with quantitative workflows.\nQualitative analysis requires human interpretation and reflexivity. Documenting every step is time-consuming, and under tight timelines, many organizations skip this critical process.\nQualitative and quantitative teams often work separately, without shared standards or mixed-methods integration."
  },
  {
    "objectID": "analysis.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "href": "analysis.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "title": "Analysis",
    "section": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI",
    "text": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI\n\nR\nBest when\n\nDatasets are large or mixed (qual + quant) and need audit trails.\n\nYou want reproducibility, automation, and version control.\n\nYou‚Äôre under time constraints and have existing scripts/templates (IRR optional or phased).\n\nPros\n\nTransparent, reproducible code and scalable pipelines.\n\nFlexible: word frequency, sentiment, dictionaries, topic models.\n\nProduces precise visuals and integrates survey/demographic data easily.\n\nCons\n\nSteeper setup and learning curve.\n\nRequires clear documentation to ensure shared understanding.\n\n\n\n\nDedoose\nBest when\n\nWorking collaboratively with a team or training new coders.\n\nAnalyzing small‚Äìmoderate datasets.\n\nDelivering quick turnarounds using built-in IRR workflows.\n\nPros\n\nMulti-user collaboration, role permissions, IRR features.\n\nLow barrier for non-programmers.\nSimple approach for line-by-line coding\n\nCons\n\nLicense cost.\n\nLimited automation/custom analyses compared to code.\n\nReproducibility and export trails less granular than scripted pipelines.\n\n\n\n\nAI\nBest when\n\nVery fast and low barrier (though not a replacement for traditional qualitative coding.\n\nAnalyzing short datasets, scoping questions, or drafting a codebook.\n\nPreparing stakeholder previews before deeper human analysis.\n\nPros\n\nVery fast and accessible; supports brainstorming structures.\n\nCan summarize, cluster, and compare data quickly.\n\nUseful for early iteration before moving to R or Dedoose.\n\nCons\n\nNot a substitute for human interpretation; may produce hallucinations.\nInconsistent across runs; lacks deep context if prompts are weak.\n\nData governance and privacy limits ‚Äî avoid uploading sensitive data."
  },
  {
    "objectID": "analysis.html#terminology",
    "href": "analysis.html#terminology",
    "title": "Analysis",
    "section": "Terminology",
    "text": "Terminology\nBefore starting your pre-processing and analysis, it‚Äôs important to understand a few core terms. These concepts are essential for working with text data and deciding on the appropriate pre-processing and analysis steps.\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nTokenization\nBreaking text into units (words, phrases, sentences)\n\n\nStemming\nReducing words to their root (e.g., ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù)\n\n\nLemmatization\nReducing to dictionary form (e.g., ‚Äúbetter‚Äù ‚Üí ‚Äúgood‚Äù)\n\n\nStop Words\nCommon words often removed (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù)\n\n\nDocument-Term Matrix\nTable of word frequencies across documents\n\n\nTF-IDF\nTerm importance based on frequency and inverse document frequency\n\n\nCorpus\nCollection of text documents as one dataset\n\n\nDictionary\nList of keywords/phrases used to code or categorize text\n\n\n\n\n\n\n# Load all packages \nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(quanteda)\nlibrary(textstem)\nlibrary(sentimentr)\nlibrary(topicmodels)\nlibrary(flextable)\nlibrary(knitr)\nlibrary(omni)\n\n\n\n\n\nPre-processing prepares your qualitative data for analysis by cleaning, organizing, and standardizing text. This step ensures the data is usable for word frequency, sentiment analysis, topic modeling, and other text mining techniques.\nYou should always assess the scope and quality of your data first:\n\nAre the data cleaned (lowercase, removed participant names, punctuation, symbols)?\n\n\n\n\n\n\n\nCheck out our function that does all of these data cleaning tasks for\nyou in R! You can also segment your text by question, combine multiple\ninterviews and focus groups into one dataset, and more.\n\n\n\n\n Cleaning transcripts function \n\n\nHow much text do you have? (Word counts per document/response.)\nHow many participants contributed?\nHow detailed or shallow are the responses?\nWhose voices are you analyzing?\n\nOnce you understand your data, you can decide which pre-processing steps are appropriate."
  },
  {
    "objectID": "analysis.html#tokenization",
    "href": "analysis.html#tokenization",
    "title": "Analysis",
    "section": "Tokenization",
    "text": "Tokenization\nTokenization breaks text into individual pieces‚Äîusually words, but sometimes phrases or sentences.\n\nMost text mining techniques require tokenized text.\nThis is common for word frequency analysis, sentiment analysis, and topic modeling.\nAfter tokenization, we lose the flow of sentences which is generally okay for some analyses, but not for narrative analysis or content analysis.\n\nWhat are Stop Words?\nStop words are common words like ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúbut‚Äù that don‚Äôt add much meaning on their own. Because we want to focus on broader themes from our participants‚Äô voices, we usually want to remove stop words after text is tokenized. This process allows us to focus on content-rich words, like nouns and verbs. We should remove stop words when running a word frequency analysis, topic modeling, or sentiment analysis.\nWe can also create custom stop words that we want to remove from our analyses, for example, location names or project-specific words that appear frequently but aren‚Äôt relevant to the analysis.\nExample:\n\nIn the example below, my custom stop words are ‚Äútravis‚Äù and ‚Äúcounty‚Äù, and they‚Äôre added to the stop_words bank which includes other words like ‚Äúbut‚Äù, ‚Äúis‚Äù, ‚Äúthe‚Äù, etc. If you‚Äôd like to see all of the stop words, see View(stop_words)."
  },
  {
    "objectID": "analysis.html#stemming",
    "href": "analysis.html#stemming",
    "title": "Analysis",
    "section": "Stemming",
    "text": "Stemming\nStemming words cuts them down to their root forms (e.g., ‚Äúrunning‚Äù becomes ‚Äúrun‚Äù). This pre-processing step should primarily be used for topic modeling or for other analyses that you decide that exact word form isn‚Äôt critical. This step is recommended to use with larger datasets, with typically hundreds of documents or more, but for our purposes we recommend stemming any time you have enough data for topic modeling (around 5,000 total words)."
  },
  {
    "objectID": "analysis.html#lemmatization",
    "href": "analysis.html#lemmatization",
    "title": "Analysis",
    "section": "Lemmatization",
    "text": "Lemmatization\nLemmatization converts words to their dictionary root and keeps the words readable to the user (e.g., ‚Äúbetter‚Äù becomes ‚Äúgood‚Äù). This pre-processing step should be used for word frequency analysis, sentiment analysis, or thematic/content analysis as it works will with small and large corpuses.\nLet‚Äôs compare the stem words, vs lemmatized words against the original tokenized words:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nline\nspeaker\nparticipant_id\nquestion\nsection\nsection_label\nsession\nword\nstem_word\nlem_word\n\n\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nbiggest\nbiggest\nbig\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nchallenges\nchalleng\nchallenge\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ntransportation\ntransport\ntransportation\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ncars\ncar\ncar\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nmakes\nmake\nmake\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ndifficult\ndifficult\ndifficult\n\n\n\n\n\n\n\n\nWhen to Use Stemming vs.¬†Lemmatization\n\n\n\n\n\n\nStemming\nLemmatization\n\n\n\n\nYou need speed over accuracy\nSlower but more accurate\n\n\nWorking with large datasets\nBetter for small datasets\n\n\nBasic information retrieval tasks\nBetter for nuanced analysis\n\n\nSearch engines or topic modeling where fine detail isn‚Äôt critical\nBetter for in-depth analysis\n\n\nNot concerned about human readability\nMaintains readable words)\n\n\n\n\n\n\n\n  \n    Analyses"
  },
  {
    "objectID": "analysis.html#word-frequency-analysis",
    "href": "analysis.html#word-frequency-analysis",
    "title": "Analysis",
    "section": "Word frequency analysis",
    "text": "Word frequency analysis\n\n\n\n\nWord frequency analysis is a simple and effective method that counts how often specific words appear in your dataset. It‚Äôs often used early in qualitative analysis to get a general sense of prominent topics, but it can also be applied as a stand-alone method to identify frequently mentioned issues in participant responses. Word frequency works best when you have a reasonable amount of text to analyze. As a general best practice, having at least 100‚Äì200 content words (excluding stop words) allows for more reliable interpretation of patterns, though smaller datasets can still offer preliminary insights.\nTo ensure accuracy, it‚Äôs important to pre-process your text. Using lemmatized words helps avoid counting variations like ‚Äúrun‚Äù and ‚Äúrunning‚Äù separately, and removing stop words‚Äîcommon words such as ‚Äúthe‚Äù or ‚Äúand‚Äù‚Äîallows you to focus on terms that carry more meaning. In cases where participants mention names of places or projects repeatedly, custom stop word lists can also help refine the results.\n\n\nWhile word frequency counts themselves do not explain context or meaning, they can help point to emerging themes by highlighting concepts that recur across participants or within particular sections of discussion. For example, if words like ‚Äútransportation,‚Äù ‚Äúaccess,‚Äù and ‚Äúbarrier‚Äù frequently appear in responses about service challenges, they signal a potential theme that warrants deeper exploration. Word frequency analysis can also help guide more interpretive methods such as thematic or content analysis, and is most useful when findings are contextualized within the broader dataset and research goals.\n\n\n# A tibble: 6 √ó 2\n  word             n\n  &lt;chr&gt;        &lt;int&gt;\n1 time             4\n2 people           3\n3 access           2\n4 application      2\n5 applications     2\n6 process          2"
  },
  {
    "objectID": "analysis.html#sentiment-analysis",
    "href": "analysis.html#sentiment-analysis",
    "title": "Analysis",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\nSentiment analysis is a method that measures the emotional tone of text by categorizing words or phrases as positive, negative, or neutral. It can be used to quickly gauge participants‚Äô attitudes toward a topic or to assess the overall tone of responses across interviews, focus groups, or surveys. Sentiment analysis works best when you have larger amounts of text‚Äîideally, datasets with several hundred words or more‚Äîbecause emotional tone can vary within short responses, making sentiment harder to interpret in very small datasets. However, it can still offer insights in smaller datasets when applied carefully and when results are presented as exploratory.\nBest practices for sentiment analysis include pre-processing your text by removing stop words and standardizing language through lemmatization. This ensures consistent scoring and avoids misclassifications due to word variations. Sentiment analysis typically relies on pre-built lexicons, such as Bing, AFINN, or the NRC Emotion Lexicon, which assign emotional values to words. It‚Äôs important to note that these lexicons were often designed for general use (such as social media text) and may require customization to fit specific public health or social science contexts. For example, in health-related interviews, a word like ‚Äútreatment‚Äù might appear frequently and carry different sentiment depending on the discussion‚Äôs focus.\nWhile sentiment analysis doesn‚Äôt capture nuance or context in the way manual coding can, it can highlight patterns of emotional tone across datasets or within specific discussion topics. For example, sentiment analysis might reveal that participants express more negative sentiment when discussing barriers to accessing services, and more positive sentiment when discussing recommendations for future improvements. These insights can help guide deeper qualitative coding or serve as an additional layer of analysis to support findings. As with any automated method, it‚Äôs important to review and interpret results in context and to document any limitations or adaptations made to the analysis.\n\n\n# A tibble: 2 √ó 2\n  sentiment     n\n  &lt;chr&gt;     &lt;int&gt;\n1 negative      5\n2 positive      3\n\n\n\n\n\n\n\n\n\nTip for finding quotes by tone\nLet‚Äôs say you want to pull a quote to include in a report and you know that you want it to be a positively toned quote in a ‚Äúrecommendations‚Äù section of your discussion. You can use the sentimentr package to gather sentiments of each sentence (or segment) and sort by sentiment score to find the quote with the most positive tone in your criteria.\nSee an example below:\n\n\n# A tibble: 7 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n7    10 participant P1                    0       3 Recommendatio‚Ä¶ prov‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: element_id &lt;int&gt;, avg_sentiment &lt;dbl&gt;,\n#   sd_sentiment &lt;dbl&gt;, n_sentences &lt;int&gt;\n\n\nMixed-methods with sentiment analysis\nBecause sentiment analysis gives you a numeric output as a sentiment score, you can imagine instances where you may want to compare sentiment scores between groups, correlate sentiment scores with other variables in a quantitative survey, or conduct pre-post comparisons."
  },
  {
    "objectID": "analysis.html#topic-modeling",
    "href": "analysis.html#topic-modeling",
    "title": "Analysis",
    "section": "Topic modeling",
    "text": "Topic modeling\nTopic modeling is an automated method used to identify themes or topics across large collections of text. It uses algorithms to group together words that frequently appear in similar contexts, helping reveal hidden patterns or structures in qualitative data. Topic modeling is especially useful when you have large datasets‚Äîtypically a minimum of 5,000 words or more spread across multiple documents or participant responses. The method works best when documents are of relatively similar length, which helps the model assign topics more evenly.\nThis method is not recommended for use on smaller corpuses and would be considered poor practice to rely on it to generate meaningful insights. If you don‚Äôt have enough data for this analysis, consider using the content analysis strategy to identify themes in the data.\nBefore running a topic model, it‚Äôs important to pre-process your text. Best practices include stemming words to reduce variation (so that ‚Äúrun‚Äù and ‚Äúrunning‚Äù are treated as the same word) and removing stop words to focus on meaningful content. Topic modeling doesn‚Äôt require predefined codes or themes, making it a good exploratory tool for surfacing unexpected topics in your data. However, it‚Äôs important to remember that these topics are generated algorithmically‚Äîthey group terms based on statistical patterns, not human interpretation. As a result, human review is always needed to interpret and label the topics in a way that makes sense for your project and participants.\nTopic modeling can complement manual coding by offering a high-level view of common themes, pointing analysts toward areas that may warrant deeper exploration. For example, a topic model might surface clusters of words related to barriers (‚Äútransportation,‚Äù ‚Äúaccess,‚Äù ‚Äúcost‚Äù) and another cluster about solutions (‚Äúeducation,‚Äù ‚Äúoutreach,‚Äù ‚Äúsupport‚Äù), giving you a starting point for thematic analysis. Commonly used R packages for topic modeling include topicmodels, which provides algorithms like Latent Dirichlet Allocation (LDA), and tm for pre-processing and managing textual data.\n\n\n[1] 46.1033\n\n\n[1] 46.13593\n\n\n# A tibble: 20 √ó 3\n# Groups:   topic [2]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0617\n 2     1 transportation 0.0544\n 3     1 services       0.0467\n 4     1 residents      0.0313\n 5     1 challenges     0.0297\n 6     1 agree          0.0281\n 7     1 lot            0.0278\n 8     1 access         0.0276\n 9     1 applications   0.0275\n10     1 application    0.0274\n11     2 people         0.0800\n12     2 time           0.0695\n13     2 process        0.0485\n14     2 application    0.0381\n15     2 applications   0.0381\n16     2 access         0.0380\n17     2 timeconsuming  0.0264\n18     2 campaigns      0.0260\n19     2 buses          0.0254\n20     2 simplifying    0.0253\n\n\n# A tibble: 30 √ó 3\n# Groups:   topic [3]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0778\n 2     1 transportation 0.0543\n 3     1 services       0.0542\n 4     1 lot            0.0390\n 5     1 residents      0.0353\n 6     1 applications   0.0347\n 7     1 access         0.0312\n 8     1 vouchers       0.0261\n 9     1 makes          0.0256\n10     1 planning       0.0249\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "analysis.html#content-analysis",
    "href": "analysis.html#content-analysis",
    "title": "Analysis",
    "section": "Content analysis",
    "text": "Content analysis\nContent analysis is a method used to count how often predefined concepts, themes, or categories appear in qualitative data. It relies on a dictionary‚Äîa list of key terms or phrases‚Äîdesigned to reflect your evaluation questions or coding framework. Content analysis works well for both small and large datasets, making it a flexible tool when you want to systematically measure the presence of specific themes across interviews, focus groups, or open-ended survey responses.\nA key requirement for effective content analysis is a carefully designed dictionary that accurately captures the concepts you‚Äôre interested in. This might include terms related to barriers, facilitators, or recommendations, depending on the project‚Äôs goals. Best practice is to validate the dictionary by reviewing examples of matched text to make sure the terms are identifying the intended content. You may need to refine the dictionary over time, adding synonyms or removing words that generate false positives.\nContent analysis can help answer questions like ‚ÄúHow frequently do participants mention prevention strategies?‚Äù or ‚ÄúWhat percentage of responses reference funding challenges?‚Äù It is particularly useful when you need to quantify qualitative data for reporting purposes, or when you want to compare how frequently themes appear across different stakeholder groups. In R, the quanteda package offers efficient tools for dictionary-based content analysis, allowing you to apply a dictionary and quickly summarize how often key terms or concepts appear in the dataset.\n\n\nDocument-feature matrix of: 7 documents, 109 features (81.26% sparse) and 0 docvars.\n       features\ndocs    sure i think one of the biggest challenges is transportation\n  text1    1 1     1   1  5   2       1          1  1              1\n  text2    0 1     0   0  0   0       0          0  0              0\n  text3    0 0     0   0  1   0       0          0  0              0\n  text4    0 0     0   0  0   4       0          0  1              0\n  text5    0 0     0   0  0   0       0          0  0              0\n  text6    0 0     0   0  0   1       0          0  0              0\n[ reached max_ndoc ... 1 more document, reached max_nfeat ... 99 more features ]\n\n\nDocument-feature matrix of: 7 documents, 3 features (85.71% sparse) and 0 docvars.\n       features\ndocs    prevention treatment harm_reduction\n  text1          0         1              0\n  text2          0         0              0\n  text3          1         0              0\n  text4          0         0              0\n  text5          2         0              0\n  text6          0         0              0\n[ reached max_ndoc ... 1 more document ]\n\n\n[1] \"text1\" \"text2\" \"text3\" \"text4\" \"text5\" \"text6\"\n\n\n# A tibble: 6 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: doc_id &lt;chr&gt;, prevention &lt;dbl&gt;, treatment &lt;dbl&gt;,\n#   harm_reduction &lt;dbl&gt;"
  },
  {
    "objectID": "analysis.html#thematic-analysis-in-dedoose",
    "href": "analysis.html#thematic-analysis-in-dedoose",
    "title": "Analysis",
    "section": "Thematic Analysis in Dedoose",
    "text": "Thematic Analysis in Dedoose\n@qualBPT help here!! Can we add anything re coding to this guide in this section, maybe Ivonne‚Äôs work? What other programs should we add?\nIf using Dedoose to conduct thematic analysis, we recommend a structured, reflective approach grounded in reflexive thematic analysis (Clarke & Braun, 2006) and informed by critical realism.\nHere‚Äôs how to approach it:\n\nStart with Familiarization Read through transcripts or responses in full before coding.\n\nUse memos to reflect on initial impressions, patterns, and researcher assumptions.\n\nDevelop Codes Iteratively Begin with inductive coding (bottom-up), focusing on what participants actually say.\n\nAvoid pre-loading the codebook unless doing deductive analysis is needed for evaluation purposes.\nUse Dedoose‚Äôs ‚ÄúDescriptor‚Äù fields to track context (e.g., stakeholder group, session type) for later analysis.\n\nApply Codes Reflexively Apply codes carefully, updating definitions and merging/splitting codes as needed.\n\nEncourage coders to discuss disagreements and maintain an audit trail of key coding decisions.\n\nConstruct Themes Thoughtfully After coding, review excerpts by code and group them into broader themes that reflect patterns across participants.\n\nUse Dedoose‚Äôs ‚ÄúCode Co-Occurrence‚Äù and ‚ÄúCode Application‚Äù tools to explore theme structure.\n\nAcknowledge Researcher Role Reflect on how your perspective, language, and interpretation influence theme development.\n\nBe cautious not to overstate findings; describe patterns and nuance rather than asserting consensus.\n\nDocument Everything Keep a record of how codes and themes evolved.\n\nClearly state the number of participants or excerpts that informed each theme.\nMake your interpretive lens and limitations explicit‚Äîespecially when datasets are small or uneven across groups.\n\nThematic analysis in Dedoose should still reflect Omni‚Äôs commitment to critical realism: treat participant input as reflecting real issues shaped by context and perspective, and be transparent about what the data can‚Äîand cannot‚Äîsupport."
  },
  {
    "objectID": "analysis.html#combining-analyses",
    "href": "analysis.html#combining-analyses",
    "title": "Analysis",
    "section": "Combining analyses",
    "text": "Combining analyses\nNo single method can fully capture the richness and complexity of qualitative data. At Omni, we often combine different qualitative analysis approaches to explore various angles of our data and answer nuanced evaluation questions. Pairing methods like word frequency, sentiment analysis, content analysis, and thematic analysis can help reveal both patterns and meaning, ensuring our findings are grounded in evidence and provide actionable insights."
  },
  {
    "objectID": "data_prep.html",
    "href": "data_prep.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "You‚Äôll find guidance on:\n\nPrinciples and purpose of qualitative data cleaning\nDefining ‚Äúclean‚Äù and ‚Äúanalysis-ready‚Äù data at Omni\nStep-by-step cleaning procedures in R\nReporting and documentation standards\n\nThese data cleaning methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more."
  },
  {
    "objectID": "data_prep.html#quarto",
    "href": "data_prep.html#quarto",
    "title": "Data Prep",
    "section": "",
    "text": "Manager‚Äôs Summary\nData Cleaner‚Äôs Summary"
  },
  {
    "objectID": "data_prep.html#introduction",
    "href": "data_prep.html#introduction",
    "title": "Data Cleaning",
    "section": "Introduction",
    "text": "Introduction\nData cleaning is often one of the first things you will do when you start working with qualitative data at Omni. Whether we‚Äôre working with interview transcripts, focus group discussions, or open-ended survey responses, the raw data we receive is rarely ready for immediate analysis. Cleaning is not just about tidying up; it‚Äôs about making informed decisions that clarify the meaning and integrity of the data while preparing it for systematic analysis.\nThe decisions we make during the cleaning process are every bit as complex and impactful as those made during coding and analysis. Thoughtful data cleaning can preserve the richness of qualitative data, while careless decisions can distort or diminish participants‚Äô voices. Therefore, it is especially important to have a strong set of working principles to guide your decisions when cleaning qualitative data.\nThis guide covers a general approach to qualitative data cleaning, with an emphasis on useful R packages and functions designed to conquer some common challenges. While this guide includes tools and code to make your life easier, it also offers guidelines for making judgment calls about what to remove, retain, or clarify in the data.\nThe steps in a qualitative data cleaning process will always be informed by two key factors:\n\nThe state of the data when we (Omni) receive it\n\n\nFor example, some transcripts may come from automated services (like Zoom or Otter.ai) and contain timestamps, speaker labels, or filler words that require removal. Others may be professionally transcribed and need minimal cleaning.\n\n\nThe specific needs of the project\n\n\nBecause of this variability, we encourage a flexible, judgment-driven approach to data cleaning. The steps described in this guide are common to many projects, but their order and application should be tailored to the needs of the dataset and the analytic goals of the project. Importantly, depending on the type of analysis, different cleaning steps may be required. Consult the analysis plan and research questions in your project materials to verify the needs of the project."
  },
  {
    "objectID": "data_prep.html#rationale",
    "href": "data_prep.html#rationale",
    "title": "Data Cleaning",
    "section": "Rationale",
    "text": "Rationale\nWhen we clean qualitative data, we apply a series of thoughtful transformations that make the data clearer, more consistent, and usable for analysis. Qualitative data cleaning requires attention to detail and sensitivity to the context in which the data were collected. The procedures we use need to be flexible because the downstream purposes of the data can vary from project to project, whether for thematic coding, content analysis, or mixed-methods integration.\nThe qualitative data cleaner often has to make many judgment calls during this process. These decisions are guided by the project‚Äôs goals, the nature of the source data, team experience, and guidance documents (like this one). Every decision and its rationale should be clearly documented in the data cleaning script or data log (more on that below). Transparency in this process ensures that the cleaned dataset remains trustworthy and aligned with our ethical standards for qualitative research.\nQualitative data cleaning requires a lot of careful thought and attention. The R code that cleans text data needs to be clearly written and well-commented, not only for reproducibility but to ensure that meaning is preserved, and participant voices are not inadvertently altered or diminished. In qualitative work, the cleaning process can directly impact the integrity of the analysis.\nJust as with quantitative analysis, qualitative data-cleaning decisions are made with greater ease and clarity when there is a clear work plan, guided by the project‚Äôs research questions or evaluation goals. Having a shared understanding of what the team hopes to explore in the data helps inform:\n\nWhat should be cleaned\nWhat should be preserved (even if messy)\nWhat should be flagged for discussion\n\nFinally, whether you‚Äôre writing code for qualitative data cleaning or any other purpose, always write your R scripts as if they will later be:\n\nHeavily scrutinized\nHeld up as example code\nModified by someone brand new to both R and the project\n\nMake it easy on future Omni-ites‚Äîand on your future self!"
  },
  {
    "objectID": "data_prep.html#when-are-data-clean",
    "href": "data_prep.html#when-are-data-clean",
    "title": "Data Cleaning",
    "section": "When are data clean?",
    "text": "When are data clean?\nWhat Does It Mean to Have ‚ÄúClean‚Äù Qualitative Data? - For there to be project tasks that direct Omni-ites to ‚Äòclean qualitative data,‚Äô and a guide to help in doing so, there should also be a shared understanding of what it means for qualitative data to be clean.\nDefinition of Clean Qualitative Data - At Omni, qualitative data are considered clean when they are organized, de-identified, and ready for analysis or coding.\nThat means the data: - Accurately reflect the original source material (e.g., interviews, focus groups, or open-text survey responses) Have been transformed into a structure that makes them easy to navigate and analyze Protect the privacy and confidentiality of participants Are consistent, clear, and free of irrelevant clutter (like transcription artifacts)\nWhat Makes a Qualitative Dataset ‚ÄúAnalysis-Ready‚Äù?\n\nFor qualitative text data to be ready for analysis, they should meet the following criteria:\n\n\nSpeaker Information Is Clear and Consistent\n\n\nParticipant speakers and interviewers are clearly labeled in the data.\nEach speaker‚Äôs text is grouped logically into segments, preserving conversational flow.\n\n\nParticipant Identifiers Are Specified and Protected\n\n\nReal names, locations, and other direct identifiers have been removed or replaced with participant IDs or pseudonyms.\nConfidential information (e.g., agency names, job titles, organizations) is anonymized where necessary, following Omni‚Äôs confidentiality guidelines.\n\n\nQuestions Are Clearly Distinguished From Responses\n\n\nInterviewer questions (or prompts) are labeled or separated from participant responses, as appropriate. This can be done by adding question text as its own field in the dataset or by adding markers in the transcript.\n\n\nText Segments Are Ordered and Organized\n\n\nThe transcript text is ordered according to the flow of conversation. Segments are correctly time-sequenced (even if timestamps themselves are removed).\n\n\nText Is Structured Into a Tidy, Rectangular Format\n\n\nEach row represents a single speaker turn or unit of analysis (e.g., a complete response to a question).\nData are stored in a rectangular table (data frame), with columns for:\n\nSession name or group (e.g., ‚ÄúEducators‚Äù or ‚ÄúPublic Health‚Äù)\nParticipant ID or role (e.g., ‚ÄúParticipant 1‚Äù, ‚ÄúFacilitator‚Äù)\nText segment (the response or comment)\nAny relevant metadata (e.g., discussion section, date)\nTranscription\n\n\n\nArtifacts Are Removed\n\n\nAll timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless specifically required for analysis.\nAutomated transcription quirks (e.g., repeated words, filler words, auto-captions like ‚Äú[inaudible]‚Äù) are reviewed, cleaned, or flagged.\n\n\nText Is Consistent in Style and Format\n\n\nAll text is converted to lowercase, unless case is important for analysis.\nSpelling errors are corrected when they obscure meaning (but regional spellings or participant quirks may be preserved if relevant).\nPunctuation and spacing are standardized (no excessive whitespace, missing periods, etc.).\n\n\nRelevant Identifiers Are Added to the Dataset\n\n\nIf there are multiple sessions or groups, these are labeled (e.g., ‚ÄúEducators,‚Äù ‚ÄúPublic Health‚Äù).\nIf there are themes or discussion sections (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù), these are identified.\nIf codes are pre-assigned for analytic purposes (e.g., ‚ÄúPre-implementation,‚Äù ‚ÄúPost-implementation‚Äù), they are included in the data structure.\n\nHow Do We Know When Qualitative Data Are Clean?\nHere are some guiding questions to help determine when qualitative data are ready for analysis (i.e., clean):\n\nWhat is the plan for coding or analyzing this data?\nThe analysis plan (or coding framework) should inform cleaning decisions. For example, if the team plans to do thematic coding, they‚Äôll need text organized into meaningful speaker turns or responses. What needs to be anonymized?\nIdentify any sensitive information that must be redacted or replaced to maintain confidentiality and ensure participant privacy. Are speaker turns properly attributed and easy to follow?\nEach speaker‚Äôs contributions should be clearly labeled, consistently formatted, and grouped logically. Are responses to specific questions clearly identifiable?\nIf interviews or focus groups follow a semi-structured guide, it‚Äôs important to separate questions from responses for clarity in analysis. Is the structure of the data appropriate for the analytic tool?\nIf the data are being uploaded to Dedoose, NVivo, or another platform, they should follow the required format (e.g., tidy data frame with speaker IDs and group names). Have all unnecessary artifacts been removed?\nTime stamps, filler words, and transcription errors that don‚Äôt add value to the analysis should be removed. Has the cleaned data been reviewed by someone else (QA check)?\nWhenever possible, have another Omni-ite review the cleaned data for accuracy and completeness.\n\nCommon Issues to Discuss Early in the Cleaning Process\nJust like in quantitative data cleaning, clarifying expectations at the start of a project will save time later. For qualitative projects, consider these:\n\nWill we analyze both facilitator questions and participant responses, or just participant responses?\nHow will we handle overlapping speech, interruptions, or incomplete thoughts?\nDo we need to standardize participant roles (e.g., ‚ÄúPublic Health Official‚Äù vs.¬†‚ÄúPH Staff‚Äù) for consistency?\nAre we preparing data for manual coding or automated text analysis?\nDo we need to translate or transcribe non-English responses?\nDo we need to connect text segments with broader context, such as the discussion theme or section of the focus group?\n\nQuick Summary of ‚ÄúClean Qualitative Data‚Äù at Omni: Clean qualitative data are:\n\nAnonymized\nClearly structured and labeled\nOrganized for easy analysis\nFree of unnecessary artifacts\nReady for use in coding and interpretation"
  },
  {
    "objectID": "data_prep.html#how-do-i-report-the-results-of-data-cleaning",
    "href": "data_prep.html#how-do-i-report-the-results-of-data-cleaning",
    "title": "Data Cleaning",
    "section": "How do I report the results of data cleaning?",
    "text": "How do I report the results of data cleaning?\nCleaning qualitative data is an interpretive and decision-heavy process, and those decisions need to be transparent. Reporting your cleaning process helps:\nProject leads understand what‚Äôs been done and why. Provide documentation in case changes need to be made later. Build trust in the integrity of the cleaned dataset. Support future qualitative coding, interpretation, and reporting. Qualitative data cleaning produces results‚Äîchanges to the text or data structure‚Äîthat should be documented in a clear, shareable data cleaning report.\nWhat to include in a report about qualitative data cleaning\n\nSummary of the Dataset You Cleaned Start with an overview:\n\nHow many transcripts or files were cleaned? How many sessions (e.g., focus groups, interviews) are included? What types of participants are represented (e.g., educators, public health professionals)?\nExample: This dataset includes transcripts from 8 focus groups, with 42 participants. Participants represent two stakeholder groups: Educators (n = 20) and Public Health Professionals (n = 22).\n\nAnonymization and De-Identification Steps Document what you removed or replaced to protect confidentiality.\n\nWere participant names replaced with IDs (e.g., Participant 01)? Were organizations, locations, or personal identifiers removed or redacted? Were job titles generalized (e.g., ‚ÄúCEO‚Äù changed to ‚Äúsenior leader‚Äù)?\nExample: Replaced all participant names with Participant IDs (e.g., P01). Removed specific references to organizations and locations (e.g., ‚Äúat Boulder Community Hospital‚Äù becomes ‚Äúat [hospital]‚Äù). Redacted job titles for anonymity when mentioned alongside unique organizations.\n\nSpeaker Labeling and Text Structuring Describe how speakers were labeled and how the transcript was organized.\n\nWere speakers consistently labeled as ‚ÄúParticipant‚Äù and ‚ÄúFacilitator‚Äù? Was each speaker turn separated into its own row or segment? Were questions separated from responses?\nExample: Speaker turns were labeled consistently as either Facilitator or Participant. Each speaker turn is stored as one row in the cleaned dataset, with associated metadata (Session name, Speaker role, Discussion section).\n\nArtifacts Removed (Timestamps, Filler Words, etc.) Note what transcription artifacts were removed or edited:\n\nWere timestamps deleted? Were filler words (e.g., ‚Äúum,‚Äù ‚Äúuh‚Äù) removed? If so, specify whether this was systematic or case-by-case. Were transcription errors corrected?\nExample: Removed all timestamps in the format [hh:mm:ss]. Deleted common filler words (‚Äúum,‚Äù ‚Äúuh‚Äù) unless they contributed to participant meaning or tone. Reviewed and corrected auto-transcription errors (e.g., ‚ÄúDodoose‚Äù corrected to ‚ÄúDedoose‚Äù).\n\nText Standardization and Formatting Summarize standardization steps for readability and consistency:\n\nWas text converted to lowercase? Was spelling corrected? If so, did you preserve participant colloquialisms? Were consistent punctuation and spacing applied?\nExample: Converted all text to lowercase for consistency. Standardized punctuation (e.g., added periods to sentence ends where missing). Corrected spelling errors that obscured meaning but preserved participant vernacular and tone where appropriate.\n\nMetadata or Contextual Information Added Note any metadata added to support analysis:\n\nSession name (e.g., ‚ÄúEducators‚Äù vs.¬†‚ÄúPublic Health Professionals‚Äù) Discussion section (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù) Participant role or group designation\nExample: Added metadata fields to identify Session Name, Participant Group (Educator/Public Health), and Discussion Section (Barriers, Facilitators, Recommendations).\n\nKey Decisions Made During Cleaning Flag any important decisions that could impact analysis:\n\nIf you excluded any portions of text (e.g., off-topic discussions), document what was excluded and why. If you made choices about retaining or removing interruptions, overlapping speech, or non-verbal cues, describe the rationale. If you generalized identifying details in ways that may impact interpretation, note this.\nExample: Excluded introductory small talk (greetings, logistics discussions) from the analysis dataset. Retained overlapping speech where relevant to the discussion. Generalized certain job titles to preserve anonymity (e.g., ‚ÄúHead Nurse‚Äù changed to ‚ÄúMedical Staff‚Äù).\n\nCounts and Summaries Where Relevant When helpful, include counts that summarize:\n\nHow many identifiers were removed? How many sessions, speakers, or responses are in the final dataset? If you organized by themes, how many segments are in each theme?\nExample: Final cleaned dataset includes 8 focus groups, 42 participants, and 620 participant responses across three discussion sections: Challenges (n = 220), Facilitators (n = 200), and Recommendations (n = 200).\nTips for reporting qualitative data cleaning be transparent\n\nEven small decisions (e.g., standardizing speaker labels) can have big implications during analysis. If you‚Äôre unsure whether to document something, document it!\nTake the perspective of your project lead or analyst. What decisions might they need to revisit later? What context would help them understand how the data were shaped?\nSupport replicability and quality control. Your cleaning report should make it easy for another team member to:\n\nUnderstand what was done\nRe-run the cleaning script\nSuggest or request changes with full knowledge of the process\n\n\nExample summary table to describe data cleaning for reporting\n\n\n\n\n\n\n\n\nCleaning Step\nAction Taken\nNotes\n\n\n\n\nAnonymization\nRemoved names; replaced with Participant IDs (P01‚ÄìP42).\nLocations and job titles generalized.\n\n\nSpeaker Labeling\nLabeled as Facilitator or Participant.\nConsistent across all sessions.\n\n\nTimestamps Removed\nDeleted all timestamps (hh:mm:ss).\n\n\n\nFiller Words Removed\nRemoved ‚Äúum,‚Äù ‚Äúuh‚Äù except when indicating hesitation.\nCase-by-case review.\n\n\nText Standardization\nConverted to lowercase; corrected major spelling errors.\nPreserved participant language and tone.\n\n\nMetadata Added\nAdded session name, participant group, and discussion section.\nUseful for subgroup analysis.\n\n\nExclusions\nRemoved introductions and off-topic discussions.\nDocumented in the data log."
  },
  {
    "objectID": "data_prep.html#terminology",
    "href": "data_prep.html#terminology",
    "title": "Data Cleaning",
    "section": "Terminology",
    "text": "Terminology\nüìù Relevant Terminology for Qualitative Data Cleaning in R\nüîß Data Structure & Format Terms\n\nTranscript: A written or typed record of spoken language from interviews, focus groups, or meetings. Transcripts may include speaker labels, timestamps, and other artifacts that need cleaning.\nTurn-Taking: Each time a participant or facilitator speaks is called a ‚Äúturn.‚Äù Clean data often organize these turns into individual rows in a dataset.\nSegment (or Excerpt): A portion of text, such as a paragraph, sentence, or speaker turn, treated as a unit for coding or analysis. Segments are often defined by the speaker‚Äôs response or by topic.\nTidy Data: Data where:\n\nEach row represents a single observation (e.g., a speaker turn or segment)\nEach column contains one type of information (e.g., speaker ID, text, session group)\nTidy data make it easier to manipulate, clean, and analyze qualitative datasets in R.\n\nRectangular Data: Another term for a table or data frame, where rows and columns are used to organize data in R.\n\nüóÇÔ∏è Qualitative Metadata & Labeling Term\n\nSpeaker Label: An identifier showing who is speaking (e.g., ‚ÄúFacilitator,‚Äù ‚ÄúParticipant 1‚Äù). Clean data should use consistent speaker labels.\nParticipant ID: A unique identifier assigned to participants to protect anonymity (e.g., ‚ÄúP01‚Äù). These are often used in place of names.\nSession ID/Group: The label identifying the specific interview or focus group a participant was part of (e.g., ‚ÄúSession 1 ‚Äì Educators‚Äù).\nDiscussion Section/Topic Area: A label identifying a portion of the conversation (e.g., ‚ÄúBarriers,‚Äù ‚ÄúRecommendations‚Äù) to help organize qualitative data.\n\n‚úÇÔ∏è Data Cleaning & Transformation Terms\n\nAnonymization/De-Identification: The process of removing or replacing personal identifiers (e.g., names, locations, job titles) to protect participant privacy.\nStandardization: Making text consistent in format (e.g., converting to lowercase, consistent punctuation, spacing).\nTokenization: (Optional depending on your analysis!) Breaking down text into smaller parts‚Äîwords, sentences, or phrases‚Äîtypically for text mining. Not always part of standard qualitative coding workflows.\nFiltering: Removing unnecessary rows or segments (e.g., small talk, off-topic responses) from the data.\nRecoding: Transforming data from one format to another (e.g., generalizing job titles or grouping participant roles).\nJoin/Merge: Combining two datasets based on a shared key (e.g., merging participant demographic info with transcripts).\nPivoting: Restructuring data from wide format (many columns) to long format (many rows), or vice versa, to make it easier to analyze or display.\n\nüè∑Ô∏è Text Cleaning Terms\n\nTimestamps: Time markers in transcripts (e.g., [00:12:34]) that need to be removed unless necessary for the analysis.\nFiller Words: Common speech disfluencies (e.g., ‚Äúum,‚Äù ‚Äúuh,‚Äù ‚Äúlike‚Äù) that can be removed for clarity, depending on analysis goals.\nInaudibles/Transcription Errors: Markers like ‚Äú[inaudible]‚Äù or machine transcription errors that need to be corrected or flagged.\nSpelling and Grammar Standardization: Correcting spelling errors that make text difficult to read, while preserving participant voice and tone where relevant."
  },
  {
    "objectID": "data_prep.html#reading-your-data-into-r",
    "href": "data_prep.html#reading-your-data-into-r",
    "title": "Data Cleaning",
    "section": "Reading your data into R",
    "text": "Reading your data into R\nFirst, we‚Äôll need to read our data into R. Depending on how your raw text is stored, you‚Äôll need to take various steps to read in your data for analysis. The goal is to turn any of your text into a dataframe with rows and columns of your text responses. In some cases, you may need to keep participant ID columns or other columns if you‚Äôre doing a mixed-method analysis. In other cases, you may be analyzing different focus groups and comparing them to eachother. Whatever you are doing, make sure your dataframe is set up or your analysis. If you are unsure about this, ask a member of Qual BPT for some help!\nHere is an example of what your data may look like when you first read it into R.\n\nand here‚Äôs what we want it to look like (eventually) for most of our analysis needs.\n\nWith clean data, we can:\n\nCompare participants‚Äô responses across sessions and discussion sections. We could answer questions like:\n\nWhat did Educators say about Community Impact vs.¬†Public Health?‚Äù\nWhat did participants across all interviews think about abatement funds?\n\nFilter by participant role (e.g., facilitators vs.¬†participants) for targeted analysis. We could answer questions like:\n\nHow many participants mentioned that the county should invest in wraparound services across all interviews?\nWhat is the most common barrier in accessing services in the county?\n\nPreserve anonymity by removing names and identifiers."
  },
  {
    "objectID": "fun_standards.html#reproducibility",
    "href": "fun_standards.html#reproducibility",
    "title": "Fundamental Standards",
    "section": "Reproducibility",
    "text": "Reproducibility\nAll data management and analysis must be transparently documented from start to finish.\nAnother Omni staff person should be able to independently retrace your steps and understand exactly how themes, findings, and interpretations were generated, without needing to confer with you directly. This applies to data management, coding, theme development, and interpretation.\nReproducibility in qualitative work is facilitated through:\n\nClear documentation of every step of the process, including:\n\nHow data were collected (e.g., interview guides, focus group protocols, open-ended survey items)\nHow transcripts or field notes were processed and stored\nHow coding was applied (including codebooks with definitions and decision rules)\nHow codes were organized into categories/themes\nHow interpretations and conclusions were drawn\n\nUse of qualitative data analysis software (e.g., Dedoose, R, or similar) that allows for:\n\nSystematic coding and categorization\nDocumentation of memos and analytic decisions\nExporting of coded data and audit trails\n\nMemos and annotations in plain English that explain:\n\nWhy specific codes were applied\nHow you handled complexities (e.g., contradictory data, ambiguous passages)\nRationale for developing themes and conclusions"
  },
  {
    "objectID": "fun_standards.html#analysis-reviews",
    "href": "fun_standards.html#analysis-reviews",
    "title": "Fundamental Standards",
    "section": "Analysis reviews",
    "text": "Analysis reviews\nWe check each other‚Äôs qualitative coding and interpretations.\nWe‚Äôre human, which means we bring our own perspectives and potential biases to qualitative work. To strengthen the credibility and trustworthiness of our findings, there must be at least two sets of eyes on:\n\nCodebooks\nApplication of codes\nTheme development and interpretation\n\nThis includes, at a minumum, one person who does the original coding and one person who reviews the coding or participates in a coding comparison. Peer debriefing and/or oversight review should also be used to critically examine interpretations, question assumptions, and ensure findings are rooted in the data rather than assumptions."
  },
  {
    "objectID": "fun_standards.html#save-and-preserve-raw-data-files",
    "href": "fun_standards.html#save-and-preserve-raw-data-files",
    "title": "Fundamental Standards",
    "section": "Save and Preserve Raw Data Files",
    "text": "Save and Preserve Raw Data Files\nOriginal data are maintained for the entirety of the project lifecycle.\nQualitative data can be messy: transcription software might include typos, audio recordings may be unclear, and datasets might include photos alongside text. Although we may engage in additional efforts to clean up our data, we must maintain a copy of the original data.\nOriginal data files should be:\n\nClearly Labeled (e.g., education_listening_session_transcript_raw.txt)\nSecurely Stored (i.e., saved to a locked down data folder in Dropbox)\nNever altered\n\nAny modifications (e.g., de-identification, transcript corrections, cleaning up of quotes for reporting) should be made on copies, with clear documentation of changes. This ensures data integrity, allows for mistakes to be traced and corrected, and maintains the authenticity of participants voices. Additionally, qualitative files should follow Omni‚Äôs data security protocols, ensuring confidentiality and participant protections at all stages."
  },
  {
    "objectID": "fun_standards.html#estimate-and-communicate-with-precision",
    "href": "fun_standards.html#estimate-and-communicate-with-precision",
    "title": "Fundamental Standards",
    "section": "Estimate and Communicate with Precision",
    "text": "Estimate and Communicate with Precision\nOur reporting is as precise as possible, and we precisely communicate the uncertainty of our findings.\nOur qualitative findings are presented with the greatest precision possible, and we communicate how interpretations were reached, including any uncertainties or limitations.\nWhen we present themes or findings to clients, they should be rooted in the data and include:\n\nClear explanations of how themes were derived\nDiscussion of alternative interpretations, where appropriate\nExplanation of analytic decisions, including the rationale for emphasizing certain themes over others\nTransparency about data limitations (e.g., sample characteristics, data quality, potential biases)\nCareful and intentional use of quantifiers (words like ‚Äúmany‚Äù, ‚Äúmost‚Äù may not be appropriate for all qualitative reporting, and should be used judiciously)\nDirect reporting of the number of participants/groups that the code/theme arose in (e.g., n=)\nDirect quotes that illustrate key themes\n\nThis information can be conveyed in a narrative or as a technical appendix. It not need to take up a lot of space in a report (regardless of where it is shared), but its inclusion better allows clients and communities to trust the rigor of our work."
  },
  {
    "objectID": "fun_standards.html#evaluate",
    "href": "fun_standards.html#evaluate",
    "title": "Fundamental Standards",
    "section": "Evaluate",
    "text": "Evaluate\nQuestion whether what you‚Äôre seeing makes sense. If it doesn‚Äôt make sense, dig in.\n#Inquiry is our greatest tool to ensure high-quality, accurate qualitative methods. At every step, from opening the raw data file to examining findings that emerge from our analyses, we should be critically examining our results and asking questions like: does this look like what we expected? does this make intuitive sense? what does this actually mean? If the answer to these questions are no or I don‚Äôt know or your gut tells you something is off, dig in until it is resolved. ‚ÄúDigging in‚Äù could consist of retracing your steps and double checking the code, the data, or assumptions about the data. It could be consulting a data dictionary, conferring with a colleague, or adding an agenda item to a project meeting. The important thing is to lean into inquiry, be critical, and identify those things that don‚Äôt seem right."
  },
  {
    "objectID": "methods.html#in-person-interviews",
    "href": "methods.html#in-person-interviews",
    "title": "Methods",
    "section": "In-Person Interviews",
    "text": "In-Person Interviews\nThe following are items/resources to consider for an in-person focus group or interview.\n\nDocuments\n\nList of confirmed participants with contact information (if applicable). This can be helpful if we need to text/call participants if they are lost, for example\nFocus group/interview guide: (1) for facilitator/interviewer and (1) for additional staff as needed (e.g., notetaker)\nNotetaking materials: facilitator/interviewer and/or notetaker may take notes on a guide, notebook, or laptop\nConsent form (if consent was not collected prior to the session) - (1) for each participant to take and (1) for each participant to sign and return.\n\nNOTE: If a youth focus group is being conducted, a parent/legal guardian consent form should be collected prior to the focus group. An assent form can be given to the youth (i.e., a similar document to a parent consent form, explaining participants‚Äô rights but without a place for the youth to sign).\n\nDemographic survey (if applicable)\nDebrief discussion tool for the facilitator/interviewer(s)\nIncentive tracking sheet (to collect gift card serial numbers and participant signatures)\n\n\n\nFacilitation Materials\n\nRecording equipment: Either 2 digital recorders ‚Äì (1) as primary, (1) as backup (smart devices such as an iPhone, iPad, or laptop often have a recording capability and can be leveraged for recording). Ensure that recorders have full batteries/charge. Bring extra batteries and a power cord (if using a smart device).\nLaptop\nPens for participants to sign consent forms\nComfort items: tissues, hand sanitizer, stress-relief toys\nSnacks and refreshments (as budget allows)\nIncentives (e.g., gift cards, cash)\nA flip chart (if applicable): markers and tape\nName tags/badges (if applicable)\nClipboards (if applicable): to complete forms\nTimer/clock (if applicable): room may not have a clock to track time, and facilitator/interviewer to avoid looking at their phone\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, site location/access instructions (e.g., parking map, parking voucher), and consent form\nReminder Emails: Send reminder emails at least 24 hours before the session. You may wish to send an additional reminder several days in advance\nThank You Emails: Follow-up by thanking participants for their time and inviting any final feedback\n\n\n\nSetting/Location\n\nAccessible by public transit\nParking space that is free or minimal cost (provide parking vouchers (if applicable))\nCentral or well known by the community (e.g., culturally sensitive)\nComfortable seating to arrange tables and chairs in a circle (if possible)\nRestroom access (where to point participants to the restroom)\nAccessibility (room is accessible to participants [e.g., wheelchair accessible], has technical supports, and is accessible to facilitator/interviewer if conducted after 5pm/business hours)\nOn-site childcare space for participants (if applicable)\nTransportation vouchers (if applicable)\n\n\n\nSafe Storage\n\nSecure Dropbox folders to store PII information (e.g., names, email addresses, phone numbers, physical addresses for qualitative data collection) per OMNI guidance\nShred documents that have PII information\nVPN access and passcode for phone storage if recorder is not available\nDestruction protocol (protocol on the timeline identified) per OMNI guidance"
  },
  {
    "objectID": "methods.html#virtual-interviews",
    "href": "methods.html#virtual-interviews",
    "title": "Methods",
    "section": "Virtual Interviews",
    "text": "Virtual Interviews\nPre-Session Preparation\n\nDocuments (links)\n\nParticipant/Registration List: Include confirmed participants and email addresses. Helpful for troubleshooting if anyone has difficulty joining the virtual platform.\n\nNote: Some projects may collect demographic information and/or gift card preferences at registration (e.g., physical or virtual).\n\nConsent Form: Provide access to a crosswalk showing that participants completed the consent form online.\nInterview/Focus Group Guide: Share links for both the facilitator/interviewer and notetaker, along with an agenda if relevant (e.g., breakout room activities). Facilitator or notetaker may take notes directly on the guide, in a notebook, or on a laptop.\nPPT Slides (if applicable): Use slides to highlight group norms, ground rules, Zoom how-to‚Äôs, or interview/focus group questions for accessibility.\n\n\n\nTechnical Preparation\n\nPlatform and Equipment\n\nConfirm you have full Zoom (or other platform) access and necessary features enabled: hosting, recording, breakout rooms, and transcription.\nCheck for updates before the session and test your microphone, camera, and internet connection.\nEnsure a strong and stable internet connection and develop a backup plan for potential connectivity issues.\nChoose a quiet, well-lit location to support accessibility and engagement.\nOpen all needed materials in advance (e.g., guides, slides, notes). If using one monitor, be mindful of maintaining eye contact and engaged body language while referencing materials.\n\n\n\nZoom Configuation\n\nEnable the waiting room to control participant entry.\nAssign alternative hosts in advance so others can manage the session if needed.\nConfirm that facilitators can record sessions, including breakout rooms (saved to their cloud).\nAdjust breakout room settings to avoid automatic closing unless intentional.\nTest your camera, microphone, and internet connection again within Zoom before the session.\n\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, virtual platform registration link, and consent form\nReminder Emails: Send reminder emails at least 24 hours ahead. You may wish to send another email one hour before the session\nTech Support Instructions: Provide instructions in the email or as an attachment for participants on how to access the virtual platform. Offer one-on-one support if participants need assistance.\nThank You Emails with Incentive/Meal voucher information (e.g., door dash, gift card): Thank participants for their time, invite any final feedback, and include a link to gather their gift card preferences (if not gathered before the event. If the gift card has already been distributed, you may wish to ask if there are any questions related to their incentive\n\n\n\nFacilitation and Support Roles\n\nAssign clear roles before the event:\n\nFacilitator/Interviewer: Leads the session, manages time, and engages participants.\nNotetaker/Tech Support: Monitors chat, handles recording, and provides technical assistance.\n\nOne team member should confirm attendance (via registration list or Zoom report). Note: Zoom attendance reports can be imperfect; double-check manually if needed.\n\n\n\nAccessibility and Engagement\n\nProvide a FAQ or Zoom instructions in advance for participants unfamiliar with the platform.\nUse slides to display discussion questions, ground rules, and key information for participants who prefer visual reference.\nPin facilitators/co-facilitators to foster connection.\nEncourage use of emoji reactions (thumbs up, checkmark) for participants who choose not to use their cameras.\nKeep accessibility in mind by minimizing distractions and allowing time for processing.\n\n\n\nBreakout Room Management\n\nAssign one staff member to remain in the main room for late arrivals or tech issues.\nPrepare an Excel list of registrants with breakout room categories to streamline assignments and track attendance.\nCoordinate breakout room timing manually if possible (uncheck the ‚Äúclose automatically‚Äù option).\nEnsure each breakout room has a designated facilitator or notetaker.\n\n\n\nSafe Storage\n\nStore personally identifiable information (PII) securely (e.g., names, emails, phone numbers, addresses) in approved Dropbox folders following Omni guidance.\nFollow data destruction protocols according to the timelines in Salesforce."
  },
  {
    "objectID": "methods.html#zoom-considerations",
    "href": "methods.html#zoom-considerations",
    "title": "Methods",
    "section": "Zoom Considerations",
    "text": "Zoom Considerations\n\nPreparation\n\nEnable the Zoom waiting room to control when participants join\nSet facilitators as alternative hosts before the Zoom meeting\n\nNOTE: Facilitators can record their sessions during breakout rooms, which will be saved in their cloud.\n\nDesignate someone to support notes, tech, or monitoring of chat if budget allows\nTest your equipment in Zoom settings, ensuring your camera, microphone, and internet connection are stable\nChoose a quiet, well-lit location to support accessibility\nHave your slides and/or documents ready (minimized or on a different monitor screen)\n\nNOTE: If working from one screen, be mindful of looking down often while facilitating maintaining eye contact or engaged body language\n\nSend the meeting link, agenda, and relevant materials (e.g., Zoom FAQ, ground rules, etc.) to participants beforehand\n\nNOTE: You may consider sending an email reminder a week in advance, in addition to 24 hours before the event\n\n\n\n\nGeneral Considerations\n\nEnsure facilitators or notetakers capture attendance. Although Zoom usage reports provide a file of who attended, it is not always the cleanest, as people can come in/out of the room\nMinimizing the Zoom window may be helpful when referencing a guide and maintaining eye contact.\nPinning the facilitator and/or co-facilitator may foster more connection during the session.\nUtilizing the emoji thumbs up or checkmark can support communication for folks who opt for no camera during the participant rights portion and throughout the discussion\nTo support accessibility, facilitators may provide a FAQ document to ensure folks can join Zoom and/or include the discussion questions on a slide deck to allow people to process the questions\n\n\n\nBreak Out Room Considerations\n\nEnsure one staff person can be in the main room if participants join the Zoom session late or leave their break-out room\nWhen creating break-out rooms, ensure that the option of closing a break-out room after 30 minutes is unchecked. This should also apply to all facilitators in the Zoom meeting. The options button appears when you are setting up break-out rooms\nIt is helpful for the staff person creating the breakout rooms to have an Excel spreadsheet of those who registered for the Zoom session and the demographic/breakout room categories. This can help you plan for who is expected to attend, create those assignments, and see who did not make it"
  },
  {
    "objectID": "food.html",
    "href": "food.html",
    "title": "Food/Refreshments",
    "section": "",
    "text": "Planning for food involves thoughtful planning to ensure participants are comfortable or excited/interested in the food options. It is important to provide meals/refreshments or snacks, primarily if the focus group or facilitation session is held during a lunch or dinner hour. Even if not during those times, providing a light snack is a courtesy we should try to incorporate to support engagement. Review the following considerations:"
  },
  {
    "objectID": "food.html#participant-preferences",
    "href": "food.html#participant-preferences",
    "title": "Food/Refreshments",
    "section": "Participant Preferences",
    "text": "Participant Preferences\n\nConsider dietary restrictions: Check in with participants about allergies and dietary restrictions (e.g., gluten-free, vegetarian, kosher, etc.).\nConsider local businesses and what the client recommends as community favorites\nConsider cultural foods: Food choices may be affected by cultural preferences/restrictions\nConsider age of participants: Tailor food options familiar to the age groups (e.g., youth-friendly snack).\nPizza goes over well with families typically, especially with youth. Side salad also goes over well.\n\n##Food Options\n\nNon-messy: pick foods/snacks that are easy to eat and not messy (e.g., bite-size portions)\n\nExamples: Mini bagels and cream cheese; cubed cheese, crackers, and fruit platter; soft cookies, muffins, sliced banana bread, etc.\n\nNon-noisy: Avoid crunchy foods or items with wrappers that may affect the sound quality of a recording\nHealth conscious foods: Include healthy options like fresh fruits/vegetables or snacks, considering access to fresh foods may be challenging for some communities and are deserving of a meal/snack that is good for them (this doesn‚Äôt mean fun foods like pizza are not encouraged, but including a mix of options si recommended)\n\nHealthy foods like a fruit tray is well received (e.g., grapes, cut melon, strawberries, etc.), but it can also be helpful to mix in more ‚Äúdessert‚Äù types of foods (e.g., soft cookies, mini muffins) for variety."
  },
  {
    "objectID": "food.html#beverage-options",
    "href": "food.html#beverage-options",
    "title": "Food/Refreshments",
    "section": "Beverage Options",
    "text": "Beverage Options\n\nWater: Keep participants hydrated and avoid providing sugary beverages. If you are concerned about the waste of bottled water, you could provide pitchers of cool water with cups.\nCoffee: Consider for morning events and/or from a cultural context that coffee is often consumed during catch-up/conversations. Bring creamer, sugar, and stirrers/spoons.\nTea: You may also wish to make available herbal and caffeinated tea options. If so, plan to also bring along a kettle if needed or ensure the location has one available"
  },
  {
    "objectID": "food.html#budgeting",
    "href": "food.html#budgeting",
    "title": "Food/Refreshments",
    "section": "Budgeting",
    "text": "Budgeting\n\nFollow the budgetary amount set aside for refreshments. With that in mind, if you‚Äôre unsure how much food to buy or serve, it‚Äôs better to have a little extra rather than not enough. We want to make sure everyone has a chance to enjoy the food. Any leftovers can be offered to participants or staff to take home if they‚Äôre interested."
  },
  {
    "objectID": "food.html#additional-considerations",
    "href": "food.html#additional-considerations",
    "title": "Food/Refreshments",
    "section": "Additional considerations:",
    "text": "Additional considerations:\n\nBring other materials that are needed such as napkins, plates, cups, and serving trays.\nThe facilitator may incorporate breaks for participants to grab a snack, like a restroom break\nBring cleaning supplies such as Clorox wipes before placing the meals/snacks and after for clean-up\nLabel foods (if necessary) for participants to easily choose their preferences"
  },
  {
    "objectID": "food.html#previous-project-examples",
    "href": "food.html#previous-project-examples",
    "title": "Food/Refreshments",
    "section": "Previous Project Examples:",
    "text": "Previous Project Examples:\n\nOn Kids Count, a dinner of pizza, Santiagos Rice/beans, or Qdoba etc. was typically just under $200 for a group of 25, including water and King Soopers cookies for dessert. Breakfast sessions were about $150 for food (bagels, fruit, etc.), water, and coffee for 25 people"
  },
  {
    "objectID": "interviews.html",
    "href": "interviews.html",
    "title": "Interviews",
    "section": "",
    "text": "Omni uses various methods for qualitative data collection, including interviews and focus groups, open-ended survey responses, and mixed-methods integration.\nBelow are some guidance and considerations for you as you plan for a qualitative method."
  },
  {
    "objectID": "interviews.html#in-person-interviews",
    "href": "interviews.html#in-person-interviews",
    "title": "Interviews",
    "section": "In-Person Interviews",
    "text": "In-Person Interviews\nThe following are items/resources to consider for an in-person focus group or interview.\n\nDocuments\n\nList of confirmed participants with contact information (if applicable). This can be helpful if we need to text/call participants if they are lost, for example\nFocus group/interview guide: (1) for facilitator/interviewer and (1) for additional staff as needed (e.g., notetaker)\nNotetaking materials: facilitator/interviewer and/or notetaker may take notes on a guide, notebook, or laptop\nConsent form (if consent was not collected prior to the session) - (1) for each participant to take and (1) for each participant to sign and return.\n\nNOTE: If a youth focus group is being conducted, a parent/legal guardian consent form should be collected prior to the focus group. An assent form can be given to the youth (i.e., a similar document to a parent consent form, explaining participants‚Äô rights but without a place for the youth to sign).\n\nDemographic survey (if applicable)\nDebrief discussion tool for the facilitator/interviewer(s)\nIncentive tracking sheet (to collect gift card serial numbers and participant signatures)\n\n\n\nFacilitation Materials\n\nRecording equipment: Either 2 digital recorders ‚Äì (1) as primary, (1) as backup (smart devices such as an iPhone, iPad, or laptop often have a recording capability and can be leveraged for recording). Ensure that recorders have full batteries/charge. Bring extra batteries and a power cord (if using a smart device).\nLaptop\nPens for participants to sign consent forms\nComfort items: tissues, hand sanitizer, stress-relief toys\nSnacks and refreshments (as budget allows)\nIncentives (e.g., gift cards, cash)\nA flip chart (if applicable): markers and tape\nName tags/badges (if applicable)\nClipboards (if applicable): to complete forms\nTimer/clock (if applicable): room may not have a clock to track time, and facilitator/interviewer to avoid looking at their phone\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, site location/access instructions (e.g., parking map, parking voucher), and consent form\nReminder Emails: Send reminder emails at least 24 hours before the session. You may wish to send an additional reminder several days in advance\nThank You Emails: Follow-up by thanking participants for their time and inviting any final feedback\n\n\n\nSetting/Location\n\nAccessible by public transit\nParking space that is free or minimal cost (provide parking vouchers (if applicable))\nCentral or well known by the community (e.g., culturally sensitive)\nComfortable seating to arrange tables and chairs in a circle (if possible)\nRestroom access (where to point participants to the restroom)\nAccessibility (room is accessible to participants [e.g., wheelchair accessible], has technical supports, and is accessible to facilitator/interviewer if conducted after 5pm/business hours)\nOn-site childcare space for participants (if applicable)\nTransportation vouchers (if applicable)\n\n\n\nSafe Storage\n\nSecure Dropbox folders to store PII information (e.g., names, email addresses, phone numbers, physical addresses for qualitative data collection) per OMNI guidance\nShred documents that have PII information\nVPN access and passcode for phone storage if recorder is not available\nDestruction protocol (protocol on the timeline identified) per OMNI guidance"
  },
  {
    "objectID": "interviews.html#virtual-interviews",
    "href": "interviews.html#virtual-interviews",
    "title": "Interviews",
    "section": "Virtual Interviews",
    "text": "Virtual Interviews\nPre-Session Preparation\n\nDocuments (links)\n\nParticipant/Registration List: Include confirmed participants and email addresses. Helpful for troubleshooting if anyone has difficulty joining the virtual platform.\n\nNote: Some projects may collect demographic information and/or gift card preferences at registration (e.g., physical or virtual).\n\nConsent Form: Provide access to a crosswalk showing that participants completed the consent form online.\nInterview/Focus Group Guide: Share links for both the facilitator/interviewer and notetaker, along with an agenda if relevant (e.g., breakout room activities). Facilitator or notetaker may take notes directly on the guide, in a notebook, or on a laptop.\nPPT Slides (if applicable): Use slides to highlight group norms, ground rules, Zoom how-to‚Äôs, or interview/focus group questions for accessibility.\n\n\n\nTechnical Preparation\n\nPlatform and Equipment\n\nConfirm you have full Zoom (or other platform) access and necessary features enabled: hosting, recording, breakout rooms, and transcription.\nCheck for updates before the session and test your microphone, camera, and internet connection.\nEnsure a strong and stable internet connection and develop a backup plan for potential connectivity issues.\nChoose a quiet, well-lit location to support accessibility and engagement.\nOpen all needed materials in advance (e.g., guides, slides, notes). If using one monitor, be mindful of maintaining eye contact and engaged body language while referencing materials.\n\n\n\nZoom Configuation\n\nEnable the waiting room to control participant entry.\nAssign alternative hosts in advance so others can manage the session if needed.\nConfirm that facilitators can record sessions, including breakout rooms (saved to their cloud).\nAdjust breakout room settings to avoid automatic closing unless intentional.\nTest your camera, microphone, and internet connection again within Zoom before the session.\n\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, virtual platform registration link, and consent form\nReminder Emails: Send reminder emails at least 24 hours ahead. You may wish to send another email one hour before the session\nTech Support Instructions: Provide instructions in the email or as an attachment for participants on how to access the virtual platform. Offer one-on-one support if participants need assistance.\nThank You Emails with Incentive/Meal voucher information (e.g., door dash, gift card): Thank participants for their time, invite any final feedback, and include a link to gather their gift card preferences (if not gathered before the event. If the gift card has already been distributed, you may wish to ask if there are any questions related to their incentive\n\n\n\nFacilitation and Support Roles\n\nAssign clear roles before the event:\n\nFacilitator/Interviewer: Leads the session, manages time, and engages participants.\nNotetaker/Tech Support: Monitors chat, handles recording, and provides technical assistance.\n\nOne team member should confirm attendance (via registration list or Zoom report). Note: Zoom attendance reports can be imperfect; double-check manually if needed.\n\n\n\nAccessibility and Engagement\n\nProvide a FAQ or Zoom instructions in advance for participants unfamiliar with the platform.\nUse slides to display discussion questions, ground rules, and key information for participants who prefer visual reference.\nPin facilitators/co-facilitators to foster connection.\nEncourage use of emoji reactions (thumbs up, checkmark) for participants who choose not to use their cameras.\nKeep accessibility in mind by minimizing distractions and allowing time for processing.\n\n\n\nBreakout Room Management\n\nAssign one staff member to remain in the main room for late arrivals or tech issues.\nPrepare an Excel list of registrants with breakout room categories to streamline assignments and track attendance.\nCoordinate breakout room timing manually if possible (uncheck the ‚Äúclose automatically‚Äù option).\nEnsure each breakout room has a designated facilitator or notetaker.\n\n\n\nSafe Storage\n\nStore personally identifiable information (PII) securely (e.g., names, emails, phone numbers, addresses) in approved Dropbox folders following Omni guidance.\nFollow data destruction protocols according to the timelines in Salesforce."
  },
  {
    "objectID": "incentives.html",
    "href": "incentives.html",
    "title": "Incentives",
    "section": "",
    "text": "Always refer to an incentive protocol developed by the project team when processing incentives for qualitative methods.\n\nGather repeated names of focus group registration as participants may have the same first or last name or join via a friend/connection‚Äôs Zoom link. Keep the name/email/attendance record in the same row in a tracking spreadsheet.\nHave separate lines for Name, Address, Address 2 (apartment/unit number), City, State, and Zip in an online form of contact information. Prompt people to include their apartment or unit number in the directions.\n\nThis makes mail merging with many responses much easier when processing physical gift cards and helps prevent mail from bouncing back to us.\n\nPlease be aware of the specific challenges/benefits of the administration method and the vendor you‚Äôre working with (e.g., physical vs.¬†e-gift card; Amazon vs.¬†Kroger vs.¬†Visa [which carries a $5 activation fee]; etc.).\n\nNOTE: To avoid online scammers, you may wish to limit your options to physical gift cards, as they require a mailing address. By contrast, e-gift cards only require a valid email address, and scammers have sophisticated methods for creating multiple email addresses.\n\n\nSee some examples of incentive tracking spreadsheets here:\n\nSummit County Community Health Assessment PhotoVoice Incentive Tracker\nDeKalb County Community Health Assessment Qual Incentive Tracker"
  },
  {
    "objectID": "incentives.html#in-person-interviews",
    "href": "incentives.html#in-person-interviews",
    "title": "Incentives",
    "section": "In-Person Interviews",
    "text": "In-Person Interviews\nThe following are items/resources to consider for an in-person focus group or interview.\n\nDocuments\n\nList of confirmed participants with contact information (if applicable). This can be helpful if we need to text/call participants if they are lost, for example\nFocus group/interview guide: (1) for facilitator/interviewer and (1) for additional staff as needed (e.g., notetaker)\nNotetaking materials: facilitator/interviewer and/or notetaker may take notes on a guide, notebook, or laptop\nConsent form (if consent was not collected prior to the session) - (1) for each participant to take and (1) for each participant to sign and return.\n\nNOTE: If a youth focus group is being conducted, a parent/legal guardian consent form should be collected prior to the focus group. An assent form can be given to the youth (i.e., a similar document to a parent consent form, explaining participants‚Äô rights but without a place for the youth to sign).\n\nDemographic survey (if applicable)\nDebrief discussion tool for the facilitator/interviewer(s)\nIncentive tracking sheet (to collect gift card serial numbers and participant signatures)\n\n\n\nFacilitation Materials\n\nRecording equipment: Either 2 digital recorders ‚Äì (1) as primary, (1) as backup (smart devices such as an iPhone, iPad, or laptop often have a recording capability and can be leveraged for recording). Ensure that recorders have full batteries/charge. Bring extra batteries and a power cord (if using a smart device).\nLaptop\nPens for participants to sign consent forms\nComfort items: tissues, hand sanitizer, stress-relief toys\nSnacks and refreshments (as budget allows)\nIncentives (e.g., gift cards, cash)\nA flip chart (if applicable): markers and tape\nName tags/badges (if applicable)\nClipboards (if applicable): to complete forms\nTimer/clock (if applicable): room may not have a clock to track time, and facilitator/interviewer to avoid looking at their phone\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, site location/access instructions (e.g., parking map, parking voucher), and consent form\nReminder Emails: Send reminder emails at least 24 hours before the session. You may wish to send an additional reminder several days in advance\nThank You Emails: Follow-up by thanking participants for their time and inviting any final feedback\n\n\n\nSetting/Location\n\nAccessible by public transit\nParking space that is free or minimal cost (provide parking vouchers (if applicable))\nCentral or well known by the community (e.g., culturally sensitive)\nComfortable seating to arrange tables and chairs in a circle (if possible)\nRestroom access (where to point participants to the restroom)\nAccessibility (room is accessible to participants [e.g., wheelchair accessible], has technical supports, and is accessible to facilitator/interviewer if conducted after 5pm/business hours)\nOn-site childcare space for participants (if applicable)\nTransportation vouchers (if applicable)\n\n\n\nSafe Storage\n\nSecure Dropbox folders to store PII information (e.g., names, email addresses, phone numbers, physical addresses for qualitative data collection) per OMNI guidance\nShred documents that have PII information\nVPN access and passcode for phone storage if recorder is not available\nDestruction protocol (protocol on the timeline identified) per OMNI guidance"
  },
  {
    "objectID": "incentives.html#virtual-interviews",
    "href": "incentives.html#virtual-interviews",
    "title": "Incentives",
    "section": "Virtual Interviews",
    "text": "Virtual Interviews\nPre-Session Preparation\n\nDocuments (links)\n\nParticipant/Registration List: Include confirmed participants and email addresses. Helpful for troubleshooting if anyone has difficulty joining the virtual platform.\n\nNote: Some projects may collect demographic information and/or gift card preferences at registration (e.g., physical or virtual).\n\nConsent Form: Provide access to a crosswalk showing that participants completed the consent form online.\nInterview/Focus Group Guide: Share links for both the facilitator/interviewer and notetaker, along with an agenda if relevant (e.g., breakout room activities). Facilitator or notetaker may take notes directly on the guide, in a notebook, or on a laptop.\nPPT Slides (if applicable): Use slides to highlight group norms, ground rules, Zoom how-to‚Äôs, or interview/focus group questions for accessibility.\n\n\n\nTechnical Preparation\n\nPlatform and Equipment\n\nConfirm you have full Zoom (or other platform) access and necessary features enabled: hosting, recording, breakout rooms, and transcription.\nCheck for updates before the session and test your microphone, camera, and internet connection.\nEnsure a strong and stable internet connection and develop a backup plan for potential connectivity issues.\nChoose a quiet, well-lit location to support accessibility and engagement.\nOpen all needed materials in advance (e.g., guides, slides, notes). If using one monitor, be mindful of maintaining eye contact and engaged body language while referencing materials.\n\n\n\nZoom Configuation\n\nEnable the waiting room to control participant entry.\nAssign alternative hosts in advance so others can manage the session if needed.\nConfirm that facilitators can record sessions, including breakout rooms (saved to their cloud).\nAdjust breakout room settings to avoid automatic closing unless intentional.\nTest your camera, microphone, and internet connection again within Zoom before the session.\n\n\n\n\nCommunication\n\nInvitation Emails: Include the purpose of the interview/focus group, virtual platform registration link, and consent form\nReminder Emails: Send reminder emails at least 24 hours ahead. You may wish to send another email one hour before the session\nTech Support Instructions: Provide instructions in the email or as an attachment for participants on how to access the virtual platform. Offer one-on-one support if participants need assistance.\nThank You Emails with Incentive/Meal voucher information (e.g., door dash, gift card): Thank participants for their time, invite any final feedback, and include a link to gather their gift card preferences (if not gathered before the event. If the gift card has already been distributed, you may wish to ask if there are any questions related to their incentive\n\n\n\nFacilitation and Support Roles\n\nAssign clear roles before the event:\n\nFacilitator/Interviewer: Leads the session, manages time, and engages participants.\nNotetaker/Tech Support: Monitors chat, handles recording, and provides technical assistance.\n\nOne team member should confirm attendance (via registration list or Zoom report). Note: Zoom attendance reports can be imperfect; double-check manually if needed.\n\n\n\nAccessibility and Engagement\n\nProvide a FAQ or Zoom instructions in advance for participants unfamiliar with the platform.\nUse slides to display discussion questions, ground rules, and key information for participants who prefer visual reference.\nPin facilitators/co-facilitators to foster connection.\nEncourage use of emoji reactions (thumbs up, checkmark) for participants who choose not to use their cameras.\nKeep accessibility in mind by minimizing distractions and allowing time for processing.\n\n\n\nBreakout Room Management\n\nAssign one staff member to remain in the main room for late arrivals or tech issues.\nPrepare an Excel list of registrants with breakout room categories to streamline assignments and track attendance.\nCoordinate breakout room timing manually if possible (uncheck the ‚Äúclose automatically‚Äù option).\nEnsure each breakout room has a designated facilitator or notetaker.\n\n\n\nSafe Storage\n\nStore personally identifiable information (PII) securely (e.g., names, emails, phone numbers, addresses) in approved Dropbox folders following Omni guidance.\nFollow data destruction protocols according to the timelines in Salesforce."
  },
  {
    "objectID": "codebook.html",
    "href": "codebook.html",
    "title": "Codebook",
    "section": "",
    "text": "Omni‚Äôs core value of #accountability ensures that all of the work we do promotes accuracy, is transparent, and represents the lived experiences of our partners and the communities that we work with. Within the qualitative work that we do, this means that we keep detailed notes about 1) our coding decisions, 2) what those codes mean, and 3) how these codes build to the bigger picture in our analysis. Key to ensuring that we remain #accountable in our work, is the development of a codebook for every qualitative analysis conducted at Omni. Doing so is in alignment with Omni‚Äôs Fundamental Qualitative Standards and can lead to smoother, more transparent qualitative analyses and writeups.\nBelow you will find an example codebook template, an annotated codebook example, and a filled out codebook example. Every project at Omni that involves a qualitative analysis must include a fully-completed codebook that lives somewhere in the project‚Äôs space, either within Confluence or Dropbox. Codebooks should be accessible to the entire team, not just those conducting the analysis, and it is recommended that the codebook is shared in spaces alongside other key project information (i.e., Trello, Confluence main pages).\nNote: The structures of a codebook may change depending on the type of analysis that is completed. For example, if we are doing a content analysis, then we will not need the theme or theme description columns. You are also welcome to add additional columns with relevant information, such as notes, memos, and inclusion/exclusion criteria. It is important to ensure that the codes and their definitions remain clear, so we caution against including too much additional information. In rare instances, codebooks may be a deliverable on a project. In these instance, speak to the client about what they would like to have included. An example of a codebook deliverable can be found here."
  },
  {
    "objectID": "codebook.html#codebook-template",
    "href": "codebook.html#codebook-template",
    "title": "Codebook",
    "section": "Codebook Template",
    "text": "Codebook Template\n\n\n\n\n\n\n\n\n\n\n\nTheme\nTheme Description\nCode\nCode Type\nDefinition\nRepresentative Quote(s)\n\n\n\n\nLabel of the theme that was created based on the codes\nDefinition of the theme\nLabel of the code from within your coding structure (either in Dedoose or R)\nWhether the code is a parent code (i.e., high-level code) or child code (i.e., sub-code building up to the parent code)\nHow the code was defined by the coder\nExample quotes from the data that can help a reader better understand what the code means"
  },
  {
    "objectID": "codebook.html#codebooks-for-dedoose",
    "href": "codebook.html#codebooks-for-dedoose",
    "title": "Codebook",
    "section": "Codebooks for Dedoose",
    "text": "Codebooks for Dedoose\nDedoose also allows you to import and export codebooks. For project teams that will be using Dedoose, it may be helpful to opt for a structure that allows for easy importing and exporting of codes. In order to import your codes, Dedoose requires an Excel spreadsheet with the following column headings: Id, Parent Id, Title, Description, Weighted, Weight Minimum, Weight Maximum, and Weight Default.\nTo note, while this is helpful for ease of use in Dedoose, a codebook structured in this way will not likely be clear for clients or for new team members. Because of this, we recommend using this structure to import your codes into Dedoose AND then using Omni‚Äôs codebook template as you are coding your data to ensure that you have a clear and transparent codebook.\nMore information on the code import process for Dedoose can be found on their help page."
  },
  {
    "objectID": "analysis.html#executive-summary",
    "href": "analysis.html#executive-summary",
    "title": "Analysis",
    "section": "",
    "text": "Omni‚Äôs qualitative analysis guide supports staff in conducting transparent, systematic, and actionable qualitative research in complex, real-world settings. Our clients often require timely, credible findings grounded in participants‚Äô lived experiences. To meet these demands, this guide outlines practical workflows rooted in two complementary paradigms: pragmatism and critical realism.\n\n\n\nPragmatism directs us to focus on real-world utility and actionable insights.\n\n\nCritical realism encourages us to understand participant perspectives while acknowledging how those perspectives are shaped by broader structures and contexts.\n\n\n\nTogether, these paradigms support our commitment to meaningful, context-aware findings that are both usable and methodologically sound.\n\n\nThis guide provides step-by-step instructions for conducting qualitative analysis, from data pre-processing to reporting. It includes techniques like word frequency analysis, sentiment analysis, thematic coding, content analysis, and topic modeling, all implemented with transparency and adaptability in mind.\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\nTool Flexibility: While R is our preferred tool for reproducibility and integration with quantitative methods, the guide also includes best-practice workflows for using Dedoose (for team-based coding) and AI tools like NotebookLM (for early exploratory work).\n\n\n\n\n  \n\n\n\nMethod Selection Guidance: We offer practical decision points based on dataset size, analytic goals, and project context, ensuring methods match the scope and purpose of each evaluation.\n\n\n\n\n  \n  \n  \n\n\n\nStructured Workflows: Omni workflows help analysts navigate all stages of qualitative analysis‚Äîfrom clarifying analytic frameworks and coding approaches to integrating qualitative and quantitative data in mixed-methods designs.\n\n\n\n\n  \n  \n  \n\n\n\nAdaptability: Whether you're working with rich interview transcripts or brief open-ended survey responses, the guide provides adaptable tools that emphasize rigor, transparency, and context.\n\n\n\n\n\n\n\n\n\n\n\nBy centering participant voices, documenting our methods clearly, and\nmaintaining a reflexive stance, this guide strengthens the credibility\nand usefulness of Omni‚Äôs qualitative work. It equips staff with tools\nand strategies that not only meet evaluation standards but also foster\naccountability, responsiveness, and connection to the communities we\nserve.\n\n\n\n\n\n\nVersion Control\n\n\n\n\nVersion\nDescription\nDate released\n\n\n\n\n-4.0\nAdding interactive features\n2025-08-14\n\n\n-5.0\nSecond draft for review and rebrand\n2025-08-14\n\n\n-6.0\nInitial draft for review\n2025-03-26"
  },
  {
    "objectID": "analysis.html#introduction",
    "href": "analysis.html#introduction",
    "title": "Analysis",
    "section": "Introduction",
    "text": "Introduction\n\n\nAt Omni, we conduct qualitative research in complex, real-world environments. Our clients and projects often require fast timelines, nuanced insights, and transparent methods that can stand up to external review. To meet these needs, we use systematic, reproducible qualitative analysis methods grounded in pragmatism and critical realism.\n\n\n\n\n\n\n\nAt Omni, we conduct qualitative research in complex, real-world environments. Our clients and projects often require fast timelines, nuanced insights, and transparent methods that can stand up to external review. To meet these needs, we use systematic, reproducible qualitative analysis methods grounded in pragmatism and critical realism.\n\n\n\n\nThis approach ensures our findings are actionable and reflect the realities and lived experiences of participants, while acknowledging the influence of context, interpretation, and limitations in our data."
  },
  {
    "objectID": "analysis.html#omnis-approach-to-analysis",
    "href": "analysis.html#omnis-approach-to-analysis",
    "title": "Analysis",
    "section": "Omni‚Äôs Approach to Analysis",
    "text": "Omni‚Äôs Approach to Analysis\nOmni‚Äôs qualitative practice is grounded in pragmatism and critical realism.\n\nPragmatism means we focus on providing useful, actionable insights for real-world decision-making. Our goal is to help clients understand participants‚Äô experiences in ways that inform policy, programs, and practice. This reflects a pragmatic stance rooted in the work of scholars like  Morgan (2007)  and  Danermark et al.¬†(2015) , emphasizing inquiry that is guided by consequences and utility.\nCritical realism acknowledges that while participants‚Äô experiences reflect real phenomena (barriers, challenges, successes), they are shaped by context and perspective. Influenced by  Fletcher‚Äôs (2017)  work and work by others, this perspective guides us to acknowledge our limitations, reflect on researcher influence, and avoid overstating claims.\nOmni‚Äôs qualitative practice draws on reflexive thematic analysis  (Clarke & Braun, 2006)  and content analysis  (Hseih & Shannon, 2005) , emphasizing the researcher‚Äôs active role in interpreting data and constructing themes, in alignment with our commitment to critical realism and methodological transparency.\n\n\nTransparent and Systematic Workflows\nAt Omni, we use structured qualitative and mixed-methods workflows. These processes are transparent, systematic, and designed to integrate qualitative and quantitative findings when appropriate.\n\nExample Omni Workflow for Qualitative analysis:\n\nClarify Purpose and Analytic Framework\n\n\nDefine the evaluation questions and purpose of the qualitative analysis\nSelect an analytic method\n\n\nPrepare and Familiarize with the Data\n\n\nClean transcripts/text\nRead through interviews, discussions, or sessions at least once (text like reports you may not need context for, use your discretion)\n\n\nSystematic Coding of the Data\n\n\nDeductive, Inductive, or hybrid\nDeductive coding uses predefined codes (like our dictionaries) to apply to our data\nInductive coding uses text mining or topic modeling to identify emergent themes\n\n\nTheme Development and Refinement\n\n\nAnalyze and refine codes/themes\n\n\nInterpretation and Synthesis\n\n\nCompare themes to evaluation questions and contextual frameworks\n\n\nExplore themes visually\nGet ready for reporting"
  },
  {
    "objectID": "analysis.html#ways-of-analyzing-qualitative-data",
    "href": "analysis.html#ways-of-analyzing-qualitative-data",
    "title": "Analysis",
    "section": "Ways of Analyzing Qualitative Data",
    "text": "Ways of Analyzing Qualitative Data\n\nR\nBest when - Datasets are large or mixed (qual + quant) and need audit trails.\n- You want reproducibility, automation, and version control.\n- You‚Äôre under time constraints and have existing scripts/templates (IRR optional or phased).\nPros - Transparent, reproducible code and scalable pipelines.\n- Flexible: word frequency, sentiment, dictionaries, topic models.\n- Produces precise visuals and integrates survey/demographic data easily.\nCons - Steeper setup and learning curve.\n- Requires clear documentation to ensure shared understanding.\n\n\n\nDedoose\nBest when - Working collaboratively with a team or training new coders.\n- Analyzing small‚Äìmoderate corpora.\n- Delivering quick turnarounds using built-in IRR workflows.\nPros - Multi-user collaboration, role permissions, IRR features.\n- Low barrier for non-programmers.\nCons - License cost.\n- Limited automation/custom analyses compared to code.\n- Reproducibility and export trails less granular than scripted pipelines.\n\n\n\nAI\nBest when - Exploring data early to surface possible themes or codes quickly.\n- Analyzing short corpora, scoping questions, or drafting a codebook.\n- Preparing stakeholder previews before deeper human analysis.\nPros - Very fast and accessible; supports brainstorming structures.\n- Can summarize, cluster, and compare data quickly.\n- Useful for early iteration before moving to R or Dedoose.\nCons - Not a substitute for human interpretation; may produce hallucinations.\n- Inconsistent across runs; lacks deep context if prompts are weak.\n- Data governance and privacy limits ‚Äî avoid uploading sensitive data.\n\n\n  \n    Method Selection\n    \n      \n    \n  \n\n\n\n\nOnce pre-processed, your data is ready for analysis. Selecting the right method depends on:\n\nHow much data you have\nYour research question(s)\nWhether you need exploratory insights or answers to specific questions\nYour integrative framework (if conducting mixed-methods)\n\n\n\n\n\n\n\nUnderstanding Your Data Before Analysis\nBefore starting pre-processing or analysis, it‚Äôs important to assess the scope and quality of your data. Take time to understand:\n\nHow many participants are included?\nHow much text do you have (word count, number of responses)?\nHow detailed are the responses (in-depth vs.¬†brief)?\nHow are participants grouped (by stakeholder type, session, etc.)?\nWhose voices are most important to elevate in this analysis?\n\nThis step ensures you choose methods that fit your dataset and align with your project goals. For example:\n\nSmaller datasets (under ~2,000 words) are well-suited to word frequency, sentiment analysis, or basic content analysis.\nLarger datasets (5,000+ words) can support topic modeling or advanced thematic analysis.\n\nAssessing your data upfront helps set realistic expectations for analysis and ensures your findings are grounded, transparent, and defensible.\n\n\nWorking with a Small Corpus\nAt Omni, qualitative research often happens in real-world settings, with tight timelines and limited participant availability. We may aim for 10 interviews and complete 5. We may expect long, detailed conversations and instead get brief answers. Even with these constraints, small datasets can still provide meaningful insights, especially when there is consistency across participant experiences.\nWhen working with limited data:\n\nFocus on what participants actually shared, rather than attempting to generalize.\nDocument patterns and recurring concerns, while linking them clearly to the project‚Äôs research questions.\nBe transparent about the number of participants, the methods used, and any limitations in interpretation.\n\nSmaller samples can still highlight critical issues‚Äîsuch as barriers to access or common recommendations for program improvement‚Äîbut the scope and representativeness of these findings should be clearly communicated.\n\n\nSuggested Methods by Dataset Size and Purpose\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: If you are working with open-ended\nresponses from a survey and have data from 30 or fewer\nparticipants, carefully consider whether the data are\nsufficient for meaningful analysis. In many cases, it is appropriate to\nreport that there were too few responses to analyze\nsystematically. However, if you need to report findings, be\ntransparent about limitations. Focus on describing frequently\nmentioned key words, rather than inferring broader themes.\nAvoid suggesting consensus when data are limited, and clearly state that\nfindings reflect input from a small number of\nparticipants. Transparent reporting maintains the credibility\nof your analysis.\n\n\n\n\n\nGrouping Voices to Guide Analysis\nBefore you start coding or analyzing, decide:\n\nWhose voices are we centering in this analysis?\nHow will we group participant responses?\n\nYour grouping choices influence:\n\nWhich perspectives are highlighted\nHow themes emerge\nWhat questions you can answer\n\nAt Omni, we might group data by:\n\nParticipant (individual experiences)\nStakeholder Group (e.g., educators vs.¬†public health professionals)\nDiscussion Section (e.g., barriers vs.¬†recommendations)\n\nThese decisions should align with the project‚Äôs goals and be clearly documented in reports and presentations.\n\n\nReady for Pre-processing?\nOnce you understand your data, you‚Äôre ready to start pre-processing!\n\n\n  \n    Cleaning and Pre-Processing Your Data"
  },
  {
    "objectID": "analysis.html#method-selection",
    "href": "analysis.html#method-selection",
    "title": "Analysis",
    "section": "Method Selection",
    "text": "Method Selection\n\n\nOnce pre-processed, your data is ready for analysis. Selecting the right method depends on:\n\nHow much data you have\nYour research question(s)\nWhether you need exploratory insights or answers to specific questions\nYour integrative framework (if conducting mixed-methods)\n\n\n\n\n\n\nUnderstanding Your Data Before Analysis\nBefore starting pre-processing or analysis, it‚Äôs important to assess the scope and quality of your data. Take time to understand:\n\nHow many participants are included?\nHow much text do you have (word count, number of responses)?\nHow detailed are the responses (in-depth vs.¬†brief)?\nHow are participants grouped (by stakeholder type, session, etc.)?\nWhose voices are most important to elevate in this analysis?\n\nThis step ensures you choose methods that fit your dataset and align with your project goals. For example:\n\nSmaller datasets (under ~2,000 words) are well-suited to word frequency, sentiment analysis, or basic content analysis.\nLarger datasets (5,000+ words) can support topic modeling or advanced thematic analysis.\n\nAssessing your data upfront helps set realistic expectations for analysis and ensures your findings are grounded, transparent, and defensible.\n\n\nWorking with a Small Corpus\nAt Omni, qualitative research often happens in real-world settings, with tight timelines and limited participant availability. We may aim for 10 interviews and complete 5. We may expect long, detailed conversations and instead get brief answers. Even with these constraints, small datasets can still provide meaningful insights, especially when there is consistency across participant experiences.\nWhen working with limited data:\n\nFocus on what participants actually shared, rather than attempting to generalize.\nDocument patterns and recurring concerns, while linking them clearly to the project‚Äôs research questions.\nBe transparent about the number of participants, the methods used, and any limitations in interpretation.\n\nSmaller samples can still highlight critical issues‚Äîsuch as barriers to access or common recommendations for program improvement‚Äîbut the scope and representativeness of these findings should be clearly communicated.\n\n\nSuggested Methods by Dataset Size and Purpose\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: If you are working with open-ended\nresponses from a survey and have data from 30 or fewer\nparticipants, carefully consider whether the data are\nsufficient for meaningful analysis. In many cases, it is appropriate to\nreport that there were too few responses to analyze\nsystematically. However, if you need to report findings, be\ntransparent about limitations. Focus on describing frequently\nmentioned key words, rather than inferring broader themes.\nAvoid suggesting consensus when data are limited, and clearly state that\nfindings reflect input from a small number of\nparticipants. Transparent reporting maintains the credibility\nof your analysis.\n\n\n\n\n\nGrouping Voices to Guide Analysis\nBefore you start coding or analyzing, decide:\n\nWhose voices are we centering in this analysis?\nHow will we group participant responses?\n\nYour grouping choices influence:\n\nWhich perspectives are highlighted\nHow themes emerge\nWhat questions you can answer\n\nAt Omni, we might group data by:\n\nParticipant (individual experiences)\nStakeholder Group (e.g., educators vs.¬†public health professionals)\nDiscussion Section (e.g., barriers vs.¬†recommendations)\n\nThese decisions should align with the project‚Äôs goals and be clearly documented in reports and presentations.\n\n\nReady for Pre-processing?\nOnce you understand your data, you‚Äôre ready to start pre-processing!\n\n\n  \n    Cleaning and Pre-Processing Your Data"
  },
  {
    "objectID": "approach.html",
    "href": "approach.html",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "",
    "text": "Omni‚Äôs qualitative analysis guide supports staff in conducting transparent, systematic, and actionable qualitative research in complex, real-world settings. Our clients often require timely, credible findings grounded in participants‚Äô lived experiences. To meet these demands, this guide outlines practical workflows rooted in two complementary paradigms: pragmatism and critical realism.\n\n\n\nPragmatism directs us to focus on real-world utility and actionable insights.\n\n\nCritical realism encourages us to understand participant perspectives while acknowledging how those perspectives are shaped by broader structures and contexts.\n\n\n\nTogether, these paradigms support our commitment to meaningful, context-aware findings that are both usable and methodologically sound.\n\n\nThis guide provides step-by-step instructions for conducting qualitative analysis, from data pre-processing to reporting. It includes techniques like word frequency analysis, sentiment analysis, thematic coding, content analysis, and topic modeling, all implemented with transparency and adaptability in mind."
  },
  {
    "objectID": "approach.html#executive-summary",
    "href": "approach.html#executive-summary",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "",
    "text": "Omni‚Äôs qualitative analysis guide supports staff in conducting transparent, systematic, and actionable qualitative research in complex, real-world settings. Our clients often require timely, credible findings grounded in participants‚Äô lived experiences. To meet these demands, this guide outlines practical workflows rooted in two complementary paradigms: pragmatism and critical realism.\n\n\n\nPragmatism directs us to focus on real-world utility and actionable insights.\n\n\nCritical realism encourages us to understand participant perspectives while acknowledging how those perspectives are shaped by broader structures and contexts.\n\n\n\nTogether, these paradigms support our commitment to meaningful, context-aware findings that are both usable and methodologically sound.\n\n\nThis guide provides step-by-step instructions for conducting qualitative analysis, from data pre-processing to reporting. It includes techniques like word frequency analysis, sentiment analysis, thematic coding, content analysis, and topic modeling, all implemented with transparency and adaptability in mind."
  },
  {
    "objectID": "approach.html#purpose",
    "href": "approach.html#purpose",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "Purpose",
    "text": "Purpose\nThis guide was developed to support Omni staff in conducting methodologically sound, transparent, and reproducible qualitative analyses. It offers practical, step-by-step instructions and highlights best practices for text pre-processing, analysis, and reporting. Whether working with interview transcripts, focus groups, open-ended survey responses, or other text-based data, Omni teams can use this guide to produce findings that are both grounded in participants‚Äô voices and useful for program improvement and decision-making.\n\nHow do our qualitative resources align with Omni‚Äôs core values?\nInquiry: Provides clear, rigorous methods that encourage thoughtful exploration of participants‚Äô experiences.\nAgility: Equips staff with adaptable tools to meet diverse project needs and respond efficiently to change.\nConnection: Centers participants‚Äô voices and strengthens relationships with the communities and partners we serve.\nAccountability: Uses transparent, reproducible analysis practices to keep our work credible, ethical, and trustworthy.\nIn many applied settings, qualitative methods (and especially mixed-methods) are described in vague terms. Reports may mention ‚Äúthemes emerging‚Äù or ‚Äútriangulating findings,‚Äù but rarely explain the actual process used to get there. This vagueness makes it hard to replicate or assess qualitative findings and limits their credibility.\n\n\nWhy Are Existing Descriptions of Methods So Vague?\nAt Omni, we aim to avoid vague or ad hoc practices. We document clear, systematic workflows that integrate qualitative insights with quantitative data when appropriate.\nSeveral factors explain the common lack of clarity in methodology:\n\nDifferent disciplines (e.g., public health vs.¬†education research) use different frameworks, leading to inconsistent approaches.\nQuantitative research has standard tools (R, SPSS, Stata), but qualitative tools (NVivo, MAXQDA, Dedoose) often rely on manual processes and don‚Äôt always integrate cleanly with quantitative workflows.\nQualitative analysis requires human interpretation and reflexivity. Documenting every step is time-consuming, and under tight timelines, many organizations skip this critical process.\nQualitative and quantitative teams often work separately, without shared standards or mixed-methods integration."
  },
  {
    "objectID": "approach.html#what-this-guide-covers",
    "href": "approach.html#what-this-guide-covers",
    "title": "Approach",
    "section": "What This Guide Covers",
    "text": "What This Guide Covers\nYou‚Äôll find guidance on:\n\nText mining / Natural Language Processing (NLP)\n(e.g., word frequency, sentiment analysis, topic modeling)\nThematic and content analysis\n(e.g., dictionary-based coding, thematic coding frameworks)\nNarrative analysis @qualBPT do we need?\n(Optional: e.g., structural analysis, language style matching)\nVisualizing and reporting qualitative data\n(e.g., word clouds, bar charts, heatmaps, joint displays for mixed-methods)\n\nThese methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more.\nIn many applied settings, qualitative methods (and especially mixed-methods) are described in vague terms. Reports may mention ‚Äúthemes emerging‚Äù or ‚Äútriangulating findings,‚Äù but rarely explain the actual process used to get there. This vagueness makes it hard to replicate or assess qualitative findings and limits their credibility.\n\n\n\n\n\n\nAt Omni, we aim to avoid vague or ad hoc practices. We document\nclear, systematic workflows that integrate qualitative insights with\nquantitative data when appropriate.\n\n\n\n\nWhy Are Existing Descriptions of Methods So Vague?\nSeveral factors explain the common lack of clarity in methodology:\n\nDifferent disciplines (e.g., public health vs.¬†education research) use different frameworks, leading to inconsistent approaches.\nQuantitative research has standard tools (R, SPSS, Stata), but qualitative tools (NVivo, MAXQDA, Dedoose) often rely on manual processes and don‚Äôt always integrate cleanly with quantitative workflows.\nQualitative analysis requires human interpretation and reflexivity. Documenting every step is time-consuming, and under tight timelines, many organizations skip this critical process.\nQualitative and quantitative teams often work separately, without shared standards or mixed-methods integration."
  },
  {
    "objectID": "approach.html#omnis-approach-to-analysis",
    "href": "approach.html#omnis-approach-to-analysis",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "Omni‚Äôs Approach to Analysis",
    "text": "Omni‚Äôs Approach to Analysis\nOmni‚Äôs qualitative practice is grounded in pragmatism and critical realism.\n\nPragmatism means we focus on providing useful, actionable insights for real-world decision-making. Our goal is to help clients understand participants‚Äô experiences in ways that inform policy, programs, and practice. This reflects a pragmatic stance rooted in the work of scholars like  Morgan (2007)  and  Danermark et al.¬†(2015) , emphasizing inquiry that is guided by consequences and utility.\nCritical realism acknowledges that while participants‚Äô experiences reflect real phenomena (barriers, challenges, successes), they are shaped by context and perspective. Influenced by  Fletcher‚Äôs (2017)  work and work by others, this perspective guides us to acknowledge our limitations, reflect on researcher influence, and avoid overstating claims.\nOmni‚Äôs qualitative practice draws on reflexive thematic analysis  (Clarke & Braun, 2006)  and content analysis  (Hseih & Shannon, 2005) , emphasizing the researcher‚Äôs active role in interpreting data and constructing themes, in alignment with our commitment to critical realism and methodological transparency.\n\n\nTransparent and Systematic Workflows\nAt Omni, we use structured qualitative and mixed-methods workflows. These processes are transparent, systematic, and designed to integrate qualitative and quantitative findings when appropriate.\n\nExample Omni Workflow for Qualitative analysis:\n\nClarify Purpose and Analytic Framework\n\n\nDefine the evaluation questions and purpose of the qualitative analysis\nSelect an analytic method\n\n\nPrepare and Familiarize with the Data\n\n\nClean transcripts/text\nRead through interviews, discussions, or sessions at least once (text like reports you may not need context for, use your discretion)\n\n\nSystematic Coding of the Data\n\n\nDeductive, Inductive, or hybrid\nDeductive coding uses predefined codes (like our dictionaries) to apply to our data\nInductive coding uses text mining or topic modeling to identify emergent themes\n\n\nTheme Development and Refinement\n\n\nAnalyze and refine codes/themes\n\n\nInterpretation and Synthesis\n\n\nCompare themes to evaluation questions and contextual frameworks\n\n\nExplore themes visually\nGet ready for reporting"
  },
  {
    "objectID": "approach.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "href": "approach.html#choosing-your-analysis-tool-r-vs.-dedoose-vs.-ai",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI",
    "text": "Choosing Your Analysis Tool: R vs.¬†Dedoose vs.¬†AI\n\nRDedooseAI\n\n\nBest when\n\nDatasets are large or mixed (qual + quant) and need audit trails.\n\nYou want reproducibility, automation, and version control.\n\nYou‚Äôre under time constraints and have existing scripts/templates (IRR optional or phased).\n\nPros\n\nTransparent, reproducible code and scalable pipelines.\n\nFlexible: word frequency, sentiment, dictionaries, topic models.\n\nProduces precise visuals and integrates survey/demographic data easily.\n\nCons\n\nSteeper setup and learning curve for new R users.\n\nRequires clear documentation to ensure shared understanding.\n\n\n\nBest when\n\nWorking collaboratively with a team or training new coders.\n\nAnalyzing small‚Äìmoderate datasets.\n\nDelivering quick turnarounds using built-in IRR workflows.\n\nPros\n\nMulti-user collaboration, role permissions, IRR features.\n\nLow barrier for non-programmers.\nSimple approach for line-by-line coding\n\nCons\n\nLicense cost.\n\nLimited automation/custom analyses compared to code.\n\nReproducibility and export trails less granular than scripted pipelines.\n\n\n\nBest when\n\nVery fast and low barrier (though not a replacement for traditional qualitative coding.\n\nAnalyzing small datasets, scoping questions, or drafting a codebook.\n\nPreparing stakeholder previews before deeper human analysis.\n\nPros\n\nVery fast and accessible; supports brainstorming structures.\n\nCan summarize, cluster, and compare data quickly.\n\nUseful for early iteration before moving to R or Dedoose.\n\nCons\n\nNot a substitute for human interpretation; may produce hallucinations.\nInconsistent across runs; lacks deep context if prompts are weak.\n\nData governance and privacy limits ‚Äî avoid uploading sensitive data."
  },
  {
    "objectID": "data_prep.html#terminology-1",
    "href": "data_prep.html#terminology-1",
    "title": "Data Cleaning",
    "section": "Terminology",
    "text": "Terminology\nBefore starting your pre-processing and analysis, it‚Äôs important to understand a few core terms. These concepts are essential for working with text data and deciding on the appropriate pre-processing and analysis steps.\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nTokenization\nBreaking text into units (words, phrases, sentences)\n\n\nStemming\nReducing words to their root (e.g., ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù)\n\n\nLemmatization\nReducing to dictionary form (e.g., ‚Äúbetter‚Äù ‚Üí ‚Äúgood‚Äù)\n\n\nStop Words\nCommon words often removed (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù)\n\n\nDocument-Term Matrix\nTable of word frequencies across documents\n\n\nTF-IDF\nTerm importance based on frequency and inverse document frequency\n\n\nDataset\nCollection of text documents as one dataset\n\n\nDictionary\nList of keywords/phrases used to code or categorize text\n\n\n\n\n# Load all packages \nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(quanteda)\nlibrary(textstem)\nlibrary(sentimentr)\nlibrary(topicmodels)\nlibrary(flextable)\nlibrary(knitr)\nlibrary(omni)\n\nPre-processing prepares your qualitative data for analysis by cleaning, organizing, and standardizing text. This step ensures the data is usable for word frequency, sentiment analysis, topic modeling, and other text mining techniques.\nYou should always assess the scope and quality of your data first:\n\nAre the data cleaned (lowercase, removed participant names, punctuation, symbols)?\nHow much text do you have? (Word counts per document/response.)\nHow many participants contributed?\nHow detailed or shallow are the responses?\nWhose voices are you analyzing?\n\nOnce you understand your data, you can decide which pre-processing steps are appropriate."
  },
  {
    "objectID": "data_prep.html#tokenization",
    "href": "data_prep.html#tokenization",
    "title": "Data Cleaning",
    "section": "Tokenization",
    "text": "Tokenization\nTokenization breaks text into individual pieces‚Äîusually words, but sometimes phrases or sentences.\n\nMost text mining techniques require tokenized text.\nThis is common for word frequency analysis, sentiment analysis, and topic modeling.\nAfter tokenization, we lose the flow of sentences which is generally okay for some analyses, but not for narrative analysis or content analysis.\n\nWhat are Stop Words?\nStop words are common words like ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúbut‚Äù that don‚Äôt add much meaning on their own. Because we want to focus on broader themes from our participants‚Äô voices, we usually want to remove stop words after text is tokenized. This process allows us to focus on content-rich words, like nouns and verbs. We should remove stop words when running a word frequency analysis, topic modeling, or sentiment analysis.\nWe can also create custom stop words that we want to remove from our analyses, for example, location names or project-specific words that appear frequently but aren‚Äôt relevant to the analysis.\nExample:\n\nIn the example below, my custom stop words are ‚Äútravis‚Äù and ‚Äúcounty‚Äù, and they‚Äôre added to the stop_words bank which includes other words like ‚Äúbut‚Äù, ‚Äúis‚Äù, ‚Äúthe‚Äù, etc. If you‚Äôd like to see all of the stop words, see View(stop_words).\n\n\n# %%%%%%%%%%%%%%% Stop words %%%%%%%%%%%%%%%\n\n# Use standard stop words + custom ones (e.g., counties, names)\nmy_stop_words &lt;- bind_rows(stop_words, \n                           data.frame(word = c(\"travis\", \n                                               \"county\"), lexicon = \"custom\"))\n\ncleaned_text &lt;- tokenized_text %&gt;% \n  anti_join(my_stop_words, by = \"word\")"
  },
  {
    "objectID": "data_prep.html#stemming",
    "href": "data_prep.html#stemming",
    "title": "Data Cleaning",
    "section": "Stemming",
    "text": "Stemming\nStemming words cuts them down to their root forms (e.g., ‚Äúrunning‚Äù becomes ‚Äúrun‚Äù). This pre-processing step should primarily be used for topic modeling or for other analyses that you decide that exact word form isn‚Äôt critical. This step is recommended to use with larger datasets, with typically hundreds of documents or more, but for our purposes we recommend stemming any time you have enough data for topic modeling (around 5,000 total words).\n\n# %%%%%%%%%%%%%%% Stemming %%%%%%%%%%%%%%%\n\nlibrary(textstem)\n\nstemmed_text &lt;- cleaned_text %&gt;%\n  mutate(stem_word = stem_words(word))"
  },
  {
    "objectID": "data_prep.html#lemmatization",
    "href": "data_prep.html#lemmatization",
    "title": "Data Cleaning",
    "section": "Lemmatization",
    "text": "Lemmatization\nLemmatization converts words to their dictionary root and keeps the words readable to the user (e.g., ‚Äúbetter‚Äù becomes ‚Äúgood‚Äù). This pre-processing step should be used for word frequency analysis, sentiment analysis, or thematic/content analysis as it works will with small and large datasets.\n\n# %%%%%%%%%%%%%%% Lemmatization %%%%%%%%%%%%%%%\n\nlemmatized_text &lt;- cleaned_text %&gt;% \n  mutate(lem_word = lemmatize_words(word))\n\nLet‚Äôs compare the stem words, vs lemmatized words against the original tokenized words:\n\ncompare_words &lt;- cleaned_text %&gt;% \n  left_join(stemmed_text, \n            by = join_by(line, \n                         speaker, \n                         participant_id, question, section, section_label,\n                         session, word)) %&gt;% \n  left_join(lemmatized_text,\n            by = join_by(line, \n                         speaker, \n                         participant_id, question, section, section_label,\n                         session, word)) %&gt;%\n  slice(1:10) %&gt;%\n  kable()\n\n\ncompare_words\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nline\nspeaker\nparticipant_id\nquestion\nsection\nsection_label\nsession\nword\nstem_word\nlem_word\n\n\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nbiggest\nbiggest\nbig\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nchallenges\nchalleng\nchallenge\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ntransportation\ntransport\ntransportation\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\npeople\npeopl\npeople\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ncars\ncar\ncar\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\nmakes\nmake\nmake\n\n\n2\nparticipant\nP1\n0\n1\nIntroduction\nEducation\ndifficult\ndifficult\ndifficult\n\n\n\n\n\n\n# create a data frame for the table\ncomparison_table &lt;- data.frame(\n  \"Stemming\" = c(\n    \"You need speed over accuracy\",\n    \"Working with large datasets\",\n    \"Basic information retrieval tasks\",\n    \"Search engines or topic modeling where fine detail isn't critical\",\n    \"Not concerned about human readability\"\n  ),\n  \"Lemmatization\" = c(\n    \"Slower but more accurate\",\n    \"Better for small datasets\",\n    \"Better for nuanced analysis\",\n    \"Better for in-depth analysis\",\n    \"Maintains readable words)\"\n  )\n)\n\nkable(comparison_table,\n      caption = \"When to Use Stemming vs. Lemmatization\",\n      align = 'll')\n\n\nWhen to Use Stemming vs.¬†Lemmatization\n\n\n\n\n\n\nStemming\nLemmatization\n\n\n\n\nYou need speed over accuracy\nSlower but more accurate\n\n\nWorking with large datasets\nBetter for small datasets\n\n\nBasic information retrieval tasks\nBetter for nuanced analysis\n\n\nSearch engines or topic modeling where fine detail isn‚Äôt critical\nBetter for in-depth analysis\n\n\nNot concerned about human readability\nMaintains readable words)"
  },
  {
    "objectID": "analysis_plan.html",
    "href": "analysis_plan.html",
    "title": "Analysis Plan",
    "section": "",
    "text": "# Create a fake, tidy qualitative dataset\ntext_data &lt;- tibble(\n  line = 1:10,\n  speaker = c(\"interviewer\", \"participant\", \"participant\", \"interviewer\", \"participant\",\n              \"participant\", \"interviewer\", \"participant\", \"participant\", \"participant\"),\n  participant_id = c(\"I1\", \"P1\", \"P2\", \"I1\", \"P1\", \"P2\", \"I1\", \"P1\", \"P2\", \"P1\"),\n  question = c(1, 0, 0, 1, 0, 0, 1, 0, 0, 0),\n  section = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 3),\n  section_label = c(\"Introduction\", \"Introduction\", \"Introduction\", \"Barriers\", \n                    \"Barriers\", \"Barriers\", \"Recommendations\", \"Recommendations\", \n                    \"Recommendations\", \"Recommendations\"),\n  text = c(\n    \"Can you tell me about your experience accessing services in the county?\",\n    \"Sure, I think one of the biggest challenges is transportation in Travis County. There are many people here who do not own their own cars which makes it difficult to access any type of treatment services. On top of that, the buses are never on time so people have to do a lot of planning ahead of time to get to their appointment.\",\n    \"I agree, especially for people in rural areas. It's hard to get to services.\",\n    \"What kinds of barriers do you see in your community?\",\n    \"Travis county definitely has a lack of awareness about available programs.\",\n    \"Also, the application process is confusing and time-consuming. The health administrative offices used to post the applications at midnight and they would take new clients on a rolling basis, so by the time it was morning all applications would be filled.\",\n    \"What are your recommendations for improving access?\",\n    \"More outreach and education campaigns would help Travis county residents, rather than wasting time on trying to get policy changes.\",\n    \"Simplifying the application process would make a big difference.\",\n    \"Providing transportation vouchers could also improve access.\"\n  ),\n  session = c(rep(\"Education\", 5), rep(\"Public Health\", 5))\n) %&gt;% \n  mutate(text = tolower(text),\n         text = str_replace_all(text, \"[^a-zA-Z0-9\\\\s]\", \"\"))\n\ntext_data &lt;- text_data %&gt;% \n  filter(speaker != \"interviewer\")\n\n# Tokenize text\ntokenized_text &lt;- text_data %&gt;% \n  unnest_tokens(word, text)\n\n# Use standard stop words + custom ones (e.g., counties, names)\nmy_stop_words &lt;- bind_rows(stop_words, \n                           data.frame(word = c(\"travis\", \n                                               \"county\"), lexicon = \"custom\"))\n\ncleaned_text &lt;- tokenized_text %&gt;% \n  anti_join(my_stop_words, by = \"word\")\n\nlibrary(textstem)\n\nstemmed_text &lt;- cleaned_text %&gt;%\n  mutate(stem_word = stem_words(word))\n\n\nlemmatized_text &lt;- cleaned_text %&gt;% \n  mutate(lem_word = lemmatize_words(word))"
  },
  {
    "objectID": "analysis_plan.html#planning-your-analysis",
    "href": "analysis_plan.html#planning-your-analysis",
    "title": "Analysis Plan",
    "section": "",
    "text": "Selecting the right analysis depends on:\n\nHow much data you have\nYour research question(s)\nWhether you need exploratory insights or answers to specific questions\nYour integrative framework (if conducting mixed-methods)\n\n\n\nBefore starting pre-processing or analysis, it‚Äôs important to assess the scope and quality of your data. Take time to understand:\n\nHow many participants are included?\nHow much text do you have (word count, number of responses)?\nHow detailed are the responses (in-depth vs.¬†brief)?\nHow are participants grouped (by stakeholder type, session, etc.)?\nWhose voices are most important to elevate in this analysis?\n\nThis step ensures you choose methods that fit your dataset and align with your project goals. For example:\n\nSmaller datasets (under ~2,000 words) are well-suited to word frequency, sentiment analysis, or basic content analysis.\nLarger datasets (5,000+ words) can support topic modeling or advanced thematic analysis. You can also conduct word frequency, sentiment analysis, or basic content analysis.\n\nAssessing your data upfront helps set realistic expectations for analysis and ensures your findings are grounded, transparent, and defensible.\n\n\n\nAt Omni, qualitative research often happens in real-world settings, with tight timelines and limited participant availability. We may aim for 10 interviews and complete 5. We may expect long, detailed conversations and instead get brief answers. Even with these constraints, small datasets can still provide meaningful insights, especially when there is consistency across participant experiences.\nWhen working with limited data:\n\nFocus on what participants actually shared, rather than attempting to generalize.\nDocument patterns and recurring concerns, while linking them clearly to the project‚Äôs research questions.\nBe transparent about the number of participants, the methods used, and any limitations in interpretation.\n\nSmaller samples can still highlight critical issues‚Äîsuch as barriers to access or common recommendations for program improvement‚Äîbut the scope and representativeness of these findings should be clearly communicated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: If you are working with open-ended responses from a survey and have data from 30 or fewer participants, carefully consider whether the data are sufficient for meaningful analysis. In many cases, it is appropriate to report that there were too few responses to analyze systematically. However, if you need to report findings, be transparent about limitations. Focus on describing frequently mentioned key words, rather than inferring broader themes. Avoid suggesting consensus when data are limited, and clearly state that findings reflect input from a small number of participants Transparent reporting maintains the credibility of your analysis.\n\n\n\n\nBefore you start coding or analyzing, decide:\n\nWhose voices are we centering in this analysis?\nHow will we group participant responses?\n\nYour grouping choices influence:\n\nWhich perspectives are highlighted\nHow themes emerge\nWhat questions you can answer\n\nAt Omni, we might group data by:\n\nParticipant (individual experiences)\nVested Partner Group (e.g., educators vs.¬†public health professionals)\nDiscussion Section (e.g., barriers vs.¬†recommendations)\n\nThese decisions should align with the project‚Äôs goals and be clearly documented in reports and presentations."
  },
  {
    "objectID": "analysis_plan.html#word-frequency-analysis",
    "href": "analysis_plan.html#word-frequency-analysis",
    "title": "Analysis Plan",
    "section": "Word frequency analysis",
    "text": "Word frequency analysis\nWord frequency analysis is a simple and effective method that counts how often specific words appear in your dataset. It‚Äôs often used early in qualitative analysis to get a general sense of prominent topics, but it can also be applied as a stand-alone method to identify frequently mentioned issues in participant responses. Word frequency works best when you have a reasonable amount of text to analyze. As a general best practice, having at least 100‚Äì200 content words (excluding stop words) allows for more reliable interpretation of patterns, though smaller datasets can still offer preliminary insights.\nTo ensure accuracy, it‚Äôs important to pre-process your text. Using lemmatized words helps avoid counting variations like ‚Äúrun‚Äù and ‚Äúrunning‚Äù separately, and removing stop words‚Äîcommon words such as ‚Äúthe‚Äù or ‚Äúand‚Äù‚Äîallows you to focus on terms that carry more meaning. In cases where participants mention names of places or projects repeatedly, custom stop word lists can also help refine the results.\nWhile word frequency counts themselves do not explain context or meaning, they can help point to emerging themes by highlighting concepts that recur across participants or within particular sections of discussion. For example, if words like ‚Äútransportation,‚Äù ‚Äúaccess,‚Äù and ‚Äúbarrier‚Äù frequently appear in responses about service challenges, they signal a potential theme that warrants deeper exploration. Word frequency analysis can also help guide more interpretive methods such as thematic or content analysis, and is most useful when findings are contextualized within the broader dataset and research goals.\n\n# %%%%%%%%%%%%%%% Word frequencies %%%%%%%%%%%%%%%\n# Word counts\nword_counts &lt;- lemmatized_text %&gt;%\n  count(word, sort = TRUE)\n\nhead(word_counts)\n\n# A tibble: 6 √ó 2\n  word             n\n  &lt;chr&gt;        &lt;int&gt;\n1 time             4\n2 people           3\n3 access           2\n4 application      2\n5 applications     2\n6 process          2\n\n# Visualize the word counts\n\nword_counts %&gt;%\n  top_n(5) %&gt;%\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Top 10 Most Frequent Words\", x = \"Word\", y = \"Count\") +\n  theme_omni(plot_background_color = \"White\")"
  },
  {
    "objectID": "analysis_plan.html#sentiment-analysis",
    "href": "analysis_plan.html#sentiment-analysis",
    "title": "Analysis Plan",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\nSentiment analysis is a method that measures the emotional tone of text by categorizing words or phrases as positive, negative, or neutral. It can be used to quickly gauge participants‚Äô attitudes toward a topic or to assess the overall tone of responses across interviews, focus groups, or surveys. Sentiment analysis works best when you have larger amounts of text (ideally, datasets with several hundred words or more) because emotional tone can vary within short responses, making sentiment harder to interpret in very small datasets. However, it can still offer insights in smaller datasets when applied carefully and when results are presented as exploratory.\nBest practices for sentiment analysis include pre-processing your text by removing stop words and standardizing language through lemmatization. This ensures consistent scoring and avoids misclassifications due to word variations. Sentiment analysis typically relies on pre-built lexicons (vocabularies), such as Bing, AFINN, or the NRC Emotion Lexicon, which assign emotional values to words. It‚Äôs important to note that these lexicons were often designed for general use (such as social media text) and may require customization to fit specific public health or social science contexts. For example, in health-related interviews, a word like ‚Äútreatment‚Äù might appear frequently and carry different sentiment depending on the discussion‚Äôs focus.\nWhile sentiment analysis doesn‚Äôt capture nuance or context in the way manual coding can, it can highlight patterns of emotional tone across datasets or within specific discussion topics. For example, sentiment analysis might reveal that participants express more negative sentiment when discussing barriers to accessing services, and more positive sentiment when discussing recommendations for future improvements. These insights can help guide deeper qualitative coding or serve as an additional layer of analysis to support findings. As with any automated method, it‚Äôs important to review and interpret results in context and to document any limitations or adaptations made to the analysis.\n\nlibrary(tidytext)\n\n# Get sentiment lexicon (if you wanted to test for positive, negative, and 8 emotions, replace \"bing\" with \"nrc\")\nbing &lt;- get_sentiments(\"bing\")\n\n# Join with your text\nsentiment_data &lt;- lemmatized_text %&gt;%\n  inner_join(bing, by = \"word\")\n\n# Count positive vs negative\nsentiment_summary &lt;- sentiment_data %&gt;%\n  count(sentiment)\n\nsentiment_summary\n\n# A tibble: 2 √ó 2\n  sentiment     n\n  &lt;chr&gt;     &lt;int&gt;\n1 negative      5\n2 positive      3\n\n# Visualize\nsentiment_summary %&gt;%\n  ggplot(aes(x = sentiment, y = n, fill = sentiment)) +\n  geom_col() +\n  labs(title = \"Sentiment Analysis\", x = \"Sentiment\", y = \"Word Count\") +\n  scale_fill_omni_discrete() +\n  theme_omni(plot_background_color = \"White\")\n\n\n\n\n\n\n\n\nHere is another example of how a sentiment analysis can be vizzed. The figure below is grouped by listening session and the portion of discussion in each listening session. The dark blues represent a more negative sentiment and the tan represents a more positive sentiment. We can see that Community Based Organizations had very positive sentiment when discussing treatment and recovery in their sessions, and negative sentiment about community impact. These polarizing sentiment results may cause us to look further in the CBO transcripts to see what people were positive and negative about in the respective discussions.\n\nTip for finding quotes by tone\nLet‚Äôs say you want to pull a quote to include in a report and you know that you want it to be a positively toned quote in a ‚Äúrecommendations‚Äù section of your discussion. You can use the sentimentr package to gather sentiments of each sentence (or segment) and sort by sentiment score to find the quote with the most positive tone in your criteria.\nSee an example below:\n\nlibrary(sentimentr)\n\ntext_data_wsentiment &lt;- sentiment(text_data$text)\n\nsentiment_summary &lt;- text_data_wsentiment %&gt;%\n  group_by(element_id) %&gt;%\n  summarize(\n    avg_sentiment = mean(sentiment, na.rm = TRUE),\n    sd_sentiment = sd(sentiment, na.rm = TRUE),\n    n_sentences = n()\n  )\n\n# Combine summarized sentiment scores with your original data\ntext_data_with_sentiment &lt;- text_data %&gt;%\n  mutate(element_id = row_number()) %&gt;%\n  left_join(sentiment_summary, by = \"element_id\")\n\n# View the combined data\ntext_data_with_sentiment\n\n# A tibble: 7 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n7    10 participant P1                    0       3 Recommendatio‚Ä¶ prov‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: element_id &lt;int&gt;, avg_sentiment &lt;dbl&gt;,\n#   sd_sentiment &lt;dbl&gt;, n_sentences &lt;int&gt;\n\n\nMixed-methods with sentiment analysis\nBecause sentiment analysis gives you a numeric output as a sentiment score, you can imagine instances where you may want to compare sentiment scores between groups, correlate sentiment scores with other variables in a quantitative survey, or conduct pre-post comparisons."
  },
  {
    "objectID": "analysis_plan.html#topic-modeling",
    "href": "analysis_plan.html#topic-modeling",
    "title": "Analysis Plan",
    "section": "Topic modeling",
    "text": "Topic modeling\nTopic modeling is an automated method used to identify themes or topics across large collections of text. It uses algorithms to group together words that frequently appear in similar contexts, helping reveal hidden patterns or structures in qualitative data. Topic modeling is especially useful when you have large datasets‚Äîtypically a minimum of 5,000 words or more spread across multiple documents or participant responses. The method works best when documents are of relatively similar length, which helps the model assign topics more evenly.\nThis method is not recommended for use on smaller datasets and would be considered poor practice to rely on it to generate meaningful insights. If you don‚Äôt have enough data for this analysis, consider using the content analysis strategy to identify themes in the data.\nBefore running a topic model, it‚Äôs important to pre-process your text. Best practices include stemming words to reduce variation (so that ‚Äúrun‚Äù and ‚Äúrunning‚Äù are treated as the same word) and removing stop words to focus on meaningful content. Topic modeling doesn‚Äôt require predefined codes or themes, making it a good exploratory tool for surfacing unexpected topics in your data. However, it‚Äôs important to remember that these topics are generated algorithmically‚Äîthey group terms based on statistical patterns, not human interpretation. As a result, human review is always needed to interpret and label the topics in a way that makes sense for your project and participants.\nTopic modeling can complement manual coding by offering a high-level view of common themes, pointing analysts toward areas that may warrant deeper exploration. For example, a topic model might surface clusters of words related to barriers (‚Äútransportation,‚Äù ‚Äúaccess,‚Äù ‚Äúcost‚Äù) and another cluster about solutions (‚Äúeducation,‚Äù ‚Äúoutreach,‚Äù ‚Äúsupport‚Äù), giving you a starting point for thematic analysis. Commonly used R packages for topic modeling include topicmodels, which provides algorithms like Latent Dirichlet Allocation (LDA), and tm for pre-processing and managing textual data.\n\nlibrary(tm)\nlibrary(topicmodels)\n\n# Create Document-Term Matrix (DTM)\ndtm &lt;- stemmed_text %&gt;%\n  count(document = 1, word) %&gt;%\n  cast_dtm(document, word, n)\n\n# Fit LDA models with 2 and 3 topics\nlda_model_2 &lt;- LDA(dtm, k = 2, control = list(seed = 1234))\nlda_model_3 &lt;- LDA(dtm, k = 3, control = list(seed = 1234))\n\n# Compare perplexity (lower is better)\nperplexity_2 &lt;- perplexity(lda_model_2)\nperplexity_3 &lt;- perplexity(lda_model_3)\n\n# Print perplexity values to see how many topics we should go with- in this case 2 topics perform better than 3\nperplexity_2\n\n[1] 46.1033\n\nperplexity_3\n\n[1] 46.13593\n\n# View top terms for both models\ntopics_2 &lt;- tidy(lda_model_2, matrix = \"beta\")\ntopics_3 &lt;- tidy(lda_model_3, matrix = \"beta\")\n\n# Top terms for 2-topic model\ntop_terms_2 &lt;- topics_2 %&gt;%\n  group_by(topic) %&gt;%\n  top_n(10, beta) %&gt;%\n  arrange(topic, -beta)\n\n# Top terms for 3-topic model\ntop_terms_3 &lt;- topics_3 %&gt;%\n  group_by(topic) %&gt;%\n  top_n(10, beta) %&gt;%\n  arrange(topic, -beta)\n\n# Display the top terms to compare interpretability\ntop_terms_2\n\n# A tibble: 20 √ó 3\n# Groups:   topic [2]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0617\n 2     1 transportation 0.0544\n 3     1 services       0.0467\n 4     1 residents      0.0313\n 5     1 challenges     0.0297\n 6     1 agree          0.0281\n 7     1 lot            0.0278\n 8     1 access         0.0276\n 9     1 applications   0.0275\n10     1 application    0.0274\n11     2 people         0.0800\n12     2 time           0.0695\n13     2 process        0.0485\n14     2 application    0.0381\n15     2 applications   0.0381\n16     2 access         0.0380\n17     2 timeconsuming  0.0264\n18     2 campaigns      0.0260\n19     2 buses          0.0254\n20     2 simplifying    0.0253\n\ntop_terms_3\n\n# A tibble: 30 √ó 3\n# Groups:   topic [3]\n   topic term             beta\n   &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1     1 time           0.0778\n 2     1 transportation 0.0543\n 3     1 services       0.0542\n 4     1 lot            0.0390\n 5     1 residents      0.0353\n 6     1 applications   0.0347\n 7     1 access         0.0312\n 8     1 vouchers       0.0261\n 9     1 makes          0.0256\n10     1 planning       0.0249\n# ‚Ñπ 20 more rows"
  },
  {
    "objectID": "analysis_plan.html#content-analysis",
    "href": "analysis_plan.html#content-analysis",
    "title": "Analysis Plan",
    "section": "Content analysis",
    "text": "Content analysis\nContent analysis is a method used to count how often predefined concepts, themes, or categories appear in qualitative data. It relies on a dictionary‚Äîa list of key terms or phrases‚Äîdesigned to reflect your evaluation questions or coding framework. Content analysis works well for both small and large datasets, making it a flexible tool when you want to systematically measure the presence of specific themes across interviews, focus groups, or open-ended survey responses.\nA key requirement for effective content analysis is a carefully designed dictionary that accurately captures the concepts you‚Äôre interested in. This might include terms related to barriers, facilitators, or recommendations, depending on the project‚Äôs goals. Best practice is to validate the dictionary by reviewing examples of matched text to make sure the terms are identifying the intended content. You may need to refine the dictionary over time, adding synonyms or removing words that generate false positives.\nContent analysis can help answer questions like ‚ÄúHow frequently do participants mention prevention strategies?‚Äù or ‚ÄúWhat percentage of responses reference funding challenges?‚Äù It is particularly useful when you need to quantify qualitative data for reporting purposes, or when you want to compare how frequently themes appear across different stakeholder groups. In R, the quanteda package offers efficient tools for dictionary-based content analysis, allowing you to apply a dictionary and quickly summarize how often key terms or concepts appear in the dataset.\n\n\nDocument-feature matrix of: 7 documents, 109 features (81.26% sparse) and 0 docvars.\n       features\ndocs    sure i think one of the biggest challenges is transportation\n  text1    1 1     1   1  5   2       1          1  1              1\n  text2    0 1     0   0  0   0       0          0  0              0\n  text3    0 0     0   0  1   0       0          0  0              0\n  text4    0 0     0   0  0   4       0          0  1              0\n  text5    0 0     0   0  0   0       0          0  0              0\n  text6    0 0     0   0  0   1       0          0  0              0\n[ reached max_ndoc ... 1 more document, reached max_nfeat ... 99 more features ]\n\n\nDocument-feature matrix of: 7 documents, 3 features (85.71% sparse) and 0 docvars.\n       features\ndocs    prevention treatment harm_reduction\n  text1          0         1              0\n  text2          0         0              0\n  text3          1         0              0\n  text4          0         0              0\n  text5          2         0              0\n  text6          0         0              0\n[ reached max_ndoc ... 1 more document ]\n\n\n[1] \"text1\" \"text2\" \"text3\" \"text4\" \"text5\" \"text6\"\n\n\n# A tibble: 6 √ó 12\n   line speaker     participant_id question section section_label  text  session\n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;  \n1     2 participant P1                    0       1 Introduction   sure‚Ä¶ Educat‚Ä¶\n2     3 participant P2                    0       1 Introduction   i ag‚Ä¶ Educat‚Ä¶\n3     5 participant P1                    0       2 Barriers       trav‚Ä¶ Educat‚Ä¶\n4     6 participant P2                    0       2 Barriers       also‚Ä¶ Public‚Ä¶\n5     8 participant P1                    0       3 Recommendatio‚Ä¶ more‚Ä¶ Public‚Ä¶\n6     9 participant P2                    0       3 Recommendatio‚Ä¶ simp‚Ä¶ Public‚Ä¶\n# ‚Ñπ 4 more variables: doc_id &lt;chr&gt;, prevention &lt;dbl&gt;, treatment &lt;dbl&gt;,\n#   harm_reduction &lt;dbl&gt;"
  },
  {
    "objectID": "analysis_plan.html#thematic-analysis-in-dedoose",
    "href": "analysis_plan.html#thematic-analysis-in-dedoose",
    "title": "Analysis Plan",
    "section": "Thematic Analysis in Dedoose",
    "text": "Thematic Analysis in Dedoose\nIf using Dedoose to conduct thematic analysis, we recommend a structured, reflective approach grounded in reflexive thematic analysis (Clarke & Braun, 2006) and informed by critical realism.\nHere‚Äôs how to approach it:\n\nStart by familiarizing yourself with the data by doing a full read through of transcripts or responses before beginning coding. Review notes taken during the interview/focus group during this time.\n\n\nUse memos to reflect on initial impressions, patterns, and researcher assumptions.\n\n\nDetermine whether the analysis should use an inductive or deductive apporach\n\n\nIn an inductive approach, the researcher reads through the data and generates codes as they go. These codes are often grounded in a mix of participant realities and researcher interpretations. Note: If an inductive approach is determined, then the codebook should be generated and iterated upon after the first round of coding (see below).\nIn a deductive approach, the researcher predefines a coding structure and reads through the data applying codes to excerpts. These codes more often heavily rely on the research questions and decisions made by the research team/clients. Note: If a deductive approach is determined, then a codebook should be generated prior to the start of analysis.\nDetermining an inductive versus deductive approach should be communicated with the project lead. The Qual BPT is available to consult on this decision.\n\n\nConduct your first round of coding applying codes broadly, with the intent to synthesize and further detail codes on the second round of coding.\n\n\nThe first round of coding will generally create a lot of new codes (if taking an inductive approach). This is expected and completely normal as codes will be synthesized into broader categories later on.\nAlways use a parent code/child code structure to increase transparency and accuracy in your coding. Parent codes are the broader subject, while child codes are granular topics that make up that topic.\n\nFor example:\n\nProgrammatic Challenges (Parent Code)\nSmall budgets (child code)\nLimited staff (child code)\nFunding cuts (child code)\n\n\nParent codes and child codes should be explicitly referenced in your codebook\nEvery code, both parent code and child code, should have an attached definition so that others who revisit your codes know exactly what that code means\n\n\nConduct your second round of coding applying codes on a more limited basis and collapsing code categories into an organized structure, redefining codes as needed\n\n\nIn your second round of coding it is common to find that some of your initial codes overlap. In cases where the information is contextually the same, you should collapse these codes for clarity and redefine the final code if needed.\n\nFor example, transportation issues + lack of reliable transportation = transportation challenges\n\nAny updates to your codes should be reflected in your codebook\n\n\nConstruct themes thoughtfully after coding, reviewing excerpts by code and grouping them into broader themes that reflect patterns across participants\n\n\nIf you have followed a clear parent code/child code structure, then your themes will likely stem from those. Typically, our research/evaluation questions guide the development of our themes.\n\nFor example,\n\nEvaluation question = What challenges did sub-awardees face over the course of the funding cycle?\nTheme 1: Limited Capacity for Organizational Growth\n\nCode 1: Limited funding\nCode 2: Limited staff\nCode 3: Budget cuts\n\n\n\nDedoose‚Äôs Code Co-Occurrence and Code Application tools can assist you in identifying themes that stem from patterns between codes\n\n\nAcknowledge the researcher‚Äôs role and reflect on how your perspective, language, and interpretation influenced coding and theme development\n\n\nBe cautious not to overstate findings. Instead, describe patterns and nuances across participant groups, rather than presenting your findings as a consensus across the group.\nRecognize outliers. Some participants may have had a vastly different experience from other participants. Determine whether these experiences should be reported under another theme or in a standalone section.\n\n\nDocument everything and keep a record of how codes and themes evolved\n\n\nOmni‚Äôs Qualitative Fundamental Standards foster transparency in the way that we do our qualitative work. Always keep a copy of the raw transcripts (pre-cleaning) to ensure that the raw data is maintained. Additionally, ensure that you are communicating your coding decisions with your team and ask another team member, or a member of the Qual BPT to review your coding, codes, code structures, codebook, and themes.\nClearly state the number of participants or excerpts that informed each theme.\nMake your interpretive lens and limitations explicit - especially when datasets are small or uneven across groups\n\nThematic analysis in Dedoose should still reflect Omni‚Äôs commitment to critical realism: treat participant input as reflecting real issues shaped by context and perspective, and be transparent about what the data can‚Äîand cannot‚Äîsupport."
  },
  {
    "objectID": "analysis_plan.html#combining-analyses",
    "href": "analysis_plan.html#combining-analyses",
    "title": "Analysis Plan",
    "section": "Combining analyses",
    "text": "Combining analyses\nNo single method can fully capture the richness and complexity of qualitative data. At Omni, we often combine different qualitative analysis approaches to explore various angles of our data and answer nuanced evaluation questions. Pairing methods like word frequency, sentiment analysis, content analysis, and thematic analysis can help reveal both patterns and meaning, ensuring our findings are grounded in evidence and provide actionable insights."
  },
  {
    "objectID": "analysis_plan.html#what-this-page-covers",
    "href": "analysis_plan.html#what-this-page-covers",
    "title": "Analysis Plan",
    "section": "What this page covers:",
    "text": "What this page covers:\nSelecting the right analysis depends on:\n\nHow much data you have\nYour research question(s)\nWhether you need exploratory insights or answers to specific questions\nYour integrative framework (if conducting mixed-methods)"
  },
  {
    "objectID": "analysis_plan.html#understanding-your-data-before-analysis",
    "href": "analysis_plan.html#understanding-your-data-before-analysis",
    "title": "Analysis Plan",
    "section": "Understanding Your Data Before Analysis",
    "text": "Understanding Your Data Before Analysis\nBefore starting pre-processing or analysis, it‚Äôs important to assess the scope and quality of your data. Take time to understand:\n\nHow many participants are included?\nHow much text do you have (word count, number of responses)?\nHow detailed are the responses (in-depth vs.¬†brief)?\nHow are participants grouped (by stakeholder type, session, etc.)?\nWhose voices are most important to elevate in this analysis?\n\nThis step ensures you choose methods that fit your dataset and align with your project goals. For example:\n\nSmaller datasets (under ~2,000 words) are well-suited to word frequency, sentiment analysis, or basic content analysis.\nLarger datasets (5,000+ words) can support topic modeling or advanced thematic analysis. You can also conduct word frequency, sentiment analysis, or basic content analysis.\n\nAssessing your data upfront helps set realistic expectations for analysis and ensures your findings are grounded, transparent, and defensible."
  },
  {
    "objectID": "analysis_plan.html#working-with-a-small-dataset",
    "href": "analysis_plan.html#working-with-a-small-dataset",
    "title": "Analysis Plan",
    "section": "Working with a Small Dataset",
    "text": "Working with a Small Dataset\nAt Omni, qualitative research often happens in real-world settings, with tight timelines and limited participant availability. We may aim for 10 interviews and complete 5. We may expect long, detailed conversations and instead get brief answers. Even with these constraints, small datasets can still provide meaningful insights, especially when there is consistency across participant experiences.\nWhen working with limited data:\n\nFocus on what participants actually shared, rather than attempting to generalize.\nDocument patterns and recurring concerns, while linking them clearly to the project‚Äôs research questions.\nBe transparent about the number of participants, the methods used, and any limitations in interpretation.\n\nSmaller samples can still highlight critical issues‚Äîsuch as barriers to access or common recommendations for program improvement‚Äîbut the scope and representativeness of these findings should be clearly communicated."
  },
  {
    "objectID": "analysis_plan.html#suggested-methods-by-dataset-size-and-purpose",
    "href": "analysis_plan.html#suggested-methods-by-dataset-size-and-purpose",
    "title": "Analysis Plan",
    "section": "Suggested Methods by Dataset Size and Purpose",
    "text": "Suggested Methods by Dataset Size and Purpose\n\n\n\n\n\n\n\nNote: If you are working with open-ended responses from a survey and have data from 30 or fewer participants, carefully consider whether the data are sufficient for meaningful analysis. In many cases, it is appropriate to report that there were too few responses to analyze systematically. However, if you need to report findings, be transparent about limitations. Focus on describing frequently mentioned key words, rather than inferring broader themes. Avoid suggesting consensus when data are limited, and clearly state that findings reflect input from a small number of participants Transparent reporting maintains the credibility of your analysis.\n\nGrouping Voices to Guide Analysis\nBefore you start coding or analyzing, decide:\n\nWhose voices are we centering in this analysis?\nHow will we group participant responses?\n\nYour grouping choices influence:\n\nWhich perspectives are highlighted\nHow themes emerge\nWhat questions you can answer\n\nAt Omni, we might group data by:\n\nParticipant (individual experiences)\nVested Partner Group (e.g., educators vs.¬†public health professionals)\nDiscussion Section (e.g., barriers vs.¬†recommendations)\n\nThese decisions should align with the project‚Äôs goals and be clearly documented in reports and presentations."
  },
  {
    "objectID": "approach.html#introduction",
    "href": "approach.html#introduction",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "Introduction",
    "text": "Introduction\nAt Omni, we conduct qualitative research in complex, real-world environments. Our clients and projects often require fast timelines, nuanced insights, and transparent methods that can stand up to external review. To meet these needs, we use systematic, reproducible qualitative analysis methods grounded in pragmatism and critical realism.\nThis approach ensures our findings are actionable and reflect the realities and lived experiences of participants, while acknowledging the influence of context, interpretation, and limitations in our data.\n\nPurpose\nThis guide was developed to support Omni staff in conducting methodologically sound, transparent, and reproducible qualitative analyses. It offers practical, step-by-step instructions and highlights best practices for text pre-processing, analysis, and reporting. Whether working with interview transcripts, focus groups, open-ended survey responses, or other text-based data, Omni teams can use this guide to produce findings that are both grounded in participants‚Äô voices and useful for program improvement and decision-making.\n\n\nHow do our qualitative resources align with Omni‚Äôs core values?\nInquiry: Provides clear, rigorous methods that encourage thoughtful exploration of participants‚Äô experiences.\nAgility: Equips staff with adaptable tools to meet diverse project needs and respond efficiently to change.\nConnection: Centers participants‚Äô voices and strengthens relationships with the communities and partners we serve.\nAccountability: Uses transparent, reproducible analysis practices to keep our work credible, ethical, and trustworthy.\nIn many applied settings, qualitative methods (and especially mixed-methods) are described in vague terms. Reports may mention ‚Äúthemes emerging‚Äù or ‚Äútriangulating findings,‚Äù but rarely explain the actual process used to get there. This vagueness makes it hard to replicate or assess qualitative findings and limits their credibility."
  },
  {
    "objectID": "approach.html#why-are-existing-descriptions-of-methods-so-vague",
    "href": "approach.html#why-are-existing-descriptions-of-methods-so-vague",
    "title": "Omni‚Äôs Approach to Qualitative Analysis",
    "section": "Why Are Existing Descriptions of Methods So Vague?",
    "text": "Why Are Existing Descriptions of Methods So Vague?\nAt Omni, we aim to avoid vague or ad hoc practices. We document clear, systematic workflows that integrate qualitative insights with quantitative data when appropriate.\nSeveral factors explain the common lack of clarity in methodology:\n\nDifferent disciplines (e.g., public health vs.¬†education research) use different frameworks, leading to inconsistent approaches.\nQuantitative research has standard tools (R, SPSS, Stata), but qualitative tools (NVivo, MAXQDA, Dedoose) often rely on manual processes and don‚Äôt always integrate cleanly with quantitative workflows.\nQualitative analysis requires human interpretation and reflexivity. Documenting every step is time-consuming, and under tight timelines, many organizations skip this critical process.\nQualitative and quantitative teams often work separately, without shared standards or mixed-methods integration."
  },
  {
    "objectID": "data_prep.html#what-this-guide-covers",
    "href": "data_prep.html#what-this-guide-covers",
    "title": "Data Cleaning",
    "section": "What This Guide Covers",
    "text": "What This Guide Covers\nYou‚Äôll find guidance on:\n\nText mining / Natural Language Processing (NLP)\n(e.g., word frequency, sentiment analysis, topic modeling)\nThematic and content analysis\n(e.g., dictionary-based coding, thematic coding frameworks)\nNarrative analysis @qualBPT do we need?\n(Optional: e.g., structural analysis, language style matching)\nVisualizing and reporting qualitative data\n(e.g., word clouds, bar charts, heatmaps, joint displays for mixed-methods)\n\nThese methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more."
  },
  {
    "objectID": "data_prep.html#what-this-page-covers",
    "href": "data_prep.html#what-this-page-covers",
    "title": "Data Cleaning",
    "section": "",
    "text": "You‚Äôll find guidance on:\n\nPrinciples and purpose of qualitative data cleaning\nDefining ‚Äúclean‚Äù and ‚Äúanalysis-ready‚Äù data at Omni\nStep-by-step cleaning procedures in R\nReporting and documentation standards\n\nThese data cleaning methods can be applied to text from: Word documents (.docx), PDFs (.pdf), Zoom transcripts (.docx or .txt), open-ended survey responses (.xlsx or .csv), and more."
  },
  {
    "objectID": "analysis_plan.html#draft-your-analysis-plan",
    "href": "analysis_plan.html#draft-your-analysis-plan",
    "title": "Analysis Plan",
    "section": "Draft Your Analysis Plan",
    "text": "Draft Your Analysis Plan\nTwo especially helpful documents to have before qualitative data collection and cleaning begins are:\n\nA codebook (or at least a data dictionary). This helps ensure consistency in how we treat things like speaker names, special terminology, or sensitive content.\nA data analysis plan. This outlines the team‚Äôs approach to coding and analysis and helps identify if additional cleaning steps are necessary. For example: anonymizing sensitive details or removing artifacts from automated transcription tools (timestamps, filler words, etc.). This step should happen before data collection begins, but may be slightly adjusted given the quality and count of data received after data collection finishes.\n\nWhenever possible, we expect teams to develop a data analysis plan and request any available data dictionaries or codebooks from the client or partner organizations who collected the data. However, you may need to create a codebook if one doesn‚Äôt exist‚Äîfeel free to reach out to the QualBPT (or whichever team you want to point folks to) if you need support.\nIn many cases, the people drafting the analysis plan are different from those cleaning the qualitative data, so strong cross-team communication is essential. We recommend including the qualitative data cleaner (or cleaning team) in project discussions as early as possible. When drafting the analysis plan, think through what text cleaning steps will be necessary to make the data usable for coding, protect participant confidentiality, and meet the project‚Äôs goals."
  },
  {
    "objectID": "data_prep.html#when-are-my-data-clean",
    "href": "data_prep.html#when-are-my-data-clean",
    "title": "Data Cleaning",
    "section": "When are my data clean?",
    "text": "When are my data clean?\nFor there to be project tasks that direct Omni-ites to ‚Äòclean qualitative data,‚Äô and a guide to help in doing so, there should also be a shared understanding of what it means for qualitative data to be clean.\nAt Omni, qualitative data are considered clean when they are organized, de-identified, and ready for analysis or coding.\nThat means the data:\n\nAccurately reflect the original source material (e.g., interviews, focus groups, or open-text survey responses)\nHave been transformed into a structure that makes them easy to navigate and analyze\nProtect the privacy and confidentiality of participants\nAre consistent, clear, and free of irrelevant clutter (like transcription artifacts)\n\n\nWhat Makes a Qualitative Dataset ‚ÄúAnalysis-Ready‚Äù?\nFor qualitative text data to be ready for analysis, they should meet the following criteria:\n\nSpeaker Information Is Clear and Consistent\n\n\nParticipant speakers and interviewers are clearly labeled in the data.\nEach speaker‚Äôs text is grouped logically into segments, preserving conversational flow.\n\n\nParticipant Identifiers Are Specified and Protected\n\n\nReal names, locations, and other direct identifiers have been removed or replaced with participant IDs or pseudonyms.\nConfidential information (e.g., agency names, job titles, organizations) is anonymized where necessary, following Omni‚Äôs confidentiality guidelines.\n\n\nQuestions Are Clearly Distinguished From Responses\n\n\nInterviewer questions (or prompts) are labeled or separated from participant responses, as appropriate. This can be done by adding question text as its own field in the dataset or by adding markers in the transcript.\n\n\nText Segments Are Ordered and Organized\n\n\nThe transcript text is ordered according to the flow of conversation. Segments are correctly time-sequenced (even if timestamps themselves are removed).\n\n\nText Is Structured Into a Tidy, Rectangular Format\n\n\nEach row represents a single speaker turn or unit of analysis (e.g., a complete response to a question).\nData are stored in a rectangular table (data frame), with columns for:\n\nSession name or group (e.g., ‚ÄúEducators‚Äù or ‚ÄúPublic Health‚Äù)\nParticipant ID or role (e.g., ‚ÄúParticipant 1‚Äù, ‚ÄúFacilitator‚Äù)\nText segment (the response or comment)\nAny relevant metadata (e.g., discussion section, date)\nTranscription\n\n\n\nArtifacts Are Removed\n\n\nAll timestamps (e.g., [00:05:23], (0:12:45)) are deleted unless specifically required for analysis.\nAutomated transcription quirks (e.g., repeated words, filler words, auto-captions like ‚Äú[inaudible]‚Äù) are reviewed, cleaned, or flagged.\n\n\nText Is Consistent in Style and Format\n\n\nAll text is converted to lowercase, unless case is important for analysis.\nSpelling errors are corrected when they obscure meaning (but regional spellings or participant quirks may be preserved if relevant).\nPunctuation and spacing are standardized (no excessive whitespace, missing periods, etc.).\n\n\nRelevant Identifiers Are Added to the Dataset\n\n\nIf there are multiple sessions or groups, these are labeled (e.g., ‚ÄúEducators,‚Äù ‚ÄúPublic Health‚Äù).\nIf there are themes or discussion sections (e.g., ‚ÄúChallenges,‚Äù ‚ÄúRecommendations‚Äù), these are identified.\nIf codes are pre-assigned for analytic purposes (e.g., ‚ÄúPre-implementation,‚Äù ‚ÄúPost-implementation‚Äù), they are included in the data structure.\n\n\n\nHow Do We Know When Qualitative Data Are Clean\nHere are some guiding questions to help determine when qualitative data are ready for analysis (i.e., clean):\n\nWhat is the plan for coding or analyzing this data?\nThe analysis plan (or coding framework) should inform cleaning decisions. For example, if the team plans to do thematic coding, they‚Äôll need text organized into meaningful speaker turns or responses. What needs to be anonymized?\nIdentify any sensitive information that must be redacted or replaced to maintain confidentiality and ensure participant privacy. Are speaker turns properly attributed and easy to follow?\nEach speaker‚Äôs contributions should be clearly labeled, consistently formatted, and grouped logically. Are responses to specific questions clearly identifiable?\nIf interviews or focus groups follow a semi-structured guide, it‚Äôs important to separate questions from responses for clarity in analysis. Is the structure of the data appropriate for the analytic tool?\nIf the data are being uploaded to Dedoose, NVivo, or another platform, they should follow the required format (e.g., tidy data frame with speaker IDs and group names). Have all unnecessary artifacts been removed?\nTime stamps, filler words, and transcription errors that don‚Äôt add value to the analysis should be removed. Has the cleaned data been reviewed by someone else (QA check)?\nWhenever possible, have another Omni-ite review the cleaned data for accuracy and completeness.\n\n\n\nCommon Issues to Discuss Early in the Cleaning Process\nJust like in quantitative data cleaning, clarifying expectations at the start of a project will save time later. For qualitative projects, consider these:\n\nWill we analyze both facilitator questions and participant responses, or just participant responses?\nHow will we handle overlapping speech, interruptions, or incomplete thoughts?\nDo we need to standardize participant roles (e.g., ‚ÄúPublic Health Official‚Äù vs.¬†‚ÄúPH Staff‚Äù) for consistency?\nAre we preparing data for manual coding or automated text analysis?\nDo we need to translate or transcribe non-English responses?\nDo we need to connect text segments with broader context, such as the discussion theme or section of the focus group?\n\nQuick summary of ‚Äúclean qualitative data‚Äù at Omni:\n\nAnonymized\nClearly structured and labeled\nOrganized for easy analysis\nFree of unnecessary artifacts\nReady for use in coding and interpretation"
  },
  {
    "objectID": "data_prep.html#cleaning-transcripts",
    "href": "data_prep.html#cleaning-transcripts",
    "title": "Data Cleaning",
    "section": "Cleaning transcripts",
    "text": "Cleaning transcripts\nOne of the main forms of qualitative data we receive includes online transcripts. Below is a function you can use to clean your Zoom/Otter.ai transcripts and get them to a tidy format by entering the interviewer name(s), and key phrases used by the interviewer to mark the section of the discussion. For example, an interview might begin with an introduction, then include a discussion of barriers, and a discussion of strengths. We‚Äôll likely want to separate these out into sections so our analyses can speak to each section independent of each other, rather than be clumped altogether.\nThis function works for Zoom transcripts that are saved as Word documents or .txt files. There are few things you need to specify in the function, including updating the file path, the interviewers, setting your list of questions, adding section labels, and the session name.\n\n# youll need these libraries for this function:\nlibrary(tidyverse)\nlibrary(officer)\nlibrary(stringr)\n\n# function to clean transcripts\nclean_transcripts &lt;- function(file_path,\n                              file_type = c(\".docx\", \".txt\"),\n                              interviewers,\n                              session_name) {\n\n  file_type &lt;- match.arg(file_type)\n\n  # ================================\n  # ‚úÖ 1. Load transcript\n  # ================================\n  if (file_type == \".docx\") {\n    doc &lt;- read_docx(file_path)\n    text_data &lt;- docx_summary(doc)\n    df &lt;- text_data %&gt;%\n      dplyr::select(line = doc_index, text)\n  } else if (file_type == \".txt\") {\n    text_lines &lt;- readLines(file_path, encoding = \"UTF-8\")\n    df &lt;- tibble(line = seq_along(text_lines), text = text_lines)\n  } else {\n    stop(\"Unsupported file type. Use '.docx' or '.txt'\")\n  }\n\n  # ================================\n  # ‚úÖ 2. Classify speakers\n  # ================================\n  df &lt;- df %&gt;%\n    mutate(\n      speaker = case_when(\n        str_detect(text, str_c(interviewers, collapse = \"|\")) ~ \"interviewer\",\n        TRUE ~ \"participant\"\n      )\n    ) %&gt;%\n    filter(\n      text != \"\",\n      !str_detect(text, \"^\\\\d+$\"),\n      !str_detect(text, \"--&gt;\")\n    )\n\n  # ================================\n  # ‚úÖ 3. Extract and assign participant IDs\n  # ================================\n  unique_participants &lt;- df %&gt;%\n    filter(speaker == \"participant\" & str_detect(text, \":\")) %&gt;%\n    mutate(participant_name = str_extract(text, \"^[^:]+\")) %&gt;%\n    distinct(participant_name) %&gt;%\n    drop_na() %&gt;%\n    mutate(participant_id = paste0(\"P\", row_number()))\n\n  df &lt;- df %&gt;%\n    mutate(\n      participant_name = if_else(\n        speaker == \"participant\" & str_detect(text, \":\"),\n        str_extract(text, \"^[^:]+\"),\n        NA_character_\n      )\n    ) %&gt;%\n    left_join(unique_participants, by = \"participant_name\") %&gt;%\n    select(-participant_name)\n\n  # ================================\n  # ‚úÖ 4. Detect section markers and extract section labels\n  # ================================\n  df &lt;- df %&gt;%\n    mutate(\n      question = if_else(str_detect(text, \"\\\\[.*\\\\]\"), 1L, 0L),\n      section_label_raw = if_else(\n        question == 1L,\n        str_extract(text, \"\\\\[(.*?)\\\\]\"),\n        NA_character_\n      )\n    ) %&gt;%\n    mutate(\n      section_label_clean = str_remove_all(section_label_raw, \"\\\\[|\\\\]\")\n    )\n\n  # ================================\n  # ‚úÖ 5. Remove text before the first question\n  # ================================\n  first_question_line &lt;- min(df$line[df$question == 1], na.rm = TRUE)\n\n  if (!is.finite(first_question_line)) {\n    stop(\"‚ùå No questions (section markers) detected in brackets!\")\n  }\n\n  df &lt;- df %&gt;%\n    filter(line &gt;= first_question_line)\n\n  # ================================\n  # ‚úÖ 6. Fill forward the section labels\n  # ================================\n  df &lt;- df %&gt;%\n    arrange(line) %&gt;%\n    tidyr::fill(section_label_clean, .direction = \"down\") %&gt;%\n    mutate(\n      section = as.numeric(factor(section_label_clean))\n    )\n\n  # ================================\n  # ‚úÖ 7. Create original_text (remove speaker name only)\n  # ================================\n  df &lt;- df %&gt;%\n    mutate(\n      original_text = str_remove(text, \".*?:\\\\s*\")  # Remove everything before the colon\n    )\n\n  # ================================\n  # ‚úÖ 8. Clean the `text` column for analysis\n  # ================================\n  df &lt;- df %&gt;%\n    mutate(\n      text = iconv(original_text, from = \"UTF-8\", to = \"ASCII//TRANSLIT\"),\n      text = tolower(text),\n      text = str_replace_all(text, \"[^a-zA-Z0-9\\\\s]\", \"\")  # Remove special characters\n    )\n\n  # ================================\n  # ‚úÖ 9. Filter out section label rows (optional)\n  # ================================\n  df &lt;- df %&gt;%\n    filter(question != 1L)\n\n  # ================================\n  # ‚úÖ 10. Filter out interviewer lines (optional)\n  # ================================\n  df &lt;- df %&gt;%\n    filter(speaker != \"interviewer\") %&gt;%\n    mutate(session = session_name)\n\n  # ================================\n  # ‚úÖ 11. Return final dataframe\n  # ================================\n  final_df &lt;- df %&gt;%\n    select(\n      line,\n      speaker,\n      participant_id,\n      section,\n      section_label = section_label_clean,\n      text,           # cleaned lowercase version\n      original_text,  # original casing/punctuation minus speaker name\n      session\n    )\n\n  return(final_df)\n}\n\nThe example below comes from the Loudoun County Opioid Abatement project where Shon, Lindsay, Hannah, Luke, Eden, and Arden are staffed, so any of them could have been an interviewer.\n\nInstructions\n\nOpen the listening session slides/guide/questions that correspond to the session to make sure we know the order of the discussion.\nOpen the listening session transcript. If it is a .vtt file, save it as a .txt or .docx and open the new .txt/.docx file.\nIdentify which sections are present from the session out of the following list of section labels. If there is a slide that is unique to a single session then it will not be included in the list below. For example, the public safety session had a slide about ‚Äúpublic safety in the community‚Äù that other sessions did not have. In this case, I added a unique section label to mark this section.\n\n\n[Data check]\n[Community impact]\n[Abatement funds]\n[Prevention and harm reduction]\n[Treatment and recovery]\n[Other strategies]\n[Vision for the future]\n[Next steps]\n\n\nAdd the section labels where relevant in the transcript. For example, when you see in the transcript something that marks the beginning of the data checks slide, you would add above that line ‚Äú[Data check]‚Äù. Importantly, note that:\n\n\nYou do not need to add any section labels before the [Data check] label. This will be our first one.\nSection labels should be on their own line and spelled exactly as the labels above, including the brackets []. This is important because our cleaning function searches for brackets!\nPlease do not edit the raw text- you are adding new lines with the section labels, not changing anything in the text.\nNot all sections are in the same order across the sessions (e.g., sometimes treatment and recovery were discussed before prevention and harm reduction) so carefully skim through the transcript to identify the order (this should also align with the order of the deck which is helpful to have open at the same time)\n\n\nSave the file (.docx or .txt) with the section labels included.\nCopy and paste the example chunk below and edit the code to fit your session parameters.\nRun the chunk and check that all sections of the session are shown.\nIf everything looks ok, add your dataframe to the R chunk labeled ```{r bind all data together}.\nRun the whole script below and check the ‚Äúcleaned_text‚Äù dataframe.\n\n\n# %%%%%%%%%%%%%%%%%%% List interviewer names %%%%%%%%%%%%%%%%%%%\ninterviewers &lt;- c(\"Shon Reed\", \n                  \"Lindsay Houston\",\n                  \"Hannah Lunkenheimer\",\n                  \"Luke Saunders\",\n                  \"Eden Griffin\",\n                  \"Sam Barron\",\n                  \"Arden Trewartha\")\n\n\n# %%%%%%%%%%%%%%%%%%%%%%% EXAMPLE %%%%%%%%%%%%%%%%%%%%%%%\n\n# public safety session\nps_df &lt;- clean_transcripts( # relabel the dataframe something meaningful - like ps_df stands for public safety dataframe\n  file_path = \"../../../data_collection/Listening Sessions/Transcripts/Public Safety Transcript.txt\", # add your transcript file here- you should only need to change out the last part!\n  file_type = \".txt\", # specify whether you have a .txt or .docx file\n  interviewers = interviewers,\n  session_name = \"public safety\" # add a session name\n)\n\nps_df %&gt;% \n  select(section_label) %&gt;%\n  unique()\n\n\n#education 2\nedu2_df &lt;- clean_transcripts( # relabel the dataframe something meaningful - like ps_df stands for public safety dataframe\n  file_path = \"../../../data_collection/Listening Sessions/Transcripts/Education 2 Listening Session file.txt\", # add your transcript file here- you should only need to change out the last part!\n  file_type = \".txt\", # specify whether you have a .txt or .docx file\n  interviewers = interviewers,\n  session_name = \"education\" # add a session name\n)\n\nedu2_df %&gt;% \n  select(section_label) %&gt;%\n  unique()\n\n\n# education\ned_df &lt;- clean_transcripts(\n  file_path      = \"../../../data_collection/Listening Sessions/Transcripts/Education Listening Session Transcript.docx\",\n  file_type      = \".docx\",\n  interviewers   = interviewers,\n  session_name   = \"education\"\n)\n\ned_df %&gt;% \n  select(section_label) %&gt;%\n  unique()\n\n\n#####################\n# 3) Combine all data\n#####################\ncleaned_text &lt;- dplyr::bind_rows(\n  # add your new dataframe here to this list\n  ed_df,\n  edu2_df,\n  ps_df)\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  select(-section, -speaker)\n\n\nwrite_rds(cleaned_text, file = \"data_clean/text_data_clean.rds\")"
  },
  {
    "objectID": "data_prep.html#other-text-file-types",
    "href": "data_prep.html#other-text-file-types",
    "title": "Data Cleaning",
    "section": "Other text file types",
    "text": "Other text file types\n\nPDFs\n\nlibrary(pdftools)\nlibrary(tibble)\nlibrary(dplyr)\n\n# Define the folder where PDFs are saved\nfolder_path &lt;- \"path/to/your/pdf/folder\"\n\n# List all PDF files in the folder\npdf_files &lt;- list.files(folder_path, pattern = \"\\\\.pdf$\", full.names = TRUE)\n\npdf_data &lt;- pdf_files %&gt;%\n  map_df(~ tibble(\n    file = basename(.x),           # Extract file name only\n    text = paste(pdf_text(.x), collapse = \" \")  # Merge all pages into one text block\n  ))\n\n# View the cleaned data\nprint(pdf_data)\n\npdf_data &lt;- pdf_data %&gt;%\n  mutate(text = str_replace_all(text, \"\\\\s+\", \" \"))  # Remove extra spaces/newlines\n\nprint(pdf_data)\n\n\n\nExcel sheets\nOf course, we also tend to ask qualitative questions in some of our surveys at Omni, and these types of data should be read in like quantitative data and should already be in a clean format if you follow the data cleaning guide (insert link to data cleaning guide)."
  },
  {
    "objectID": "data_prep.html#qa-checklist-for-qual-cleaning",
    "href": "data_prep.html#qa-checklist-for-qual-cleaning",
    "title": "Data Cleaning",
    "section": "QA Checklist for Qual Cleaning",
    "text": "QA Checklist for Qual Cleaning\n[ ] Are participant and interviewer roles correctly labeled?\n[ ] Have names, locations, and job titles been de-identified?\n[ ] Are timestamps removed (unless needed for analysis)?\n[ ] Are discussion sections correctly labeled?\n[ ] Has text been standardized (case, punctuation, spacing)?\n[ ] Is the cleaned dataset in a tidy format (one speaker turn per row)?\n[ ] Has the cleaned dataset been reviewed by another team member?"
  }
]